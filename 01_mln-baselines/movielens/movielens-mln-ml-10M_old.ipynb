{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MovieLens MLN Recommendation via PyTorch\n",
    "\n",
    "adapted from https://github.com/fastai/fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "import time\n",
    "\n",
    "figure_path = '/home/weiss/git/thesis/doc/figures/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)\n",
    "\n",
    "RANDOM_STATE = 2021\n",
    "set_random_seed(RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    files = {}\n",
    "    path = Path(path)\n",
    "    for filename in path.glob('*'):\n",
    "        if filename.suffix == '.dat':\n",
    "            if filename.stem == 'ratings':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "            else:\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "            data = pd.read_csv(filename, sep='::', names=columns, engine='python')\n",
    "            files[filename.stem] = data\n",
    "    return files['ratings'], files['movies']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# pick one of the available folders\n",
    "ratings, movies = read_data('/home/weiss/rs_data/ml-10m')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   userId  movieId  rating  timestamp\n0       1      122     5.0  838985046\n1       1      185     5.0  838983525\n2       1      231     5.0  838983392\n3       1      292     5.0  838983421\n4       1      316     5.0  838983392",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>122</td>\n      <td>5.0</td>\n      <td>838985046</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>185</td>\n      <td>5.0</td>\n      <td>838983525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>231</td>\n      <td>5.0</td>\n      <td>838983392</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>292</td>\n      <td>5.0</td>\n      <td>838983421</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>316</td>\n      <td>5.0</td>\n      <td>838983392</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 69878 users, 10677 movies\n",
      "Dataset shape: (10000054, 2)\n",
      "Target shape: (10000054,)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    unique_users = ratings.userId.unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = ratings.userId.map(user_to_index)\n",
    "\n",
    "    unique_movies = ratings.movieId.unique()\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)}\n",
    "    new_movies = ratings.movieId.map(movie_to_index)\n",
    "\n",
    "    n_users = unique_users.shape[0]\n",
    "    n_movies = unique_movies.shape[0]\n",
    "\n",
    "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_movies})\n",
    "    y = ratings['rating'].astype(np.float32)\n",
    "    return (n_users, n_movies), (X, y), (user_to_index, movie_to_index)\n",
    "\n",
    "(n, m), (X, y), _ = create_dataset(ratings)\n",
    "print(f'Embeddings: {n} users, {m} movies')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, random_state=RANDOM_STATE)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=RANDOM_STATE)\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid), 'test': (X_test, y_test)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_valid), 'test': len(X_test)}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class RatingsIterator:\n",
    "\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in RatingsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class RecommenderNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates dense MLN with embedding layers.\n",
    "\n",
    "    Args:\n",
    "        n_users:\n",
    "            Number of unique users in the dataset.\n",
    "\n",
    "        n_movies:\n",
    "            Number of unique movies in the dataset.\n",
    "\n",
    "        n_factors:\n",
    "            Number of columns in the embeddings matrix.\n",
    "\n",
    "        embedding_dropout:\n",
    "            Dropout rate to apply right after embeddings layer.\n",
    "\n",
    "        hidden:\n",
    "            A single integer or a list of integers defining the number of\n",
    "            units in hidden layer(s).\n",
    "\n",
    "        dropouts:\n",
    "            A single integer or a list of integers defining the dropout\n",
    "            layers rates applied right after each of hidden layers.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_movies,\n",
    "                 n_factors=50, embedding_dropout=0.02,\n",
    "                 hidden=10, dropouts=0.2):\n",
    "\n",
    "        super().__init__()\n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "\n",
    "        def gen_layers(n_in):\n",
    "            \"\"\"\n",
    "            A generator that yields a sequence of hidden layers and\n",
    "            their activations/dropouts.\n",
    "\n",
    "            Note that the function captures `hidden` and `dropouts`\n",
    "            values from the outer scope.\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "\n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self._init()\n",
    "\n",
    "    def forward(self, users, movies, minmax=None):\n",
    "        features = torch.cat([self.u(users), self.m(movies)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        #out = self.relu(self.fc(x))  # relu delivers worse rsme\n",
    "        if minmax is not None:\n",
    "            min_rating, max_rating = minmax\n",
    "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "        return out\n",
    "\n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Setup embeddings and hidden layers with reasonable initial values.\n",
    "        \"\"\"\n",
    "\n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)\n",
    "\n",
    "\n",
    "def get_list(n):\n",
    "    if isinstance(n, (int, float)):\n",
    "        return [n]\n",
    "    elif hasattr(n, '__iter__'):\n",
    "        return list(n)\n",
    "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "\n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi*t/t_max))/2\n",
    "    return scheduler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def plot_lr(schedule):\n",
    "    ts = list(range(1000))\n",
    "    y = [schedule(t, 0.001) for t in ts]\n",
    "    plt.plot(ts, y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5, 5.0)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = float(ratings.rating.min()), float(ratings.rating.max())\n",
    "minmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# small net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=10, hidden=[10],\n",
    "    embedding_dropout=0.05, dropouts=[0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "#iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "#scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.8454 - val: 0.7826\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7685 - val: 0.7729\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.7585 - val: 0.7700\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.7538 - val: 0.7681\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.7501 - val: 0.7671\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.7468 - val: 0.7660\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 0.7443 - val: 0.7652\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 0.7419 - val: 0.7643\n",
      "[009/300] train: 0.7402 - val: 0.7643\n",
      "loss improvement on epoch: 10\n",
      "[010/300] train: 0.7385 - val: 0.7639\n",
      "loss improvement on epoch: 11\n",
      "[011/300] train: 0.7372 - val: 0.7631\n",
      "loss improvement on epoch: 12\n",
      "[012/300] train: 0.7359 - val: 0.7624\n",
      "loss improvement on epoch: 13\n",
      "[013/300] train: 0.7342 - val: 0.7619\n",
      "loss improvement on epoch: 14\n",
      "[014/300] train: 0.7330 - val: 0.7615\n",
      "[015/300] train: 0.7314 - val: 0.7615\n",
      "loss improvement on epoch: 16\n",
      "[016/300] train: 0.7306 - val: 0.7610\n",
      "loss improvement on epoch: 17\n",
      "[017/300] train: 0.7295 - val: 0.7609\n",
      "loss improvement on epoch: 18\n",
      "[018/300] train: 0.7285 - val: 0.7606\n",
      "[019/300] train: 0.7280 - val: 0.7611\n",
      "loss improvement on epoch: 20\n",
      "[020/300] train: 0.7265 - val: 0.7599\n",
      "[021/300] train: 0.7258 - val: 0.7603\n",
      "loss improvement on epoch: 22\n",
      "[022/300] train: 0.7248 - val: 0.7599\n",
      "[023/300] train: 0.7239 - val: 0.7609\n",
      "[024/300] train: 0.7234 - val: 0.7606\n",
      "[025/300] train: 0.7227 - val: 0.7603\n",
      "[026/300] train: 0.7222 - val: 0.7605\n",
      "[027/300] train: 0.7217 - val: 0.7607\n",
      "[028/300] train: 0.7216 - val: 0.7607\n",
      "[029/300] train: 0.7209 - val: 0.7606\n",
      "[030/300] train: 0.7207 - val: 0.7607\n",
      "[031/300] train: 0.7203 - val: 0.7612\n",
      "[032/300] train: 0.7202 - val: 0.7606\n",
      "[033/300] train: 0.7196 - val: 0.7606\n",
      "[034/300] train: 0.7197 - val: 0.7609\n",
      "[035/300] train: 0.7191 - val: 0.7609\n",
      "[036/300] train: 0.7188 - val: 0.7606\n",
      "[037/300] train: 0.7184 - val: 0.7612\n",
      "[038/300] train: 0.7187 - val: 0.7612\n",
      "[039/300] train: 0.7181 - val: 0.7609\n",
      "[040/300] train: 0.7177 - val: 0.7604\n",
      "[041/300] train: 0.7175 - val: 0.7609\n",
      "[042/300] train: 0.7177 - val: 0.7610\n",
      "[043/300] train: 0.7170 - val: 0.7611\n",
      "[044/300] train: 0.7170 - val: 0.7610\n",
      "[045/300] train: 0.7169 - val: 0.7607\n",
      "[046/300] train: 0.7166 - val: 0.7609\n",
      "[047/300] train: 0.7165 - val: 0.7607\n",
      "[048/300] train: 0.7163 - val: 0.7607\n",
      "[049/300] train: 0.7164 - val: 0.7611\n",
      "[050/300] train: 0.7160 - val: 0.7607\n",
      "[051/300] train: 0.7159 - val: 0.7610\n",
      "[052/300] train: 0.7158 - val: 0.7613\n",
      "[053/300] train: 0.7157 - val: 0.7611\n",
      "[054/300] train: 0.7154 - val: 0.7614\n",
      "[055/300] train: 0.7153 - val: 0.7614\n",
      "[056/300] train: 0.7151 - val: 0.7611\n",
      "[057/300] train: 0.7154 - val: 0.7615\n",
      "[058/300] train: 0.7151 - val: 0.7613\n",
      "[059/300] train: 0.7147 - val: 0.7609\n",
      "[060/300] train: 0.7148 - val: 0.7611\n",
      "[061/300] train: 0.7145 - val: 0.7611\n",
      "[062/300] train: 0.7147 - val: 0.7612\n",
      "[063/300] train: 0.7144 - val: 0.7619\n",
      "[064/300] train: 0.7142 - val: 0.7606\n",
      "[065/300] train: 0.7140 - val: 0.7623\n",
      "[066/300] train: 0.7142 - val: 0.7609\n",
      "[067/300] train: 0.7142 - val: 0.7615\n",
      "[068/300] train: 0.7137 - val: 0.7617\n",
      "[069/300] train: 0.7138 - val: 0.7616\n",
      "[070/300] train: 0.7139 - val: 0.7610\n",
      "[071/300] train: 0.7138 - val: 0.7615\n",
      "[072/300] train: 0.7136 - val: 0.7614\n",
      "[073/300] train: 0.7137 - val: 0.7611\n",
      "[074/300] train: 0.7137 - val: 0.7616\n",
      "[075/300] train: 0.7135 - val: 0.7618\n",
      "[076/300] train: 0.7135 - val: 0.7615\n",
      "[077/300] train: 0.7132 - val: 0.7614\n",
      "[078/300] train: 0.7130 - val: 0.7618\n",
      "[079/300] train: 0.7129 - val: 0.7614\n",
      "[080/300] train: 0.7131 - val: 0.7618\n",
      "[081/300] train: 0.7129 - val: 0.7612\n",
      "[082/300] train: 0.7128 - val: 0.7612\n",
      "[083/300] train: 0.7128 - val: 0.7615\n",
      "[084/300] train: 0.7126 - val: 0.7616\n",
      "[085/300] train: 0.7130 - val: 0.7619\n",
      "[086/300] train: 0.7126 - val: 0.7621\n",
      "[087/300] train: 0.7126 - val: 0.7615\n",
      "[088/300] train: 0.7128 - val: 0.7614\n",
      "[089/300] train: 0.7126 - val: 0.7625\n",
      "[090/300] train: 0.7124 - val: 0.7613\n",
      "[091/300] train: 0.7125 - val: 0.7614\n",
      "[092/300] train: 0.7125 - val: 0.7613\n",
      "[093/300] train: 0.7119 - val: 0.7614\n",
      "[094/300] train: 0.7121 - val: 0.7616\n",
      "[095/300] train: 0.7120 - val: 0.7613\n",
      "[096/300] train: 0.7121 - val: 0.7611\n",
      "[097/300] train: 0.7121 - val: 0.7619\n",
      "[098/300] train: 0.7119 - val: 0.7616\n",
      "[099/300] train: 0.7121 - val: 0.7614\n",
      "[100/300] train: 0.7120 - val: 0.7615\n",
      "[101/300] train: 0.7117 - val: 0.7615\n",
      "[102/300] train: 0.7118 - val: 0.7614\n",
      "[103/300] train: 0.7118 - val: 0.7620\n",
      "[104/300] train: 0.7115 - val: 0.7612\n",
      "[105/300] train: 0.7118 - val: 0.7611\n",
      "[106/300] train: 0.7117 - val: 0.7606\n",
      "[107/300] train: 0.7116 - val: 0.7624\n",
      "[108/300] train: 0.7115 - val: 0.7614\n",
      "[109/300] train: 0.7113 - val: 0.7622\n",
      "[110/300] train: 0.7113 - val: 0.7617\n",
      "[111/300] train: 0.7113 - val: 0.7626\n",
      "[112/300] train: 0.7117 - val: 0.7617\n",
      "[113/300] train: 0.7114 - val: 0.7621\n",
      "[114/300] train: 0.7114 - val: 0.7622\n",
      "[115/300] train: 0.7114 - val: 0.7619\n",
      "[116/300] train: 0.7110 - val: 0.7622\n",
      "[117/300] train: 0.7109 - val: 0.7615\n",
      "[118/300] train: 0.7112 - val: 0.7617\n",
      "[119/300] train: 0.7106 - val: 0.7618\n",
      "[120/300] train: 0.7108 - val: 0.7627\n",
      "[121/300] train: 0.7110 - val: 0.7620\n",
      "[122/300] train: 0.7108 - val: 0.7617\n",
      "[123/300] train: 0.7111 - val: 0.7621\n",
      "[124/300] train: 0.7108 - val: 0.7625\n",
      "[125/300] train: 0.7108 - val: 0.7621\n",
      "[126/300] train: 0.7105 - val: 0.7626\n",
      "[127/300] train: 0.7106 - val: 0.7621\n",
      "[128/300] train: 0.7105 - val: 0.7620\n",
      "[129/300] train: 0.7106 - val: 0.7620\n",
      "[130/300] train: 0.7104 - val: 0.7611\n",
      "[131/300] train: 0.7103 - val: 0.7627\n",
      "[132/300] train: 0.7107 - val: 0.7617\n",
      "[133/300] train: 0.7105 - val: 0.7617\n",
      "[134/300] train: 0.7104 - val: 0.7620\n",
      "[135/300] train: 0.7108 - val: 0.7619\n",
      "[136/300] train: 0.7104 - val: 0.7621\n",
      "[137/300] train: 0.7102 - val: 0.7622\n",
      "[138/300] train: 0.7101 - val: 0.7616\n",
      "[139/300] train: 0.7103 - val: 0.7619\n",
      "[140/300] train: 0.7104 - val: 0.7618\n",
      "[141/300] train: 0.7101 - val: 0.7623\n",
      "[142/300] train: 0.7102 - val: 0.7617\n",
      "[143/300] train: 0.7104 - val: 0.7620\n",
      "[144/300] train: 0.7099 - val: 0.7609\n",
      "[145/300] train: 0.7101 - val: 0.7625\n",
      "[146/300] train: 0.7102 - val: 0.7615\n",
      "[147/300] train: 0.7100 - val: 0.7623\n",
      "[148/300] train: 0.7099 - val: 0.7624\n",
      "[149/300] train: 0.7102 - val: 0.7623\n",
      "[150/300] train: 0.7103 - val: 0.7619\n",
      "[151/300] train: 0.7101 - val: 0.7627\n",
      "[152/300] train: 0.7100 - val: 0.7624\n",
      "[153/300] train: 0.7101 - val: 0.7624\n",
      "[154/300] train: 0.7101 - val: 0.7617\n",
      "[155/300] train: 0.7101 - val: 0.7622\n",
      "[156/300] train: 0.7101 - val: 0.7629\n",
      "[157/300] train: 0.7102 - val: 0.7620\n",
      "[158/300] train: 0.7097 - val: 0.7623\n",
      "[159/300] train: 0.7097 - val: 0.7622\n",
      "[160/300] train: 0.7097 - val: 0.7623\n",
      "[161/300] train: 0.7095 - val: 0.7624\n",
      "[162/300] train: 0.7094 - val: 0.7616\n",
      "[163/300] train: 0.7095 - val: 0.7618\n",
      "[164/300] train: 0.7098 - val: 0.7615\n",
      "[165/300] train: 0.7096 - val: 0.7622\n",
      "[166/300] train: 0.7099 - val: 0.7625\n",
      "[167/300] train: 0.7095 - val: 0.7623\n",
      "[168/300] train: 0.7093 - val: 0.7621\n",
      "[169/300] train: 0.7098 - val: 0.7622\n",
      "[170/300] train: 0.7096 - val: 0.7615\n",
      "[171/300] train: 0.7096 - val: 0.7618\n",
      "[172/300] train: 0.7096 - val: 0.7627\n",
      "[173/300] train: 0.7096 - val: 0.7631\n",
      "[174/300] train: 0.7093 - val: 0.7623\n",
      "[175/300] train: 0.7096 - val: 0.7623\n",
      "[176/300] train: 0.7094 - val: 0.7622\n",
      "[177/300] train: 0.7095 - val: 0.7612\n",
      "[178/300] train: 0.7094 - val: 0.7622\n",
      "[179/300] train: 0.7094 - val: 0.7625\n",
      "[180/300] train: 0.7091 - val: 0.7621\n",
      "[181/300] train: 0.7095 - val: 0.7622\n",
      "[182/300] train: 0.7094 - val: 0.7624\n",
      "[183/300] train: 0.7092 - val: 0.7615\n",
      "[184/300] train: 0.7093 - val: 0.7627\n",
      "[185/300] train: 0.7091 - val: 0.7620\n",
      "[186/300] train: 0.7093 - val: 0.7617\n",
      "[187/300] train: 0.7089 - val: 0.7623\n",
      "[188/300] train: 0.7092 - val: 0.7623\n",
      "[189/300] train: 0.7090 - val: 0.7615\n",
      "[190/300] train: 0.7093 - val: 0.7626\n",
      "[191/300] train: 0.7092 - val: 0.7619\n",
      "[192/300] train: 0.7092 - val: 0.7628\n",
      "[193/300] train: 0.7087 - val: 0.7624\n",
      "[194/300] train: 0.7090 - val: 0.7628\n",
      "[195/300] train: 0.7088 - val: 0.7627\n",
      "[196/300] train: 0.7090 - val: 0.7630\n",
      "[197/300] train: 0.7088 - val: 0.7627\n",
      "[198/300] train: 0.7088 - val: 0.7622\n",
      "[199/300] train: 0.7092 - val: 0.7626\n",
      "[200/300] train: 0.7088 - val: 0.7623\n",
      "[201/300] train: 0.7089 - val: 0.7633\n",
      "[202/300] train: 0.7088 - val: 0.7624\n",
      "[203/300] train: 0.7085 - val: 0.7614\n",
      "[204/300] train: 0.7087 - val: 0.7625\n",
      "[205/300] train: 0.7089 - val: 0.7628\n",
      "[206/300] train: 0.7087 - val: 0.7629\n",
      "[207/300] train: 0.7087 - val: 0.7622\n",
      "[208/300] train: 0.7088 - val: 0.7630\n",
      "[209/300] train: 0.7088 - val: 0.7620\n",
      "[210/300] train: 0.7087 - val: 0.7615\n",
      "[211/300] train: 0.7086 - val: 0.7628\n",
      "[212/300] train: 0.7086 - val: 0.7623\n",
      "[213/300] train: 0.7084 - val: 0.7623\n",
      "[214/300] train: 0.7084 - val: 0.7626\n",
      "[215/300] train: 0.7087 - val: 0.7622\n",
      "[216/300] train: 0.7086 - val: 0.7620\n",
      "[217/300] train: 0.7087 - val: 0.7623\n",
      "[218/300] train: 0.7084 - val: 0.7627\n",
      "[219/300] train: 0.7084 - val: 0.7631\n",
      "[220/300] train: 0.7084 - val: 0.7627\n",
      "[221/300] train: 0.7086 - val: 0.7627\n",
      "[222/300] train: 0.7085 - val: 0.7620\n",
      "[223/300] train: 0.7085 - val: 0.7634\n",
      "[224/300] train: 0.7083 - val: 0.7627\n",
      "[225/300] train: 0.7084 - val: 0.7621\n",
      "[226/300] train: 0.7083 - val: 0.7619\n",
      "[227/300] train: 0.7084 - val: 0.7628\n",
      "[228/300] train: 0.7085 - val: 0.7624\n",
      "[229/300] train: 0.7083 - val: 0.7623\n",
      "[230/300] train: 0.7084 - val: 0.7627\n",
      "[231/300] train: 0.7085 - val: 0.7625\n",
      "[232/300] train: 0.7082 - val: 0.7624\n",
      "[233/300] train: 0.7081 - val: 0.7633\n",
      "[234/300] train: 0.7081 - val: 0.7627\n",
      "[235/300] train: 0.7085 - val: 0.7626\n",
      "[236/300] train: 0.7083 - val: 0.7625\n",
      "[237/300] train: 0.7086 - val: 0.7625\n",
      "[238/300] train: 0.7079 - val: 0.7626\n",
      "[239/300] train: 0.7082 - val: 0.7629\n",
      "[240/300] train: 0.7082 - val: 0.7622\n",
      "[241/300] train: 0.7083 - val: 0.7626\n",
      "[242/300] train: 0.7080 - val: 0.7631\n",
      "[243/300] train: 0.7084 - val: 0.7624\n",
      "[244/300] train: 0.7082 - val: 0.7623\n",
      "[245/300] train: 0.7084 - val: 0.7636\n",
      "[246/300] train: 0.7083 - val: 0.7634\n",
      "[247/300] train: 0.7082 - val: 0.7620\n",
      "[248/300] train: 0.7080 - val: 0.7625\n",
      "[249/300] train: 0.7079 - val: 0.7629\n",
      "[250/300] train: 0.7083 - val: 0.7623\n",
      "[251/300] train: 0.7079 - val: 0.7634\n",
      "[252/300] train: 0.7078 - val: 0.7622\n",
      "[253/300] train: 0.7082 - val: 0.7634\n",
      "[254/300] train: 0.7079 - val: 0.7625\n",
      "[255/300] train: 0.7079 - val: 0.7623\n",
      "[256/300] train: 0.7079 - val: 0.7625\n",
      "[257/300] train: 0.7077 - val: 0.7627\n",
      "[258/300] train: 0.7078 - val: 0.7624\n",
      "[259/300] train: 0.7082 - val: 0.7627\n",
      "[260/300] train: 0.7077 - val: 0.7634\n",
      "[261/300] train: 0.7080 - val: 0.7629\n",
      "[262/300] train: 0.7078 - val: 0.7630\n",
      "[263/300] train: 0.7078 - val: 0.7631\n",
      "[264/300] train: 0.7080 - val: 0.7635\n",
      "[265/300] train: 0.7079 - val: 0.7625\n",
      "[266/300] train: 0.7077 - val: 0.7627\n",
      "[267/300] train: 0.7078 - val: 0.7629\n",
      "[268/300] train: 0.7078 - val: 0.7626\n",
      "[269/300] train: 0.7080 - val: 0.7625\n",
      "[270/300] train: 0.7080 - val: 0.7617\n",
      "[271/300] train: 0.7078 - val: 0.7622\n",
      "[272/300] train: 0.7079 - val: 0.7627\n",
      "[273/300] train: 0.7076 - val: 0.7629\n",
      "[274/300] train: 0.7077 - val: 0.7629\n",
      "[275/300] train: 0.7078 - val: 0.7632\n",
      "[276/300] train: 0.7079 - val: 0.7623\n",
      "[277/300] train: 0.7079 - val: 0.7627\n",
      "[278/300] train: 0.7077 - val: 0.7623\n",
      "[279/300] train: 0.7075 - val: 0.7627\n",
      "[280/300] train: 0.7077 - val: 0.7626\n",
      "[281/300] train: 0.7076 - val: 0.7625\n",
      "[282/300] train: 0.7075 - val: 0.7627\n",
      "[283/300] train: 0.7076 - val: 0.7624\n",
      "[284/300] train: 0.7078 - val: 0.7632\n",
      "[285/300] train: 0.7079 - val: 0.7635\n",
      "[286/300] train: 0.7076 - val: 0.7624\n",
      "[287/300] train: 0.7076 - val: 0.7627\n",
      "[288/300] train: 0.7079 - val: 0.7629\n",
      "[289/300] train: 0.7078 - val: 0.7632\n",
      "[290/300] train: 0.7079 - val: 0.7628\n",
      "[291/300] train: 0.7077 - val: 0.7625\n",
      "[292/300] train: 0.7075 - val: 0.7621\n",
      "[293/300] train: 0.7078 - val: 0.7635\n",
      "[294/300] train: 0.7074 - val: 0.7625\n",
      "[295/300] train: 0.7074 - val: 0.7625\n",
      "[296/300] train: 0.7075 - val: 0.7619\n",
      "[297/300] train: 0.7073 - val: 0.7623\n",
      "[298/300] train: 0.7074 - val: 0.7626\n",
      "[299/300] train: 0.7077 - val: 0.7632\n",
      "[300/300] train: 0.7075 - val: 0.7628\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "\n",
    "plt.savefig(figure_path + '/ml-10m-small-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Plot decreasing learning rate\n",
    "\n",
    "#_ = plt.plot(lr_history[:2*iterations_per_epoch-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8723\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.8722\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "with open('best.weights.small', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 877.795\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# medium net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=20, hidden=[10 ,10],\n",
    "    embedding_dropout=0.05, dropouts=[0.3, 0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "#iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "#scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.8778 - val: 0.7960\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7761 - val: 0.7788\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.7622 - val: 0.7744\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.7550 - val: 0.7715\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.7495 - val: 0.7700\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.7452 - val: 0.7690\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 0.7415 - val: 0.7679\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 0.7387 - val: 0.7669\n",
      "[009/300] train: 0.7367 - val: 0.7669\n",
      "[010/300] train: 0.7345 - val: 0.7671\n",
      "loss improvement on epoch: 11\n",
      "[011/300] train: 0.7330 - val: 0.7664\n",
      "loss improvement on epoch: 12\n",
      "[012/300] train: 0.7312 - val: 0.7653\n",
      "[013/300] train: 0.7302 - val: 0.7655\n",
      "[014/300] train: 0.7290 - val: 0.7659\n",
      "[015/300] train: 0.7278 - val: 0.7659\n",
      "[016/300] train: 0.7267 - val: 0.7658\n",
      "[017/300] train: 0.7258 - val: 0.7656\n",
      "[018/300] train: 0.7248 - val: 0.7663\n",
      "[019/300] train: 0.7240 - val: 0.7655\n",
      "[020/300] train: 0.7237 - val: 0.7654\n",
      "[021/300] train: 0.7229 - val: 0.7656\n",
      "[022/300] train: 0.7222 - val: 0.7657\n",
      "[023/300] train: 0.7218 - val: 0.7661\n",
      "[024/300] train: 0.7212 - val: 0.7664\n",
      "[025/300] train: 0.7205 - val: 0.7660\n",
      "[026/300] train: 0.7201 - val: 0.7659\n",
      "[027/300] train: 0.7196 - val: 0.7657\n",
      "[028/300] train: 0.7190 - val: 0.7655\n",
      "[029/300] train: 0.7186 - val: 0.7663\n",
      "[030/300] train: 0.7183 - val: 0.7667\n",
      "[031/300] train: 0.7179 - val: 0.7666\n",
      "[032/300] train: 0.7172 - val: 0.7662\n",
      "[033/300] train: 0.7168 - val: 0.7674\n",
      "[034/300] train: 0.7167 - val: 0.7662\n",
      "[035/300] train: 0.7167 - val: 0.7668\n",
      "[036/300] train: 0.7161 - val: 0.7666\n",
      "[037/300] train: 0.7162 - val: 0.7663\n",
      "[038/300] train: 0.7158 - val: 0.7672\n",
      "[039/300] train: 0.7155 - val: 0.7673\n",
      "[040/300] train: 0.7149 - val: 0.7676\n",
      "[041/300] train: 0.7144 - val: 0.7671\n",
      "[042/300] train: 0.7141 - val: 0.7667\n",
      "[043/300] train: 0.7144 - val: 0.7663\n",
      "[044/300] train: 0.7138 - val: 0.7664\n",
      "[045/300] train: 0.7141 - val: 0.7678\n",
      "[046/300] train: 0.7134 - val: 0.7672\n",
      "[047/300] train: 0.7131 - val: 0.7685\n",
      "[048/300] train: 0.7126 - val: 0.7672\n",
      "[049/300] train: 0.7129 - val: 0.7676\n",
      "[050/300] train: 0.7127 - val: 0.7674\n",
      "[051/300] train: 0.7123 - val: 0.7680\n",
      "[052/300] train: 0.7122 - val: 0.7677\n",
      "[053/300] train: 0.7117 - val: 0.7687\n",
      "[054/300] train: 0.7115 - val: 0.7668\n",
      "[055/300] train: 0.7116 - val: 0.7677\n",
      "[056/300] train: 0.7115 - val: 0.7688\n",
      "[057/300] train: 0.7111 - val: 0.7674\n",
      "[058/300] train: 0.7110 - val: 0.7685\n",
      "[059/300] train: 0.7105 - val: 0.7671\n",
      "[060/300] train: 0.7108 - val: 0.7678\n",
      "[061/300] train: 0.7105 - val: 0.7682\n",
      "[062/300] train: 0.7105 - val: 0.7687\n",
      "[063/300] train: 0.7104 - val: 0.7683\n",
      "[064/300] train: 0.7101 - val: 0.7686\n",
      "[065/300] train: 0.7102 - val: 0.7682\n",
      "[066/300] train: 0.7099 - val: 0.7691\n",
      "[067/300] train: 0.7092 - val: 0.7686\n",
      "[068/300] train: 0.7094 - val: 0.7694\n",
      "[069/300] train: 0.7093 - val: 0.7694\n",
      "[070/300] train: 0.7091 - val: 0.7683\n",
      "[071/300] train: 0.7091 - val: 0.7689\n",
      "[072/300] train: 0.7092 - val: 0.7691\n",
      "[073/300] train: 0.7091 - val: 0.7696\n",
      "[074/300] train: 0.7086 - val: 0.7688\n",
      "[075/300] train: 0.7089 - val: 0.7691\n",
      "[076/300] train: 0.7087 - val: 0.7697\n",
      "[077/300] train: 0.7082 - val: 0.7697\n",
      "[078/300] train: 0.7086 - val: 0.7688\n",
      "[079/300] train: 0.7082 - val: 0.7690\n",
      "[080/300] train: 0.7083 - val: 0.7693\n",
      "[081/300] train: 0.7081 - val: 0.7693\n",
      "[082/300] train: 0.7080 - val: 0.7696\n",
      "[083/300] train: 0.7078 - val: 0.7694\n",
      "[084/300] train: 0.7077 - val: 0.7694\n",
      "[085/300] train: 0.7076 - val: 0.7694\n",
      "[086/300] train: 0.7076 - val: 0.7690\n",
      "[087/300] train: 0.7075 - val: 0.7692\n",
      "[088/300] train: 0.7074 - val: 0.7692\n",
      "[089/300] train: 0.7073 - val: 0.7693\n",
      "[090/300] train: 0.7073 - val: 0.7695\n",
      "[091/300] train: 0.7072 - val: 0.7697\n",
      "[092/300] train: 0.7070 - val: 0.7691\n",
      "[093/300] train: 0.7071 - val: 0.7694\n",
      "[094/300] train: 0.7070 - val: 0.7694\n",
      "[095/300] train: 0.7067 - val: 0.7694\n",
      "[096/300] train: 0.7067 - val: 0.7685\n",
      "[097/300] train: 0.7067 - val: 0.7697\n",
      "[098/300] train: 0.7068 - val: 0.7696\n",
      "[099/300] train: 0.7066 - val: 0.7702\n",
      "[100/300] train: 0.7066 - val: 0.7689\n",
      "[101/300] train: 0.7066 - val: 0.7697\n",
      "[102/300] train: 0.7066 - val: 0.7709\n",
      "[103/300] train: 0.7061 - val: 0.7699\n",
      "[104/300] train: 0.7061 - val: 0.7700\n",
      "[105/300] train: 0.7061 - val: 0.7703\n",
      "[106/300] train: 0.7061 - val: 0.7705\n",
      "[107/300] train: 0.7062 - val: 0.7699\n",
      "[108/300] train: 0.7058 - val: 0.7702\n",
      "[109/300] train: 0.7054 - val: 0.7700\n",
      "[110/300] train: 0.7057 - val: 0.7697\n",
      "[111/300] train: 0.7055 - val: 0.7709\n",
      "[112/300] train: 0.7052 - val: 0.7696\n",
      "[113/300] train: 0.7055 - val: 0.7688\n",
      "[114/300] train: 0.7052 - val: 0.7705\n",
      "[115/300] train: 0.7052 - val: 0.7704\n",
      "[116/300] train: 0.7052 - val: 0.7699\n",
      "[117/300] train: 0.7054 - val: 0.7705\n",
      "[118/300] train: 0.7052 - val: 0.7704\n",
      "[119/300] train: 0.7052 - val: 0.7702\n",
      "[120/300] train: 0.7050 - val: 0.7712\n",
      "[121/300] train: 0.7050 - val: 0.7699\n",
      "[122/300] train: 0.7050 - val: 0.7698\n",
      "[123/300] train: 0.7049 - val: 0.7704\n",
      "[124/300] train: 0.7050 - val: 0.7692\n",
      "[125/300] train: 0.7047 - val: 0.7710\n",
      "[126/300] train: 0.7046 - val: 0.7700\n",
      "[127/300] train: 0.7047 - val: 0.7705\n",
      "[128/300] train: 0.7046 - val: 0.7698\n",
      "[129/300] train: 0.7047 - val: 0.7705\n",
      "[130/300] train: 0.7046 - val: 0.7715\n",
      "[131/300] train: 0.7049 - val: 0.7713\n",
      "[132/300] train: 0.7043 - val: 0.7706\n",
      "[133/300] train: 0.7043 - val: 0.7703\n",
      "[134/300] train: 0.7045 - val: 0.7720\n",
      "[135/300] train: 0.7041 - val: 0.7709\n",
      "[136/300] train: 0.7040 - val: 0.7708\n",
      "[137/300] train: 0.7045 - val: 0.7712\n",
      "[138/300] train: 0.7043 - val: 0.7692\n",
      "[139/300] train: 0.7043 - val: 0.7708\n",
      "[140/300] train: 0.7042 - val: 0.7714\n",
      "[141/300] train: 0.7038 - val: 0.7708\n",
      "[142/300] train: 0.7040 - val: 0.7720\n",
      "[143/300] train: 0.7037 - val: 0.7703\n",
      "[144/300] train: 0.7044 - val: 0.7711\n",
      "[145/300] train: 0.7037 - val: 0.7704\n",
      "[146/300] train: 0.7039 - val: 0.7708\n",
      "[147/300] train: 0.7036 - val: 0.7713\n",
      "[148/300] train: 0.7039 - val: 0.7721\n",
      "[149/300] train: 0.7036 - val: 0.7708\n",
      "[150/300] train: 0.7039 - val: 0.7714\n",
      "[151/300] train: 0.7037 - val: 0.7709\n",
      "[152/300] train: 0.7034 - val: 0.7706\n",
      "[153/300] train: 0.7032 - val: 0.7708\n",
      "[154/300] train: 0.7033 - val: 0.7707\n",
      "[155/300] train: 0.7038 - val: 0.7712\n",
      "[156/300] train: 0.7033 - val: 0.7713\n",
      "[157/300] train: 0.7033 - val: 0.7721\n",
      "[158/300] train: 0.7037 - val: 0.7718\n",
      "[159/300] train: 0.7031 - val: 0.7711\n",
      "[160/300] train: 0.7034 - val: 0.7712\n",
      "[161/300] train: 0.7030 - val: 0.7722\n",
      "[162/300] train: 0.7033 - val: 0.7722\n",
      "[163/300] train: 0.7031 - val: 0.7718\n",
      "[164/300] train: 0.7034 - val: 0.7718\n",
      "[165/300] train: 0.7032 - val: 0.7713\n",
      "[166/300] train: 0.7032 - val: 0.7714\n",
      "[167/300] train: 0.7032 - val: 0.7713\n",
      "[168/300] train: 0.7030 - val: 0.7705\n",
      "[169/300] train: 0.7028 - val: 0.7719\n",
      "[170/300] train: 0.7028 - val: 0.7723\n",
      "[171/300] train: 0.7026 - val: 0.7712\n",
      "[172/300] train: 0.7026 - val: 0.7714\n",
      "[173/300] train: 0.7029 - val: 0.7711\n",
      "[174/300] train: 0.7029 - val: 0.7712\n",
      "[175/300] train: 0.7031 - val: 0.7705\n",
      "[176/300] train: 0.7030 - val: 0.7724\n",
      "[177/300] train: 0.7027 - val: 0.7718\n",
      "[178/300] train: 0.7029 - val: 0.7717\n",
      "[179/300] train: 0.7026 - val: 0.7717\n",
      "[180/300] train: 0.7027 - val: 0.7720\n",
      "[181/300] train: 0.7025 - val: 0.7714\n",
      "[182/300] train: 0.7028 - val: 0.7718\n",
      "[183/300] train: 0.7026 - val: 0.7714\n",
      "[184/300] train: 0.7025 - val: 0.7722\n",
      "[185/300] train: 0.7026 - val: 0.7716\n",
      "[186/300] train: 0.7024 - val: 0.7712\n",
      "[187/300] train: 0.7026 - val: 0.7713\n",
      "[188/300] train: 0.7023 - val: 0.7703\n",
      "[189/300] train: 0.7023 - val: 0.7719\n",
      "[190/300] train: 0.7024 - val: 0.7717\n",
      "[191/300] train: 0.7025 - val: 0.7710\n",
      "[192/300] train: 0.7022 - val: 0.7717\n",
      "[193/300] train: 0.7022 - val: 0.7716\n",
      "[194/300] train: 0.7022 - val: 0.7708\n",
      "[195/300] train: 0.7024 - val: 0.7703\n",
      "[196/300] train: 0.7024 - val: 0.7723\n",
      "[197/300] train: 0.7022 - val: 0.7715\n",
      "[198/300] train: 0.7025 - val: 0.7710\n",
      "[199/300] train: 0.7026 - val: 0.7722\n",
      "[200/300] train: 0.7021 - val: 0.7713\n",
      "[201/300] train: 0.7020 - val: 0.7715\n",
      "[202/300] train: 0.7023 - val: 0.7719\n",
      "[203/300] train: 0.7016 - val: 0.7715\n",
      "[204/300] train: 0.7022 - val: 0.7715\n",
      "[205/300] train: 0.7020 - val: 0.7724\n",
      "[206/300] train: 0.7022 - val: 0.7716\n",
      "[207/300] train: 0.7022 - val: 0.7717\n",
      "[208/300] train: 0.7020 - val: 0.7726\n",
      "[209/300] train: 0.7015 - val: 0.7724\n",
      "[210/300] train: 0.7023 - val: 0.7717\n",
      "[211/300] train: 0.7017 - val: 0.7728\n",
      "[212/300] train: 0.7023 - val: 0.7725\n",
      "[213/300] train: 0.7018 - val: 0.7717\n",
      "[214/300] train: 0.7020 - val: 0.7722\n",
      "[215/300] train: 0.7019 - val: 0.7713\n",
      "[216/300] train: 0.7020 - val: 0.7722\n",
      "[217/300] train: 0.7017 - val: 0.7742\n",
      "[218/300] train: 0.7017 - val: 0.7718\n",
      "[219/300] train: 0.7015 - val: 0.7718\n",
      "[220/300] train: 0.7017 - val: 0.7714\n",
      "[221/300] train: 0.7016 - val: 0.7734\n",
      "[222/300] train: 0.7014 - val: 0.7725\n",
      "[223/300] train: 0.7016 - val: 0.7713\n",
      "[224/300] train: 0.7018 - val: 0.7710\n",
      "[225/300] train: 0.7015 - val: 0.7716\n",
      "[226/300] train: 0.7018 - val: 0.7712\n",
      "[227/300] train: 0.7011 - val: 0.7726\n",
      "[228/300] train: 0.7016 - val: 0.7727\n",
      "[229/300] train: 0.7017 - val: 0.7700\n",
      "[230/300] train: 0.7015 - val: 0.7728\n",
      "[231/300] train: 0.7013 - val: 0.7705\n",
      "[232/300] train: 0.7015 - val: 0.7712\n",
      "[233/300] train: 0.7017 - val: 0.7728\n",
      "[234/300] train: 0.7012 - val: 0.7720\n",
      "[235/300] train: 0.7015 - val: 0.7721\n",
      "[236/300] train: 0.7014 - val: 0.7724\n",
      "[237/300] train: 0.7015 - val: 0.7721\n",
      "[238/300] train: 0.7012 - val: 0.7728\n",
      "[239/300] train: 0.7017 - val: 0.7735\n",
      "[240/300] train: 0.7014 - val: 0.7719\n",
      "[241/300] train: 0.7013 - val: 0.7733\n",
      "[242/300] train: 0.7011 - val: 0.7722\n",
      "[243/300] train: 0.7011 - val: 0.7721\n",
      "[244/300] train: 0.7014 - val: 0.7727\n",
      "[245/300] train: 0.7013 - val: 0.7728\n",
      "[246/300] train: 0.7010 - val: 0.7735\n",
      "[247/300] train: 0.7014 - val: 0.7737\n",
      "[248/300] train: 0.7014 - val: 0.7741\n",
      "[249/300] train: 0.7011 - val: 0.7724\n",
      "[250/300] train: 0.7009 - val: 0.7721\n",
      "[251/300] train: 0.7010 - val: 0.7719\n",
      "[252/300] train: 0.7011 - val: 0.7733\n",
      "[253/300] train: 0.7007 - val: 0.7713\n",
      "[254/300] train: 0.7010 - val: 0.7731\n",
      "[255/300] train: 0.7007 - val: 0.7724\n",
      "[256/300] train: 0.7009 - val: 0.7713\n",
      "[257/300] train: 0.7007 - val: 0.7743\n",
      "[258/300] train: 0.7009 - val: 0.7728\n",
      "[259/300] train: 0.7012 - val: 0.7727\n",
      "[260/300] train: 0.7008 - val: 0.7726\n",
      "[261/300] train: 0.7009 - val: 0.7730\n",
      "[262/300] train: 0.7010 - val: 0.7734\n",
      "[263/300] train: 0.7011 - val: 0.7734\n",
      "[264/300] train: 0.7010 - val: 0.7714\n",
      "[265/300] train: 0.7008 - val: 0.7724\n",
      "[266/300] train: 0.7006 - val: 0.7731\n",
      "[267/300] train: 0.7009 - val: 0.7721\n",
      "[268/300] train: 0.7006 - val: 0.7725\n",
      "[269/300] train: 0.7008 - val: 0.7729\n",
      "[270/300] train: 0.7006 - val: 0.7725\n",
      "[271/300] train: 0.7008 - val: 0.7717\n",
      "[272/300] train: 0.7005 - val: 0.7724\n",
      "[273/300] train: 0.7008 - val: 0.7738\n",
      "[274/300] train: 0.7009 - val: 0.7739\n",
      "[275/300] train: 0.7007 - val: 0.7717\n",
      "[276/300] train: 0.7010 - val: 0.7719\n",
      "[277/300] train: 0.7008 - val: 0.7729\n",
      "[278/300] train: 0.7011 - val: 0.7716\n",
      "[279/300] train: 0.7006 - val: 0.7722\n",
      "[280/300] train: 0.7005 - val: 0.7722\n",
      "[281/300] train: 0.7010 - val: 0.7724\n",
      "[282/300] train: 0.7009 - val: 0.7727\n",
      "[283/300] train: 0.7008 - val: 0.7742\n",
      "[284/300] train: 0.7006 - val: 0.7731\n",
      "[285/300] train: 0.7004 - val: 0.7723\n",
      "[286/300] train: 0.7007 - val: 0.7727\n",
      "[287/300] train: 0.7005 - val: 0.7736\n",
      "[288/300] train: 0.7004 - val: 0.7746\n",
      "[289/300] train: 0.7006 - val: 0.7722\n",
      "[290/300] train: 0.7006 - val: 0.7725\n",
      "[291/300] train: 0.7006 - val: 0.7721\n",
      "[292/300] train: 0.7004 - val: 0.7745\n",
      "[293/300] train: 0.7009 - val: 0.7730\n",
      "[294/300] train: 0.7004 - val: 0.7729\n",
      "[295/300] train: 0.6999 - val: 0.7718\n",
      "[296/300] train: 0.7007 - val: 0.7717\n",
      "[297/300] train: 0.7003 - val: 0.7731\n",
      "[298/300] train: 0.7004 - val: 0.7729\n",
      "[299/300] train: 0.7002 - val: 0.7732\n",
      "[300/300] train: 0.7004 - val: 0.7728\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEQCAYAAABbfbiFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA28ElEQVR4nO3deXxdVb338c/vnMxz0qTzkM5QhiKUUZnLDEVlEIEW7lXwKvLoo6I4AOpFReQBFO9lEIVShooKUgYFChS0UGhLodBC5zadmzZTMyfnrOePddKkOafNSZvkpM33/XrllWSdtfdee+9k/fb67cmcc4iIiLQVSHQDRESk91FwEBGRKAoOIiISRcFBRESiKDiIiEiUpEQ3oKsUFha64uLiRDdDROSAsnDhwu3OuaL25QdNcCguLmbBggWJboaIyAHFzNbFKldaSUREoig4iIhIFAUHERGJouAgIiJRFBxERCSKgoOIiEQ5aC5lFZHeq7Kyku3bt9PY2JjopvQJwWCQ7OxsCgoKSE1N3ad59Png8OjcNfTLSuWiiYMT3RSRg1J9fT1bt25l6NChpKenY2aJbtJBzTlHU1MTVVVVlJSUMHz48H0KEH0+rfTEuyX84+PNiW6GyEGrtLSUoqIiMjIyFBh6gJmRkpJCYWEh+fn5lJWV7dN8+nxwCJgRDie6FSIHr/r6erKyshLdjD4pJyeHnTt37tO0fT44mEFIb8MT6TbNzc0kJfX5DHZCJCcnEwqF9mnaPh8cggFDr0oV6V5KJyXG/mz3Ph8cAmaEFRtERHaj4GAQUnQQEdmNgkPACCutJCKd8Pe//5277767y+d77bXX0lveS6PgYIZig4h0RncFh1tuuYVnn322y+e7L/r8JQQBQyMHEekWDQ0NnboBbfTo0d3Yms7p8yMHM9M5BxGJ27XXXsv06dPZuHEjZoaZUVxczJw5czAznnnmGa677jqKiooYMGAAACtXrmTq1KmMHDmS9PR0Ro0axde//nXKy8uj5t02rbR27VrMjAcffJBbb72VQYMGkZeXx0UXXcSGDRu6dT37/MghqOAgkhA/e34JSzdVJbQNEwbncNtFh3VqmltuuYXS0lLmz5/PrFmzAEhNTaWyshKAG2+8kfPOO48ZM2ZQX18PwKZNmxg6dCj33nsv+fn5rF69ml/+8pecf/75vPPOOx0u81e/+hUnnXQSf/rTn9i2bRvf/e53ueqqq3jzzTc7ucbx6/PBIRCAppCCg4jEZ/To0RQVFZGSksIJJ5ywq3zOnDkAHHfccTz88MO7TXPKKadwyimn7Pr9pJNOYsyYMZx88sksWrSIz3zmM3td5ogRI3jyySd3/V5aWspNN93Epk2bGDy4e54Lp+BgpjukRRKgs0fsB4ovfOELUWWNjY3cddddPPbYY6xbt27XiAJg2bJlHQaHCy64YLffjzjiCABKSkoUHLqLboITka40aNCgqLIf/vCH3Hfffdx6662cdNJJZGdns2HDBr74xS/uFij2pKCgYLffW05yxzPtvlJwMPT4DBHpMrEeWTFz5kymTZvGT37yk11l1dXVPdmsTuvzVysFdEJaRDopNTWVurq6uOvX1taSnJy8W9kjjzzS1c3qUho5BJRWEpHOmTBhAmVlZdx///1MmjSJtLS0vdY/99xzmT59OkcccQRjxozhmWee4e233+6h1u4bBQellUSkk7761a8yb948fvSjH1FRUcGIESN49NFH91j/vvvuwznHj3/8YwDOP/98nnrqKY477rgeanHnKTgorSQinZSZmclTTz0VVb6nA83CwkJmzpzZYf32Aaa4uDjmPE877bRuP6jVOQc9eE9EJIqCgx68JyISRcFBrwkVEYmi4GBKK4mItKfgYEY4nOhWiIj0LgoOupRVRCSKgoMevCciEiWu4GBmw8zsr2ZWaWZVZvaMmQ2Pc9rhZjbdzErMrNbMlpvZ7WaW2a7eWjNzMb4+vw/rFTfdIS0iEq3Dm+DMLAN4HWgArgEccDvwhpkd6Zyr2cu0mcBsIBm4BSgBjgV+BowFvtRukpeBn7YrWxbPiuwrpZVERKLFc4f0dcAoYLxzbiWAmS0GVgBfA/b2lu3P4oPAOc65VyJlb5hZAfA9M8twztW2qb/dOTevsyuxP3SHtIhItHjSSlOAeS2BAcA5twaYC1zcwbQpke/t3wVYEVl29LNte1hQaSURSZCWd0Tv7blMiRJPcDgM+DhG+RJgQgfTzsaPMH5tZhPMLMvMzgC+BTwQIyV1UeS8RIOZzevu8w0AZug+BxGRduIJDgVAeYzyMiB/bxM65+qBz0WWswTYCbwGvAB8s13154EbgXOAq4B64Fkzu3pP8zez681sgZktKC0tjWNVovn7HBQcRETaivdS1li9Z4cpITNLA/4M9AemAqcCN+FPRP/Pbgtw7kbn3GPOuX855/4KnAksAH61x0Y595BzbpJzblJRUVGcq7I7pZVEpDOefvppzIzFixdHfXbeeedx1FFHAfD73/+eE088kYKCAvLy8jjhhBN48cUXe7i1+y6eE9Ll+NFDe/nEHlG09RXgNGCMc25VpOwtM6sEHjKzB5xzH8aa0DkXMrO/4FNSg5xzm+Noa6cprSSSIP+4GbZ8lNg2DDwCzrujU5NMmTKF3NxcHn/8ce68885d5Vu3bmX27NnccYef39q1a/nqV79KcXExzc3NPP/881x44YW89NJLnHfeeV26Gt0hnuCwBH/eob0JwNIOpj0CKG8TGFq8F/l+KBAzOES0jE66rffWs5VEpDPS0tK47LLLePLJJ7njjjsIBHwC5qmnnsI5x5VXXgnAXXfdtWuacDjMmWeeyfLly3nggQcOmuAwC7jLzEY551YDmFkx/jLVmzuYdguQb2Zj2l7tBBwf+b5xTxOaWRJwGVDinNsSRzv3ScBQWkkkETp5xN6bTJ06lYcffpjXX3+dyZMnAzBjxgwmT57MoEGDAFi4cCG33XYb8+fPp7S0dNf9VOPHj09YuzsjnnMOfwDWAs+Z2cVmNgV4DlgPPNhSycxGmFmzmd3aZtpH8SehXzKza8zsdDO7CbgLWIi/HBYz+7KZzTSzaZE6VwBvAMcAP9jvtdyLoEYOItJJJ598MsXFxcyYMQOATz75hPfff5+pU6cCsH79es4880zKysq47777ePvtt5k/fz7nnnsu9fX1iWx63DocOTjnaiKXn94DzMCnel4Dvu2cq25T1YAgbQKOc26tmZ2Av+v5dqAQH1QeAn7hnGt5Huoa/Enr3+DPb9QC84FznXMv788KdsQiL/txzmGW8NsuROQAYGZcffXV3Hvvvdx///3MmDGDrKwsvvCFLwDwz3/+k8rKSp5++mmGDh26a7ra2to9zbLXiesd0s65EuCSDuqsJcYVTM65pcDlHUw7DzgjnrZ0tUAkIIQdBBUbRCROU6dO5fbbb+eZZ57hiSee4JJLLiEjIwNoDQLJycm76i9fvpy5c+fuFix6sz7/VNZgZAsotSQinTFu3DiOP/54br75ZkpKSnallAAmT55MUlIS06ZN45VXXmH69OmcffbZDB8e1/NKe4U+Hxxs18hBwUFEOmfq1Kls3LiRIUOGcPrpp+8qP+yww3jiiSdYt24dU6ZM4c477+SOO+7glFNOSWBrOyeutNLBbFdaSW+DE5FOuuGGG7jhhhtifnb55Zdz+eW7Z9SvuOKK3X4vLi7utU+F7vMjB6WVRESi9fngEFBaSUQkSp8PDqa0kohIlD4fHFouX9XIQUSkVZ8PDoGA0koi3a23nnQ92O3Pdu/zwaElrRTSH69It0hOTqauri7RzeiT6urqSE1N3adp+3xwCEaCg2KDSPfo378/GzdupLa2ViOIHuCco6mpibKyMjZs2EC/fv32aT66z0HnHES6VU5ODgCbNm2iqakpwa3pG5KSkkhLS2P48OGkpaXt2zy6uE0HnJZLWUN6brdIt8nJydkVJOTA0OfTSi0PYtXAQUSkVZ8PDkFdrSQiEqXPB4e2j+wWERGvzweHlrSSzjmIiLTq88GhJa2kS+xERFr1+eCgtJKISDQFB6WVRESiKDjokd0iIlEUHPT4DBGRKAoOkS2gB++JiLRScFBaSUQkioKD6VJWEZH2FBx2PXgvwQ0REelFFBz0yG4RkSgKDnrwnohIFAUHXcoqIhJFwUF3SIuIRFFwUFpJRCSKgoPSSiIiURQclFYSEYmi4KA7pEVEoig46H0OIiJRFBwiW0AjBxGRVn0+OASVVhIRidLng4MprSQiEqXPB4ddz1ZSdBAR2UXBQWklEZEofT44BANKK4mItNfng4MprSQiEqXPBwellUREovX54KC0kohItLiCg5kNM7O/mlmlmVWZ2TNmNjzOaYeb2XQzKzGzWjNbbma3m1lmu3oBM/uhma01s3oz+9DMLtmXleoM05vgRESiJHVUwcwygNeBBuAawAG3A2+Y2ZHOuZq9TJsJzAaSgVuAEuBY4GfAWOBLbar/N/A94MfAQuAK4C9mdqFz7qXOr1p8lFYSEYnWYXAArgNGAeOdcysBzGwxsAL4GnD3Xqb9LD4InOOceyVS9oaZFQDfM7MM51ytmfXHB4Y7nHN3tak3BrgD6LbgsOsOaeWVRER2iSetNAWY1xIYAJxza4C5wMUdTJsS+V7VrrwisuxIUodzInUfb1fvceAIMxsZRzv3iR68JyISLZ7gcBjwcYzyJcCEDqadjR9h/NrMJphZlpmdAXwLeKBNSuowfNpqZbvpl0S+d7ScfWZ68J6ISJR4gkMBUB6jvAzI39uEzrl64HOR5SwBdgKvAS8A32y3jArnonrosjafRzGz681sgZktKC0t7Wg9YtKD90REosV7KWusntNilO1ewSwN+DPQH5gKnArchD8R/T/t5tXpZTjnHnLOTXLOTSoqKuqoOTEprSQiEi2eE9LlxD5yzyf2iKKtrwCnAWOcc6siZW+ZWSXwkJk94Jz7kMgoxMys3eihZWRSRjcxvSZURCRKPCOHJfhzAu1NAJZ2MO0RQHmbwNDivcj3Q9ssIxUYHWMZxLGcfZb89j1cFpxDdEZLRKTviic4zAJOMLNRLQVmVoy/THVWB9NuwY8IxrQrPz7yfWPk+z+BRuCqdvWuBj6OXB3VLQJL/sZZgYVKK4mItBFPcPgDsBZ4zswuNrMpwHPAeuDBlkpmNsLMms3s1jbTPoo/Cf2SmV1jZqeb2U3AXfgb3eYCOOe2AfcAPzSz75jZaWZ2P3AG8KP9Xcm9Ss0hk3qllURE2ujwnINzriZy+ek9wAz8SeLXgG8756rbVDUgSJuA45xba2YnAD/F31VdiA8qDwG/cM6F20z/Y6Aaf5nrQGAZcLlz7vl9Xrs4WGo2WbZNaSURkTbiOSGNc64E2Otzjpxza4lxdZFzbilweRzLCOEDyO3xtKnLpGaRbXVKK4mItNHnn8pKajaZ1Ok+BxGRNhQcUnPIoo6QgoOIyC4KDilZZFoDhEOJbomISK+h4JCaDUBSU22CGyIi0nsoOLQEh1B1BxVFRPoOBYfULABSmvf4ziIRkT5HwSE1B4DkkIKDiEgLBYdIWilZIwcRkV0UHFKUVhIRaU/BITJySFFaSURkFwUHBQcRkSgKDruCg+5zEBFpoeAQTKaBFFI1chAR2UXBAaghndSwgoOISAsFB6DO0klVWklEZBcFB6Dc8shtLk10M0REeg0FB2BlcDTD6lfoyawiIhEKDsCKpLGkuTrYsTLRTRER6RUUHIDVyWP9D5sWJbYhIiK9hIIDUJk5kjpLU3AQ6W6ly6G+KjHLbqqHstV7r9PcCAsfhaa67m9P1Wao3rZ72dzfwpw7Wn9f/jK8+Zvub0sMCg5ATkYanwbGwZq3Et0UkYPXzi3w4Mnw8o9ay0rmwY5V+z/vje/Dkr9DYy2ULtv9s22fwHM3wL2Hw33HwKYPfHlzI6x7G5yD+kpftvQ5eP5b8OadrdNXl8K7D8KiJ/w0LdPG0lgLj5wPtw/wHf2e1FfBH86AB06Gyo2+bN798Oqt8OavfeBwDl65Bd64HVa82jqtc9DcAI01rdN2g6Rum/MBJDc9mTc4hs9se8T/ofYbnegmSV/UUA0NOyFrAAT2cNxWuQGSMyCjYPfyqk1+2qLxsacLh6GpZtcTAeJSW9a6nLoKSM+Lnufq12H4SYCDef8LGf1g3Lnwyk8gexCc8A1Iz4fkdP95cz18/Ayc+yt/JD99iv/smlkwaGLrvFe9DktnwajT/Ho11cLxX/MddOkncMYtsPVj36lvXAhv/ApcCAYeAVuXwJceBwvAwumw+g0Ipvh5rf0XzL4NLnvUH6G/+wB8ZiosehxO/T5sX+6X/87v/SgjKdUHjOZ6X16+BjKLfCd+3HWQNwIWzYDCcXD6j+C9h2HdXP/73N/C0dPgpe/D0En+55pSqCjxgWDnZr8vH5sCY8/226f4ZN/GV2+B/ofC9mUQSIanvgwjT4EvzfDtfvs+CCRBuAlGfNavT1b/+PdtHMw516UzTJRJkya5BQsW7NO0v3zpE2a/M5/XgzfCWT+Hz36ri1snCeccmO29TsNOn1oceITv0D55Hv59D1w+A3KHtNYLh2D7Cl9/zi/hot9B3rDWzz/6K7zxC7jwHsgfCTmDIZjc+nlzI5S8A/+82Xemp34f0nJ9R1lfAf3G+jYUf853FoEg5BfDi9+FhY9AvzFw+WN+2qwBft0ePNl3iodcAIVjffrGzE9fuwM2vAfr58PZP4dDL/ZBYvMHMPd3flkTpvhOMGuA78SWPAvPXAen/QiyiuCF78DpP/btXDcXhp/ot9XimTBkkl+vjZH/v0DkmNMCkJLpj3BHne47vfyRsG0JjDwVktJgxcuQNdBP81//gs0fQuV6ePF7EGr0HbEL+cB53evw8GRorvMdZripdZsefgms/TdUb/X7rq7cl+cO953q5Nt85/nO/8LLPwQMaNP3JaW1BoDx5/u2l37qt90hF8KJ34TXfg4rXvHLzRsBFet8/YFHQNlaCDf7tk36it+ej10M2YNh5ya/vLRcv3/Bt/+Um3zb/ny1X86Rl8OU38PjX/TbCiCYCv/5D1j8tB+9DP6M3+6jT/fLTc3xda9+ds8HFB0ws4XOuUlR5QoO8PvXV3DXK8tZPeouAnVl8I15/mhGEqe5wR99HnqR/wcKNfujuvwRvsNp8fbvfWc5/lzfIVRthoKRPme8c7PvmP/+Dd+RX/2M7zBDjbDsH/6f6qz/9nVTMuHR833nlJzpO9G3/p//xy46FArHwLZP4fLp8Py3fWcbTPHzGvwZn0444es+NbnkGbCgDwjN9ZA7DI79qq9bUwofPAmN1b6Dcc53hhbwR9onfdOnR6o2+vIW+cVQvhYmXAyfvOA7TAv4I8/0fF93zGQfFHZu8h1uQ5X/wnzdAYfBlsV+fmm5vmOpK/dtaWvUaT5dUbm+tcNMyYbGnf7njEKo3e5/nvB5WDnb/7+cdydkFsKrt8GJN8CAw2HWN/22XT3Hr8N/vuzTSuvf8/Mfd54Pjn88G1IyWtM7Gf3g1JvhHze1tiujnw8SZ/+3v7JwyDGQXuCD5+gz/Ghjxau+0/3kOb8PJn4ZklJa5+GcD8xr/+23cWZ/eOtO+MJDsPwfPihe+TSMOyf6b3L9e/DHs+DQKXDpn2DBIzDwcB8oy1bDs//lA/rpP/Ztmnml/xs85j98UE/OhIlf8vt56CS/3yAyMqprPfLfudVvm5rtgIPx5/ny+X+Ef93tt+NVT+/+f7AfFBz2YsY7a7nluSUsmppK/l8ugRNugHN/2cUtPIC0P8purPEphrxh/vuq130nMOq01jpNdb7zLhzvh+Kw+zzCYags8Z330GPBhQHnjxgt4DvqihJ4/zH43HdgzZt+mJ2S5QPE8pehrsx3qFn9/ZFefrEf0idnwPVz/D/jjpX+H765ARoqd1+vQy70+edQk+/o6sr9fFwYcob45Z/3a985r/u3n+bk78LHf/PboGa7P+IONcIx1/p8eeE4+Ohp34amWn+kd/J3Yexk+PM03/bNH0LJ25FtEoRDL/Spl0Mu8Os/93f+qPPoaT74teyD1W9AzQ7fEc/+qQ+C18/xnXHFeh9oanfA0r/7juYb70KwTaa4eps/ks7o59e16FDfMW5Z7NMp5Wth6rN+JPPx3+DMW/12f/G7Pih88Q8+wH3yApz1M5/Lzxvh064VJb7tuUP8SCoQ3Pvf1PJX/JFuzqDW9duy2AfOjAIfVBc97rdn0XhfXjgOfjPG/50UHeL33UX3wsQr9r6szmhu8AcKh07xy9n8IQw5es/1ty71+6FtwDnAKTjsxXMfbORbMz9g9ndOYcz8n8H8P8BFv/UdwIGotsx3qkkpsH2lzxVnFu5ep6HaH30mR44+lr3kO/dNi+DTF30Hft6v/c+LHvcd83HXw+I/+04J4NjroGab/4eq2dF6ZAmQlA6jTm09YVa22ue8wQ+1q7f65QeS/VHapy/4zyzoO51QAxz5Jf/PWLPN51WLP+tzui3/mJs/9CmN7SsA54+ST/uR7+CSUmHilbBjBfSf4FMo8+73gaVqs08NHHW1Tw2k5cKWj+DCu/3RdzjsO/O6Ct+Rt3h6mk+9nPoDn18G37l8+gKMPtN32qNOi97WLeuf2d8f7XWU3oqlbI0/0s/sF/1ZXYUPcO3PQ+zNzi1+nceeFbutq+fA0dd03Ol3t3/d7f9OJn3FB+XsgYltz0FIwWEv5izbxrWPzOdvXz+RY4Zmw1NXwKo34MszYdzZXdzSLlCz3R/9PnEZHD3Vd9oAy//ph+Uvfs+3+8Qb4JEL/BF23nD/ddKNfog7/4/+6DApzXcAdRWA80fxn7nan/hzId9ZjzjJ190wH4YdD5N/BvP+x+fkswfB8BP8keuwE3xn68L+xOmat/zRnwV8qqf/of7I+qOnfYojPR/WvQMrX/VpgTNv80fg0y/yOdtzfrX7kXB7VZt9x775Q5j5ZX9kOm3WnjvfcNh/tuQZf+HBqd/v3HbfscqfqDz7Fz4FInIQUHDYi0Ul5Xzhf9/mkWuP5fRD+vuj6kfP90ekF97rO7uCUTD8+K5rcKjZd3zbV/qTl2fe4vPEyek+B/zWXf5od+MimHCRP1rNG+5POj50uu/kmuv9UXZy5Gi05WSXBXyb0/P9z7U7WpeblOaPwA65wJ+sa4qkS5JS/Uk352DoMf4E2Jq3/FUh2QN86qC2zJ+cBP97+Vq/XfblSLjtdlj6d3/E3nI1TDwnj9urr/LbQp22SKfsKTjoUlb8pawAlXWRqx9Ss+DKv8AfJ8Oz17dWPOUmOOMn/gh05yZfljUQ1r/rv066sfWqlPoqn4LZ8hEcdSUMPtqnQypK4B8/8Gmc9Hx/pFy10Z8gqymFtByfIy5f60/ojTkDPpzpT2KOO9cHrNQsnyM/6kr/We5QH1SGn+jTJrlD4dEL/VH6tS/Cx3/18/z4b37EcemfWnPbe3Lk5f6rRSDYGhhafu+KS36DSXDEpbuX7UuwScvZ/7aIyC4KDsQIDuCPlv/r3/4kXHoBzL0H3vqNTy1sXNh6GVtyhs87uxB8MsufSCtd5tMqTTW+g35/uk/PFIzyuftQkz/pvXOzP7l78vf8CcJjrvFH0mvfgksfgcM+75dRsR4W/NEHgqRUf2XF2Mn+sxO+HnulvvqaDz7ZA+C0m33ZpK/4jnd/jvRFpE9QcAByYgUH8PnsYcf5ny/6nQ8CS2f5spNu9GmMrUt8Z9v/UJ/H37LYH/EXfw6Ouspfc778ZX/NdOmn/qqec34J/Q/ZfVmn/3jP1ynnDYPJP/Vf8Wo/f9jn66BFpO9RcACSgwEyUoLRwaGtQBAueRi+EN5zJzvpP2OXH3lZx41Qxy0ivYh6pIjc9OS9B4cW6sRFpA9QTxeRm55MRW0cwUFEpA9QcIgYkJPGlqoeeEyviMgBQMEhYlhBOuvLFBxEREDBYZdh+RlU1jVRVa/UkoiIgkPEsAJ/Z+0GjR5ERBQcWgzN94/oXl9em+CWiIgknoJDxLB8P3JYX6bgICKi4BCRl5FMVmoSG8qVVhIRUXCIMDOG5qdTopGDiEh8wcHMhpnZX82s0syqzOwZMxsex3Q/NTO3h6/6dnXX7qHe5/dx3TptdFEWq0qrO64oInKQ6/DZSmaWAbwONADX4N/KfTvwhpkd6Zyr2cvkDwP/bFeWGSmbFaP+y8BP25Ut66iNXWVM/yxe+ngz9U0h0pIT/AYsEZEEiufBe9cBo4DxzrmVAGa2GFgBfA24e08TOuc2ABvalpnZ1Mhyp8eYZLtzbl58Te964wZk4xys3FbN4UNyE9UMEZGEiyetNAWY1xIYAJxza4C5wMX7sMxrgK34UUKvMm5AFgArtu3soKaIyMEtnuBwGPBxjPIlwITOLMzMhgKnA08455pjVLnIzGrNrMHM5vXk+QaA4sJMkoPG8q067yAifVs8waEAKI9RXgbkd3J5UyPLjJVSeh64ETgHuAqoB541s6v3NDMzu97MFpjZgtLS0k42JVpyMMDIwkxWbNXIQUT6tnhf9uNilO3LuyanAYucc4ujFuDcjbvN3OxZYB7wK+DxmI1y7iHgIYBJkybFamOnHTY4l7dXbe+KWYmIHLDiGTmU40cP7eUTe0QRk5kdBxxC7FFDFOdcCPgLMNTMBsW7nP01cWguW6sa2Fypm+FEpO+KJzgswZ93aG8CsLQTy7oGaAae7MQ0LaOTLhkVxOOo4T5T9kFJRU8tUkSk14knOMwCTjCzUS0FZlYMfJbY9ypEMbMU4ArgJedcXCcHzCwJuAwocc5tiWearnDooGxSggE+2FDRU4sUEel14gkOfwDWAs+Z2cVmNgV4DlgPPNhSycxGmFmzmd0aYx4X4lNTMVNKZvZlM5tpZtPM7HQzuwJ4AzgG+EGn1mg/pSYFOXRwDos0chCRPqzD4BC5A/oMYDkwA3gCWAOc4Zxre82nAcE9zPMa/NVNL+xhMWuA/sBvgFfwQacBONc5NzOuNelCx47I54P1FdQ3hXp60SIivUJcVys550qASzqos5Y9XMHknNvrzXKRu6LPiKctPeH4Uf14+N9r+HB9BceP6pfo5oiI9Dg9lTWG44oLMIN315QluikiIgmh4BBDbkYyhwzM4Z1VOxLdFBGRhFBw2IPTxxfx3toyymsaE90UEZEep+CwB+cfMYhQ2PHq0q2JboqISI9TcNiDwwbnMKwgnecXb0p0U0REepyCwx6YGZcePYx/rdjOsi16EJ+I9C0KDnsx7cQRpCcHefCtVYluiohIj1Jw2Iv8zBS+dOwwXvhwM9urGxLdHBGRHqPg0IGrTxhOYyjM0wvWJ7opIiI9RsGhA2P6Z3PS6H48OnctO+ubEt0cEZEeoeAQh++fewil1Q3c8+qKRDdFRKRHKDjE4ahheVxx7HAee2ct68tqE90cEZFup+AQp29PHkswYPy/V5YluikiIt1OwSFOA3LSuP6UUfz9g008OndNopsjItKtFBw64duTx3HWhAH8/IWlvL1qe6KbIyLSbRQcOiEYMO750lGMLMzk/zy1iC2V9YlukohIt1Bw6KSs1CQenHoMtY0hvvHEQhqbw4lukohIl1Nw2Adj+mfzm0sn8n5JBbfN+hjnXKKbJCLSpeJ6TahEu+DIQXy8aTT3z1lFwIzbP384ZjHfkioicsBRcNgP3z9nPM7BA2+uojArlf971rhEN0lEpEsoOOwHM+MH546ndGcDv31tBevLarnhjDGMLspKdNNERPaLzjnsJzPjzkuP5Junj+H5xZs45563mPHOWp2HEJEDmoJDFwgGjO+dM563bz6TU8cVcctzS/jO0x+yZntNopsmIrJPFBy6UFF2Kn+YNon/c+ZYnv9wE5PvfpPfzl5Bc0iXu4rIgUXBoYsFAsZ3zhrH2z88g4uOHMQ9s5dz6QPv8O7qHYlumohI3BQcukn/7DTuveIz/PaKo9hQXseXHprHVQ/PY1VpdaKbJiLSITtYTpxOmjTJLViwINHNiKmuMcST75Xwu9dWUNcU4vJJQznv8EGcOKofgYDujRCRxDGzhc65SVHlCg49Z1tVPXe/upy/vb+BppBjVFEmv7l0IseMyE9000Skj1Jw6EVqG5uZ/ck2fvPyp2yqqOfcwwdy+OBcctKTmDJxMNlpyYluooj0EQoOvVBlXRP3vbaCZxdtZEdNIwCFWankpCdx8phCrjhuOIcOyklwK0XkYKbg0MvVNjazZFMVD765mlA4zNyVO2gMhbngiEH85MJDGZSbnugmishBaE/BQY/P6CUyUpI4triAY4sLACiraeSxd9Zy/5xVvLFsGyePLWRrVQOnjCsiLz2ZU8YVMaa/HtMhIt1DI4debn1ZLb99bQXvrtlBTloySzZVAZCaFGDaiSO4+oQR7Kxvpig7lQE5aQlurYgcaJRWOkisKq3GOcfvXlvJix9tJhRu3X+HDMzmtPH9ueToIYwdkJ3AVorIgULB4SC0ubKO5z7YRGFWKqU7G5izbBsL15UTco6JQ/MIGKSnBDlxVD/OOWwgIwszSQrqvkcRaaXg0EeU1TTy6Nw1LFhXjhlU1TXz0cZKAIbkpTMkL51AAD4zPJ/c9GRGFmYytn8WuenJ9MtKTXDrRaSn6YR0H1GQmcJ3zh6/W9nq0mreL6ngqfdKqGlspjnk+MNbq2luk5IKGEw+dAD/+bmR1DeFKMpOpSg7lazUJAwjPSXY06siIgmk4NAHjCrKYlRRFpceM3RXmXOOuqYQH5RUsLmyntXbq3n4X2t4ZenWmPMYkpfOSaP7UV7bxHEj8zl6eD6rS2s45/CBJAeNjBT9KYkcTJRWkl3W7ahh2ZadFGSmsL26gdKdDdQ0hgiFHW8tL2Xp5iqKslNZXRr9norCrFRGFWUyqjCTUUWZDMnLwAwG5qYxvCCDfpkpNIbCpCZpBCLSmyitJB0a0S+TEf0yY352w+ljdv384foKlmyqYnRRJu+uKSMYMNbtqGHN9hpeXbp1193ebSUFjOawIyctiYnD8jAzctKSOGpYHtlpSTSGHOGwY+yALLJTk2kMhQk7xxFDcklLVkAR6WkKDtJpE4flMXFYHgDHj+oX9XllbRObKutwzl9RVVJWy9aqBjJSgmyurOPD9ZUkB41V26p5YfHmvS5rWEE6xxYXEAo7mkJhtlTWc/iQXK4/ZRRmRjjsGJqfjpmebivSlZRWkoTaVlVPc9iRHAzgcCzdVEVTyJEcNGobQzz41mp2VDeQFDCSggHyM5L5YH0FYceuezyK+2VQ1xQiYMahg3IImLG5so5gwBiQk0Z2ahKj+2eRl5FMXnoKzWH/Zr6jh+czKDeN2qYQKcEAqUkBtlTVU1XXzPiBuk9E+gallaRX6t/uru7+43f//fwjBkVNs6mijiffLSEzNYmstCReXLyJzJQkggFjc6UPNoVZKTSFwqwvq2VHTSPPLNoYc/lmEOv46OSxhTQ2h6msa+LcwwfS0BzmzWWlDM1PJzU5yKjCTE4eW0h9U5ikoPHYO2uZdmIxGSlBRhVlsaG8luEFGWyqqGdofvpuqbFQ2BEwNNqRXi2ukYOZDQPuAc4CDJgNfNs5V9LBdD8FbtvDxw3OubQ2dQPAD4CvAQOBZcDPnXN/63g1NHKQvatvClFZ10RFbRNm0BQK8/66crbtbCA3PZmG5jCNzWEyU4OU1zbxj482U5CZQsCMBevKATi2OJ/Kuibqm8JsKK8lHOegOyUpwNHD8zi2uICtVfU8u2gjE4fmcfiQXF77dCsTh+aRlhxkZGEmjc1hUpMDrCmtITc9mcF56TSFwuRnpnDIwGzG9s/edVlxcyhMeW0TGyvqKK9tZHhBBkPz03EOnaeRuO3zTXBmlgF8CDQAPwEccDuQARzpnIu+dKV12qHA0HbFmcA/gWedc5e3qfsL4HvAj4GFwBXAdcCFzrmXOlpBBQfpLlX1TdQ1hnZ7dlXpzgYWrisjNTnI6tIazjp0AG8u30ZOejKrSmsYlp9OSVktQ/LSWbmtmndW72Dp5irSkoJMnjCAD9aXs62qgYlD8/hgQwWpSQF21jfvGslkpyXR0BSmMRTerS1mMKIgg8KsVJZt3cnO+uaoz1OCAYbkpxMwI2hGaXUDhwzMxsyPWrJSk6lraub4kf58UVlNI5V1TZw4qh9JQaO6oZktlfUkBwPkpCezZGMlVfXNXHjkIMb0z2LdjlpOHV/Eh+srSE8JUl7TSCjsGDcgm+EFGbz40WaOGZHPym3VjOmfRWZqEgGDmoYQ/bJSSNZd+r3K/gSHbwF3A+OdcysjZSOBFcD3nXN3d7IhU4HH8J3+i5Gy/sB64A7n3G1t6r4GFDnnjuxovgoO0tvVN4VITQpEpZPqGkOkJAXYWF5HTrrP9GamJhEKO+qbQiQHA2ytqmf51p0s21LNsq1VVNQ2MTQ/ncOH5NI/O5Wi7DSWbqqktLqRqromtlTW0xgK09AcYmBOOmu2V9Pyn94SUFZu8+8zT08Okp4SpKzNVWbBgBF2Duegf3YqycEAGyvqdn2ekRKktjEUtY5D8tLZWFFHwCDs/HzaPv8rLyOZUYWZDMxNY0d1I5mpSRw+JJequibeLyknPTmIczB2QBaDctN4b205mSlBjhyaRzAAi0p8QDp6eD4VtY00hRxh50gKBFhZWs3hg3MY0S+DMf2z2FxZz/Kt1YwqymRwbjpzlm0jKRjg5LGFjO2fRXPYUdsYIjc9+uVa4bBjc1U9g3LSCETWobq+mZz0pH1KBzY0h0gKBAj2wtcC709weA1Ic859tl35mwDOuVM72ZDZwOHAUOdcc6SsJWCMc86taFP3P4A/AaOcc2v2Nl8FB5HOqWsMkRz0J/pDYcfaHTUkBfzd8EVZqTSFHBV1jRRlpeIcvF9SzsaKOpICAf7479VcPmkY/bJS6Zfl02/vrdnBzPnr+fxRQ1i7vYZJxQWsL68lKzWJ5KCRnhxk0foKtlbVs6G8jryMFGobmllZWk1aUpCJw3KpbmjGOVi6uQrn4LDBOVQ3NLNuRy0AQ/PTqahtorrBB7iWczehsKMo2z9jLB55GclU1TURdjBhUA4rt1UzYXAOpTsbKC7M4JPNOymraaQwKwXwo6uwg6zUJMYN8DeVvr+unBH9Mmho9mm/HdUNjCzMoqquiaWbq+iXmcKmijpSk4Nsqqijf04q5x0+iNc/3cb26gZ/6XhBBqOLsqhtbKa2McS4gdkYsKG8jrrGZnLSk3dtr+tOHkXYOf69cjunjisiJRigMDuVTzZXcfFRQ/b572B/gsMW4Dnn3Nfalf8vcJlzrqgTjRgKrAPudc59t035HcC3gXTXpkFmdhzwLm1GGXui4CByYKprDJEUtN3STQvXlQG26/3q5TWNhJyjMCuVqvomymsaGZCThnNQ1xSipqGZYQUZVNY2sWZHDet21JCTlszhQ3L5aGMFq0trmDJxMGEHr3+6jcUbKuifnUpjyPHOqu0cMjCHT7fuZHBuGmu21zBhUA6HDcllycZK0lKCFGamkJ2WzPryWj7dvJPl23YyYVAO68tryc9IYUd1IwWZKSzfupP8jBSOGpbH1p31PrACRdmpLNlUxZKNlYwbkM3EYXmUlNWwdnstmyrrSA74q+V2RoJeSzCtaQwRNKMwK4VNlfV73Ibv33IWBZkp+7T99+dqpQKgPEZ5GZDfyXZMBQLA9BjLqHDRkaqszedRzOx64HqA4cOHd7IpItIbxHpu1zEjdv+Xz2/T8eWkJZPT5j3r6SnBXR1jbkYyR2XkcVTkPhyAMw4ZwBmHtM7ryuOHc+Xx3dNfNIXCJAVsj6kn51zUZ7WNzQTMSE0KsLmynrBzDMnz9+5U1jYRco6s1CT+snA9G8vrmHZiMau3V9PYHKZ0ZwOTigvIz+j6987HeylrrOHFviTPpgGLnHOLY8yr08twzj0EPAR+5LAP7RER6TIdnWyPFTTaPpdscN7urwPObdPpX3X8iF0/D8zt/hd7xXPZQDmxj9zziT2iiCmSIjqE6FEDREYhFr3l8tt8LiIiPSSe4LAEOCxG+QRgaSeWdQ3QDDy5h2WkAqNjLINOLkdERPZTPMFhFnCCmY1qKTCzYuCzkc86ZGYp+PsWXnLOlcao8k+gEbiqXfnVwMcdXakkIiJdK57g8AdgLfCcmV1sZlOA5/D3JTzYUsnMRphZs5ndGmMeF+JTU7FSSjjntuHvwP6hmX3HzE4zs/uBM4AfdWaFRERk/3V4Qto5V2NmZ+A77xn4k8Sv4R+fUd2mqgFBYgeca/DnDV7Yy6J+DFQD36L18RmXO+eej2M9RESkC+mprCIifdie7nPQQ05ERCSKgoOIiEQ5aNJKZlaKfzRHZxUC27u4ObL/tF96H+2T3ml/98uIWI9BOmiCw74yswWx8m2SWNovvY/2Se/UXftFaSUREYmi4CAiIlEUHCIP7pNeR/ul99E+6Z26Zb/0+XMOIiISTSMHERGJouAgIiJR+mRwMLNhZvZXM6s0syoze8bM9Cq5bmBmQ83sPjN7x8xqzcxFnurbvl6+mT1sZtvNrMbMZpvZETHqpZnZb8xss5nVReZ7So+szEHCzC41s7+Z2brINlxmZr8ys+x29bRPepCZnWNmr5vZFjNrMLMNZva0mU1oV69H9kufCw5mlgG8jn/x0DX4V5eOBd4ws8xEtu0gNQa4HP9iqH/FqhB5ydMs4FzgRuASIBm/T4a2q/5H4DrgVvzTfjcDL5vZUd3R+IPU94AQ/onH5wL3A18HXjWzAGifJEgBsBD4JnA28EP8u3TmmdkI6OH94pzrU1/4p76GgDFtykbiX0T0nUS372D7AgJtfv4q/nWwxe3qXBwpP71NWS7+Sb6/a1M2MVLvP9qUJeGf4Dsr0et6oHwBRTHKpkW27RnaJ73nCxgf2b7f7en90udGDsAUYJ5zbmVLgfMvE5qL3/DShZxz4TiqTQE2OefeaDNdJfA8u++TKUAT8Oc29ZqBmcA5ZpbaJY0+yLnYL9yaH/k+JPJd+6R32BH53hT53mP7pS8Gh8OAj2OUL6H1taTSs/a2T4abWVabemucc7Ux6qXgU1iyb06NfP8k8l37JEHMLGhmKWY2Fv9CtS34Th16cL/0xeBQgM9/t1cG5PdwW8Tb2z6B1v3SUb2CLm5Xn2BmQ4CfA7Odcy0vRdE+SZx3gQZgOXAkPtW3LfJZj+2XvhgcwOfi2rMeb4W0MOLbJ/HWkzhFjjSfw59z+4+2H6F9kihTgROAK4Eq/IUCxZHPemy/9MXgUE7sqJlP7Egr3a+MPe8TaN0vHdUri/GZ7IGZpeGvfBkFnOOc29DmY+2TBHHOfeKce9c59xRwJpAF3Bz5uMf2S18MDkvw+bj2JgBLe7gt4u1tn5S41neVLwFGRi5Hbl+vEViJxMXMkoG/AccB5zvnPmpXRfukF3DOVeC3Ycs5gh7bL30xOMwCTjCzUS0FkSHbZyOfSc+bBQwxs5aTophZDnARu++TWfhrui9rUy8J+BLwinOuoWeae2CL3MvwBP6o9GLn3LwY1bRPegEzG4C/J2tVpKjH9kufe/Be5Ea3D4E64Cf4vNx/A9nAkW0ir3QRM7s08uOZwH8B3wBKgVLn3JuRzurfwDDgJvzQ+If4k3ETnXPr28xrJnBOpN4a/M1bFwInOefe75k1OrCZ2f34/fAL4IV2H29wzm3QPul5ZvYs8D6wGH+uYRzwf4GBwHHOueU9ul8SfZNHgm4sGY4fUlcBO4G/0+7GLH116fZ2e/ia06ZOAfAnfC60Fngt8sfefl7pwN34y/vq8Vd2nJbodTyQvoC1e9knP9U+Sdh++QH+DumKyPZehr+UtbhdvR7ZL31u5CAiIh3ri+ccRESkAwoOIiISRcFBRESiKDiIiEgUBQcREYmi4CAiIlEUHER6OTNba2aPJ7od0rcoOIiISBQFBxERiaLgINKGmU00s1lmVm5mdWY218xObvP5o2a2wcxOMrP5ZlYfSfvcGGNex5nZbDOrNrMaM3vNzI6LUe9UM3vVzCoj9T40s6/EqHeFmX0SqbPAzD7X9VtAxFNwEIkws6OBt/HPrrkOuAT/Dt/ZZnZMm6o5+HfzTgc+D8wBfmdm17aZ15HAm/jn518LTItM96aZTWxT72L8s3FSgK/h3wP8J2BEu+adDHwXuAX/ZM0g8IKZ5e3naovEpGcriUSY2WvAYPxDzBojZUH8O3uXOec+b2aPAtcAX3bOzWwz7av4p2gWO+ecmf0VmBz5vSJSJwf/0Ls5zrkvmpnhn5a5Hf/UzfAe2rUWyAVGOefKI2WTgPnAVc65J7t0Q4igkYMIAGaWDpwK/AUIm1lS5Pn3BswGTmlTPYR/qm9bM/FP+x0S+f0U4IWWwADgnKvCP2e/5Vn84/EjhIf3FBjaeKclMES0vJxneMdrJ9J5Cg4iXgE+VXML0NTu65tAfuRZ+gDlzrmmdtNvjXxvCQ4FwOYYy9lC66sa+0W+b4hRr73dXuvoWl/WkhbHtCKdlpToBoj0EhVAGPgf4LFYFZxzYZ8JIt/MktsFiAGR7xsj38vwL2lpbyCtHf32yPchMeqJJJSCgwjgnKsxs38BE4H3O0jzBPEnq2e2KbsCKKE1OLwJXGBm2c65nQBmlo1/neOcSJ3l+HMQXzWzh5xOAEovouAg0uo7wFvAy2b2R3xaqBA4Ggg6526O1NsJ3GlmhcAK4Mv4k8/Xtung/xv/SsbXzOzX+Les/QDIAH4OEDlx/W3gGeB1M3sA//rUQ4H+zrnbunl9RfZI5xxEIpx/r+6x+MtXfwe8AvwWOAIfNFpU4UcK1wDPAacD33LOTW8zr8XAaZG604EZQDVwqnPuwzb1ngPOivz6R/wJ6+vxIwqRhNGlrCKdELmUdbJzbmii2yLSnTRyEBGRKAoOIiISRWklERGJopGDiIhEUXAQEZEoCg4iIhJFwUFERKIoOIiISJT/Dz45npKL7l2PAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "\n",
    "plt.savefig(figure_path + '/ml-10m-medium-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Plot decreasing learning rate\n",
    "\n",
    "#_ = plt.plot(lr_history[:2*iterations_per_epoch-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8755\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.8752\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "with open('best.weights.medium', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 1121.4686\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# big net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=50, hidden=[100, 100, 100],\n",
    "    embedding_dropout=0.05, dropouts=[0.3, 0.3, 0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "#iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "#scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.7883 - val: 0.7387\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7133 - val: 0.7173\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.6867 - val: 0.7073\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.6664 - val: 0.7017\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.6484 - val: 0.6974\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.6326 - val: 0.6968\n",
      "[007/300] train: 0.6177 - val: 0.6975\n",
      "[008/300] train: 0.6046 - val: 0.6977\n",
      "[009/300] train: 0.5933 - val: 0.6984\n",
      "[010/300] train: 0.5833 - val: 0.7004\n",
      "[011/300] train: 0.5743 - val: 0.7023\n",
      "[012/300] train: 0.5665 - val: 0.7090\n",
      "[013/300] train: 0.5594 - val: 0.7048\n",
      "[014/300] train: 0.5532 - val: 0.7081\n",
      "[015/300] train: 0.5473 - val: 0.7108\n",
      "[016/300] train: 0.5419 - val: 0.7143\n",
      "[017/300] train: 0.5369 - val: 0.7157\n",
      "[018/300] train: 0.5328 - val: 0.7152\n",
      "[019/300] train: 0.5287 - val: 0.7198\n",
      "[020/300] train: 0.5247 - val: 0.7172\n",
      "[021/300] train: 0.5211 - val: 0.7216\n",
      "[022/300] train: 0.5180 - val: 0.7194\n",
      "[023/300] train: 0.5148 - val: 0.7218\n",
      "[024/300] train: 0.5119 - val: 0.7239\n",
      "[025/300] train: 0.5094 - val: 0.7257\n",
      "[026/300] train: 0.5067 - val: 0.7263\n",
      "[027/300] train: 0.5039 - val: 0.7272\n",
      "[028/300] train: 0.5020 - val: 0.7288\n",
      "[029/300] train: 0.4998 - val: 0.7335\n",
      "[030/300] train: 0.4974 - val: 0.7339\n",
      "[031/300] train: 0.4955 - val: 0.7357\n",
      "[032/300] train: 0.4935 - val: 0.7379\n",
      "[033/300] train: 0.4917 - val: 0.7385\n",
      "[034/300] train: 0.4902 - val: 0.7333\n",
      "[035/300] train: 0.4886 - val: 0.7372\n",
      "[036/300] train: 0.4871 - val: 0.7384\n",
      "[037/300] train: 0.4854 - val: 0.7390\n",
      "[038/300] train: 0.4838 - val: 0.7386\n",
      "[039/300] train: 0.4828 - val: 0.7372\n",
      "[040/300] train: 0.4815 - val: 0.7422\n",
      "[041/300] train: 0.4800 - val: 0.7465\n",
      "[042/300] train: 0.4788 - val: 0.7399\n",
      "[043/300] train: 0.4777 - val: 0.7422\n",
      "[044/300] train: 0.4768 - val: 0.7465\n",
      "[045/300] train: 0.4755 - val: 0.7465\n",
      "[046/300] train: 0.4745 - val: 0.7472\n",
      "[047/300] train: 0.4735 - val: 0.7486\n",
      "[048/300] train: 0.4725 - val: 0.7479\n",
      "[049/300] train: 0.4717 - val: 0.7464\n",
      "[050/300] train: 0.4708 - val: 0.7499\n",
      "[051/300] train: 0.4697 - val: 0.7463\n",
      "[052/300] train: 0.4690 - val: 0.7477\n",
      "[053/300] train: 0.4680 - val: 0.7488\n",
      "[054/300] train: 0.4676 - val: 0.7543\n",
      "[055/300] train: 0.4666 - val: 0.7483\n",
      "[056/300] train: 0.4660 - val: 0.7510\n",
      "[057/300] train: 0.4650 - val: 0.7519\n",
      "[058/300] train: 0.4642 - val: 0.7492\n",
      "[059/300] train: 0.4638 - val: 0.7501\n",
      "[060/300] train: 0.4633 - val: 0.7567\n",
      "[061/300] train: 0.4625 - val: 0.7496\n",
      "[062/300] train: 0.4617 - val: 0.7505\n",
      "[063/300] train: 0.4615 - val: 0.7520\n",
      "[064/300] train: 0.4606 - val: 0.7576\n",
      "[065/300] train: 0.4600 - val: 0.7551\n",
      "[066/300] train: 0.4592 - val: 0.7456\n",
      "[067/300] train: 0.4591 - val: 0.7540\n",
      "[068/300] train: 0.4586 - val: 0.7538\n",
      "[069/300] train: 0.4579 - val: 0.7524\n",
      "[070/300] train: 0.4574 - val: 0.7511\n",
      "[071/300] train: 0.4571 - val: 0.7624\n",
      "[072/300] train: 0.4563 - val: 0.7569\n",
      "[073/300] train: 0.4559 - val: 0.7585\n",
      "[074/300] train: 0.4559 - val: 0.7577\n",
      "[075/300] train: 0.4552 - val: 0.7611\n",
      "[076/300] train: 0.4545 - val: 0.7599\n",
      "[077/300] train: 0.4544 - val: 0.7605\n",
      "[078/300] train: 0.4535 - val: 0.7569\n",
      "[079/300] train: 0.4538 - val: 0.7548\n",
      "[080/300] train: 0.4533 - val: 0.7553\n",
      "[081/300] train: 0.4522 - val: 0.7645\n",
      "[082/300] train: 0.4522 - val: 0.7598\n",
      "[083/300] train: 0.4520 - val: 0.7610\n",
      "[084/300] train: 0.4513 - val: 0.7673\n",
      "[085/300] train: 0.4509 - val: 0.7595\n",
      "[086/300] train: 0.4507 - val: 0.7534\n",
      "[087/300] train: 0.4508 - val: 0.7655\n",
      "[088/300] train: 0.4500 - val: 0.7640\n",
      "[089/300] train: 0.4497 - val: 0.7630\n",
      "[090/300] train: 0.4495 - val: 0.7593\n",
      "[091/300] train: 0.4488 - val: 0.7648\n",
      "[092/300] train: 0.4487 - val: 0.7604\n",
      "[093/300] train: 0.4483 - val: 0.7657\n",
      "[094/300] train: 0.4479 - val: 0.7626\n",
      "[095/300] train: 0.4475 - val: 0.7683\n",
      "[096/300] train: 0.4477 - val: 0.7586\n",
      "[097/300] train: 0.4477 - val: 0.7640\n",
      "[098/300] train: 0.4469 - val: 0.7689\n",
      "[099/300] train: 0.4469 - val: 0.7647\n",
      "[100/300] train: 0.4467 - val: 0.7634\n",
      "[101/300] train: 0.4462 - val: 0.7650\n",
      "[102/300] train: 0.4460 - val: 0.7606\n",
      "[103/300] train: 0.4456 - val: 0.7610\n",
      "[104/300] train: 0.4454 - val: 0.7627\n",
      "[105/300] train: 0.4453 - val: 0.7667\n",
      "[106/300] train: 0.4448 - val: 0.7596\n",
      "[107/300] train: 0.4446 - val: 0.7602\n",
      "[108/300] train: 0.4443 - val: 0.7661\n",
      "[109/300] train: 0.4441 - val: 0.7671\n",
      "[110/300] train: 0.4442 - val: 0.7697\n",
      "[111/300] train: 0.4436 - val: 0.7639\n",
      "[112/300] train: 0.4437 - val: 0.7674\n",
      "[113/300] train: 0.4434 - val: 0.7684\n",
      "[114/300] train: 0.4430 - val: 0.7613\n",
      "[115/300] train: 0.4429 - val: 0.7635\n",
      "[116/300] train: 0.4424 - val: 0.7684\n",
      "[117/300] train: 0.4423 - val: 0.7688\n",
      "[118/300] train: 0.4423 - val: 0.7711\n",
      "[119/300] train: 0.4418 - val: 0.7619\n",
      "[120/300] train: 0.4418 - val: 0.7624\n",
      "[121/300] train: 0.4417 - val: 0.7689\n",
      "[122/300] train: 0.4413 - val: 0.7638\n",
      "[123/300] train: 0.4413 - val: 0.7661\n",
      "[124/300] train: 0.4409 - val: 0.7641\n",
      "[125/300] train: 0.4408 - val: 0.7676\n",
      "[126/300] train: 0.4407 - val: 0.7732\n",
      "[127/300] train: 0.4403 - val: 0.7725\n",
      "[128/300] train: 0.4402 - val: 0.7693\n",
      "[129/300] train: 0.4401 - val: 0.7740\n",
      "[130/300] train: 0.4396 - val: 0.7726\n",
      "[131/300] train: 0.4397 - val: 0.7724\n",
      "[132/300] train: 0.4396 - val: 0.7652\n",
      "[133/300] train: 0.4391 - val: 0.7674\n",
      "[134/300] train: 0.4391 - val: 0.7717\n",
      "[135/300] train: 0.4388 - val: 0.7730\n",
      "[136/300] train: 0.4391 - val: 0.7704\n",
      "[137/300] train: 0.4387 - val: 0.7638\n",
      "[138/300] train: 0.4387 - val: 0.7655\n",
      "[139/300] train: 0.4383 - val: 0.7732\n",
      "[140/300] train: 0.4381 - val: 0.7639\n",
      "[141/300] train: 0.4381 - val: 0.7672\n",
      "[142/300] train: 0.4379 - val: 0.7712\n",
      "[143/300] train: 0.4376 - val: 0.7685\n",
      "[144/300] train: 0.4377 - val: 0.7594\n",
      "[145/300] train: 0.4376 - val: 0.7716\n",
      "[146/300] train: 0.4374 - val: 0.7697\n",
      "[147/300] train: 0.4371 - val: 0.7680\n",
      "[148/300] train: 0.4368 - val: 0.7702\n",
      "[149/300] train: 0.4368 - val: 0.7738\n",
      "[150/300] train: 0.4365 - val: 0.7625\n",
      "[151/300] train: 0.4364 - val: 0.7690\n",
      "[152/300] train: 0.4365 - val: 0.7769\n",
      "[153/300] train: 0.4361 - val: 0.7751\n",
      "[154/300] train: 0.4359 - val: 0.7748\n",
      "[155/300] train: 0.4358 - val: 0.7754\n",
      "[156/300] train: 0.4361 - val: 0.7685\n",
      "[157/300] train: 0.4358 - val: 0.7719\n",
      "[158/300] train: 0.4357 - val: 0.7696\n",
      "[159/300] train: 0.4353 - val: 0.7798\n",
      "[160/300] train: 0.4353 - val: 0.7707\n",
      "[161/300] train: 0.4352 - val: 0.7678\n",
      "[162/300] train: 0.4353 - val: 0.7650\n",
      "[163/300] train: 0.4353 - val: 0.7751\n",
      "[164/300] train: 0.4350 - val: 0.7725\n",
      "[165/300] train: 0.4348 - val: 0.7644\n",
      "[166/300] train: 0.4345 - val: 0.7702\n",
      "[167/300] train: 0.4343 - val: 0.7717\n",
      "[168/300] train: 0.4345 - val: 0.7778\n",
      "[169/300] train: 0.4344 - val: 0.7669\n",
      "[170/300] train: 0.4341 - val: 0.7709\n",
      "[171/300] train: 0.4341 - val: 0.7722\n",
      "[172/300] train: 0.4340 - val: 0.7812\n",
      "[173/300] train: 0.4340 - val: 0.7733\n",
      "[174/300] train: 0.4339 - val: 0.7781\n",
      "[175/300] train: 0.4337 - val: 0.7660\n",
      "[176/300] train: 0.4333 - val: 0.7737\n",
      "[177/300] train: 0.4333 - val: 0.7728\n",
      "[178/300] train: 0.4334 - val: 0.7728\n",
      "[179/300] train: 0.4331 - val: 0.7911\n",
      "[180/300] train: 0.4331 - val: 0.7682\n",
      "[181/300] train: 0.4331 - val: 0.7707\n",
      "[182/300] train: 0.4330 - val: 0.7659\n",
      "[183/300] train: 0.4329 - val: 0.7798\n",
      "[184/300] train: 0.4322 - val: 0.7673\n",
      "[185/300] train: 0.4325 - val: 0.7776\n",
      "[186/300] train: 0.4324 - val: 0.7726\n",
      "[187/300] train: 0.4324 - val: 0.7747\n",
      "[188/300] train: 0.4319 - val: 0.7701\n",
      "[189/300] train: 0.4322 - val: 0.7777\n",
      "[190/300] train: 0.4322 - val: 0.7751\n",
      "[191/300] train: 0.4317 - val: 0.7793\n",
      "[192/300] train: 0.4319 - val: 0.7692\n",
      "[193/300] train: 0.4315 - val: 0.7694\n",
      "[194/300] train: 0.4316 - val: 0.7740\n",
      "[195/300] train: 0.4313 - val: 0.7685\n",
      "[196/300] train: 0.4318 - val: 0.7803\n",
      "[197/300] train: 0.4311 - val: 0.7803\n",
      "[198/300] train: 0.4313 - val: 0.7722\n",
      "[199/300] train: 0.4311 - val: 0.7791\n",
      "[200/300] train: 0.4312 - val: 0.7763\n",
      "[201/300] train: 0.4309 - val: 0.7736\n",
      "[202/300] train: 0.4309 - val: 0.7661\n",
      "[203/300] train: 0.4308 - val: 0.7765\n",
      "[204/300] train: 0.4310 - val: 0.7736\n",
      "[205/300] train: 0.4308 - val: 0.7751\n",
      "[206/300] train: 0.4308 - val: 0.7733\n",
      "[207/300] train: 0.4306 - val: 0.7774\n",
      "[208/300] train: 0.4306 - val: 0.7739\n",
      "[209/300] train: 0.4304 - val: 0.7700\n",
      "[210/300] train: 0.4302 - val: 0.7782\n",
      "[211/300] train: 0.4299 - val: 0.7823\n",
      "[212/300] train: 0.4303 - val: 0.7721\n",
      "[213/300] train: 0.4299 - val: 0.7770\n",
      "[214/300] train: 0.4300 - val: 0.7741\n",
      "[215/300] train: 0.4298 - val: 0.7808\n",
      "[216/300] train: 0.4297 - val: 0.7761\n",
      "[217/300] train: 0.4298 - val: 0.7761\n",
      "[218/300] train: 0.4293 - val: 0.7764\n",
      "[219/300] train: 0.4296 - val: 0.7781\n",
      "[220/300] train: 0.4295 - val: 0.7767\n",
      "[221/300] train: 0.4295 - val: 0.7706\n",
      "[222/300] train: 0.4295 - val: 0.7828\n",
      "[223/300] train: 0.4292 - val: 0.7752\n",
      "[224/300] train: 0.4292 - val: 0.7680\n",
      "[225/300] train: 0.4293 - val: 0.7765\n",
      "[226/300] train: 0.4292 - val: 0.7746\n",
      "[227/300] train: 0.4290 - val: 0.7737\n",
      "[228/300] train: 0.4289 - val: 0.7733\n",
      "[229/300] train: 0.4289 - val: 0.7800\n",
      "[230/300] train: 0.4287 - val: 0.7751\n",
      "[231/300] train: 0.4285 - val: 0.7752\n",
      "[232/300] train: 0.4286 - val: 0.7763\n",
      "[233/300] train: 0.4284 - val: 0.7775\n",
      "[234/300] train: 0.4286 - val: 0.7745\n",
      "[235/300] train: 0.4284 - val: 0.7714\n",
      "[236/300] train: 0.4283 - val: 0.7737\n",
      "[237/300] train: 0.4280 - val: 0.7746\n",
      "[238/300] train: 0.4278 - val: 0.7697\n",
      "[239/300] train: 0.4280 - val: 0.7705\n",
      "[240/300] train: 0.4278 - val: 0.7709\n",
      "[241/300] train: 0.4283 - val: 0.7735\n",
      "[242/300] train: 0.4281 - val: 0.7728\n",
      "[243/300] train: 0.4276 - val: 0.7746\n",
      "[244/300] train: 0.4278 - val: 0.7796\n",
      "[245/300] train: 0.4280 - val: 0.7819\n",
      "[246/300] train: 0.4277 - val: 0.7788\n",
      "[247/300] train: 0.4275 - val: 0.7801\n",
      "[248/300] train: 0.4276 - val: 0.7788\n",
      "[249/300] train: 0.4275 - val: 0.7804\n",
      "[250/300] train: 0.4274 - val: 0.7710\n",
      "[251/300] train: 0.4271 - val: 0.7782\n",
      "[252/300] train: 0.4272 - val: 0.7723\n",
      "[253/300] train: 0.4271 - val: 0.7725\n",
      "[254/300] train: 0.4273 - val: 0.7724\n",
      "[255/300] train: 0.4271 - val: 0.7793\n",
      "[256/300] train: 0.4272 - val: 0.7761\n",
      "[257/300] train: 0.4269 - val: 0.7853\n",
      "[258/300] train: 0.4268 - val: 0.7847\n",
      "[259/300] train: 0.4268 - val: 0.7828\n",
      "[260/300] train: 0.4270 - val: 0.7843\n",
      "[261/300] train: 0.4269 - val: 0.7747\n",
      "[262/300] train: 0.4267 - val: 0.7693\n",
      "[263/300] train: 0.4264 - val: 0.7800\n",
      "[264/300] train: 0.4268 - val: 0.7803\n",
      "[265/300] train: 0.4264 - val: 0.7740\n",
      "[266/300] train: 0.4269 - val: 0.7789\n",
      "[267/300] train: 0.4263 - val: 0.7778\n",
      "[268/300] train: 0.4263 - val: 0.7706\n",
      "[269/300] train: 0.4262 - val: 0.7787\n",
      "[270/300] train: 0.4262 - val: 0.7726\n",
      "[271/300] train: 0.4260 - val: 0.7818\n",
      "[272/300] train: 0.4262 - val: 0.7764\n",
      "[273/300] train: 0.4262 - val: 0.7769\n",
      "[274/300] train: 0.4261 - val: 0.7733\n",
      "[275/300] train: 0.4258 - val: 0.7810\n",
      "[276/300] train: 0.4260 - val: 0.7877\n",
      "[277/300] train: 0.4258 - val: 0.7738\n",
      "[278/300] train: 0.4260 - val: 0.7835\n",
      "[279/300] train: 0.4260 - val: 0.7707\n",
      "[280/300] train: 0.4256 - val: 0.7743\n",
      "[281/300] train: 0.4257 - val: 0.7803\n",
      "[282/300] train: 0.4255 - val: 0.7775\n",
      "[283/300] train: 0.4256 - val: 0.7792\n",
      "[284/300] train: 0.4254 - val: 0.7766\n",
      "[285/300] train: 0.4254 - val: 0.7730\n",
      "[286/300] train: 0.4256 - val: 0.7754\n",
      "[287/300] train: 0.4258 - val: 0.7820\n",
      "[288/300] train: 0.4252 - val: 0.7782\n",
      "[289/300] train: 0.4252 - val: 0.7710\n",
      "[290/300] train: 0.4254 - val: 0.7812\n",
      "[291/300] train: 0.4253 - val: 0.7881\n",
      "[292/300] train: 0.4253 - val: 0.7827\n",
      "[293/300] train: 0.4250 - val: 0.7735\n",
      "[294/300] train: 0.4255 - val: 0.7734\n",
      "[295/300] train: 0.4254 - val: 0.7829\n",
      "[296/300] train: 0.4251 - val: 0.7756\n",
      "[297/300] train: 0.4251 - val: 0.7779\n",
      "[298/300] train: 0.4251 - val: 0.7835\n",
      "[299/300] train: 0.4249 - val: 0.7762\n",
      "[300/300] train: 0.4245 - val: 0.7784\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "\n",
    "plt.savefig(figure_path + '/ml-10m-large-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Plot decreasing learning rate\n",
    "\n",
    "#_ = plt.plot(lr_history[:2*iterations_per_epoch-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8351\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.8346\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "with open('best.weights.big', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 1723.3963\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f57757a1",
   "language": "python",
   "display_name": "PyCharm (rs-via-gnn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}