{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MovieLens MLN Recommendation via PyTorch\n",
    "\n",
    "adapted from https://github.com/fastai/fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "import time\n",
    "\n",
    "figure_path = '/home/weiss/git/thesis/doc/figures/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)\n",
    "\n",
    "RANDOM_STATE = 2021\n",
    "set_random_seed(RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    files = {}\n",
    "    path = Path(path)\n",
    "    for filename in path.glob('*'):\n",
    "        if filename.suffix == '.csv':\n",
    "            files[filename.stem] = pd.read_csv(filename)\n",
    "        elif filename.suffix == '.dat':\n",
    "            if filename.stem == 'ratings':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "            else:\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "            data = pd.read_csv(filename, sep='::', names=columns, engine='python')\n",
    "            files[filename.stem] = data\n",
    "        elif filename.suffix == '.data':  # ml-100k\n",
    "            if filename.stem == 'u':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "                data = pd.read_csv(filename, sep='\\t', names=columns, engine='python')\n",
    "                files['ratings'] = data\n",
    "        elif filename.suffix == '.item':  # ml-100k\n",
    "            if filename.stem == 'u':\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "                data = pd.read_csv(filename, sep='|', names=columns, engine='python')\n",
    "                files['movies'] = data\n",
    "    return files['ratings'], files['movies']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# pick one of the available folders\n",
    "ratings, movies = read_data('/home/weiss/rs_data/ml-100k')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   userId  movieId  rating  timestamp\n0     196      242       3  881250949\n1     186      302       3  891717742\n2      22      377       1  878887116\n3     244       51       2  880606923\n4     166      346       1  886397596",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n      <td>881250949</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n      <td>891717742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>377</td>\n      <td>1</td>\n      <td>878887116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>51</td>\n      <td>2</td>\n      <td>880606923</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>166</td>\n      <td>346</td>\n      <td>1</td>\n      <td>886397596</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                                                                        movieId  \\\n1 Toy Story (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Toy%20Story%20... 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0        0   \n2 GoldenEye (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?GoldenEye%20(1... 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0        1   \n3 Four Rooms (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Four%20Rooms%2... 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0        1   \n4 Get Shorty (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Get%20Shorty%2... 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0        0   \n5 Copycat (1995)    01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Copycat%20(1995)  0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0        1   \n\n                                                                                                                        title  \\\n1 Toy Story (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Toy%20Story%20... 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0      0   \n2 GoldenEye (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?GoldenEye%20(1... 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0      0   \n3 Four Rooms (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Four%20Rooms%2... 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0      0   \n4 Get Shorty (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Get%20Shorty%2... 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0      0   \n5 Copycat (1995)    01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Copycat%20(1995)  0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0      0   \n\n                                                                                                                        genres  \n1 Toy Story (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Toy%20Story%20... 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0       0  \n2 GoldenEye (1995)  01-Jan-1995 NaN http://us.imdb.com/M/title-exact?GoldenEye%20(1... 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0       0  \n3 Four Rooms (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Four%20Rooms%2... 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0       0  \n4 Get Shorty (1995) 01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Get%20Shorty%2... 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0       0  \n5 Copycat (1995)    01-Jan-1995 NaN http://us.imdb.com/M/title-exact?Copycat%20(1995)  0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <th>Toy Story (1995)</th>\n      <th>01-Jan-1995</th>\n      <th>NaN</th>\n      <th>http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>1</th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <th>GoldenEye (1995)</th>\n      <th>01-Jan-1995</th>\n      <th>NaN</th>\n      <th>http://us.imdb.com/M/title-exact?GoldenEye%20(1995)</th>\n      <th>0</th>\n      <th>1</th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <th>Four Rooms (1995)</th>\n      <th>01-Jan-1995</th>\n      <th>NaN</th>\n      <th>http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <th>Get Shorty (1995)</th>\n      <th>01-Jan-1995</th>\n      <th>NaN</th>\n      <th>http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)</th>\n      <th>0</th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <th>Copycat (1995)</th>\n      <th>01-Jan-1995</th>\n      <th>NaN</th>\n      <th>http://us.imdb.com/M/title-exact?Copycat%20(1995)</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>1</th>\n      <th>0</th>\n      <th>1</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 943 users, 1682 movies\n",
      "Dataset shape: (100000, 2)\n",
      "Target shape: (100000,)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    if top is not None:\n",
    "        ratings.groupby('userId')['rating'].count()\n",
    "\n",
    "    unique_users = ratings.userId.unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = ratings.userId.map(user_to_index)\n",
    "\n",
    "    unique_movies = ratings.movieId.unique()\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)}\n",
    "    new_movies = ratings.movieId.map(movie_to_index)\n",
    "\n",
    "    n_users = unique_users.shape[0]\n",
    "    n_movies = unique_movies.shape[0]\n",
    "\n",
    "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_movies})\n",
    "    y = ratings['rating'].astype(np.float32)\n",
    "    return (n_users, n_movies), (X, y), (user_to_index, movie_to_index)\n",
    "\n",
    "(n, m), (X, y), _ = create_dataset(ratings)\n",
    "print(f'Embeddings: {n} users, {m} movies')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, random_state=RANDOM_STATE)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=RANDOM_STATE)\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid), 'test': (X_test, y_test)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_valid), 'test': len(X_test)}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class RatingsIterator:\n",
    "\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in RatingsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class RecommenderNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates dense MLN with embedding layers.\n",
    "\n",
    "    Args:\n",
    "        n_users:\n",
    "            Number of unique users in the dataset.\n",
    "\n",
    "        n_movies:\n",
    "            Number of unique movies in the dataset.\n",
    "\n",
    "        n_factors:\n",
    "            Number of columns in the embeddings matrix.\n",
    "\n",
    "        embedding_dropout:\n",
    "            Dropout rate to apply right after embeddings layer.\n",
    "\n",
    "        hidden:\n",
    "            A single integer or a list of integers defining the number of\n",
    "            units in hidden layer(s).\n",
    "\n",
    "        dropouts:\n",
    "            A single integer or a list of integers defining the dropout\n",
    "            layers rates applied right after each of hidden layers.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_movies,\n",
    "                 n_factors=50, embedding_dropout=0.02,\n",
    "                 hidden=10, dropouts=0.2):\n",
    "\n",
    "        super().__init__()\n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "\n",
    "        def gen_layers(n_in):\n",
    "            \"\"\"\n",
    "            A generator that yields a sequence of hidden layers and\n",
    "            their activations/dropouts.\n",
    "\n",
    "            Note that the function captures `hidden` and `dropouts`\n",
    "            values from the outer scope.\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "\n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self._init()\n",
    "\n",
    "    def forward(self, users, movies, minmax=None):\n",
    "        features = torch.cat([self.u(users), self.m(movies)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        #out = self.relu(self.fc(x))  # relu delivers worse rsme\n",
    "        if minmax is not None:\n",
    "            min_rating, max_rating = minmax\n",
    "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "        return out\n",
    "\n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Setup embeddings and hidden layers with reasonable initial values.\n",
    "        \"\"\"\n",
    "\n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)\n",
    "\n",
    "\n",
    "def get_list(n):\n",
    "    if isinstance(n, (int, float)):\n",
    "        return [n]\n",
    "    elif hasattr(n, '__iter__'):\n",
    "        return list(n)\n",
    "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "\n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi*t/t_max))/2\n",
    "    return scheduler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def plot_lr(schedule):\n",
    "    ts = list(range(1000))\n",
    "    y = [schedule(t, 0.001) for t in ts]\n",
    "    plt.plot(ts, y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(1.0, 5.0)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = float(ratings.rating.min()), float(ratings.rating.max())\n",
    "minmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# small net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=10, hidden=[10],\n",
    "    embedding_dropout=0.05, dropouts=[0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "#iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "#scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 1.4751 - val: 1.2103\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 1.3707 - val: 1.1426\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 1.2983 - val: 1.0820\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 1.2287 - val: 1.0252\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 1.1617 - val: 0.9782\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 1.1034 - val: 0.9300\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 1.0471 - val: 0.8963\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 1.0011 - val: 0.8660\n",
      "loss improvement on epoch: 9\n",
      "[009/300] train: 0.9640 - val: 0.8394\n",
      "loss improvement on epoch: 10\n",
      "[010/300] train: 0.9363 - val: 0.8245\n",
      "loss improvement on epoch: 11\n",
      "[011/300] train: 0.9149 - val: 0.8158\n",
      "loss improvement on epoch: 12\n",
      "[012/300] train: 0.9000 - val: 0.8067\n",
      "loss improvement on epoch: 13\n",
      "[013/300] train: 0.8951 - val: 0.8042\n",
      "loss improvement on epoch: 14\n",
      "[014/300] train: 0.8845 - val: 0.7940\n",
      "loss improvement on epoch: 15\n",
      "[015/300] train: 0.8752 - val: 0.7924\n",
      "[016/300] train: 0.8707 - val: 0.7959\n",
      "[017/300] train: 0.8662 - val: 0.7956\n",
      "loss improvement on epoch: 18\n",
      "[018/300] train: 0.8596 - val: 0.7914\n",
      "loss improvement on epoch: 19\n",
      "[019/300] train: 0.8549 - val: 0.7827\n",
      "[020/300] train: 0.8513 - val: 0.7847\n",
      "loss improvement on epoch: 21\n",
      "[021/300] train: 0.8499 - val: 0.7826\n",
      "[022/300] train: 0.8458 - val: 0.7830\n",
      "loss improvement on epoch: 23\n",
      "[023/300] train: 0.8384 - val: 0.7788\n",
      "loss improvement on epoch: 24\n",
      "[024/300] train: 0.8369 - val: 0.7775\n",
      "[025/300] train: 0.8398 - val: 0.7780\n",
      "loss improvement on epoch: 26\n",
      "[026/300] train: 0.8346 - val: 0.7759\n",
      "[027/300] train: 0.8325 - val: 0.7776\n",
      "[028/300] train: 0.8282 - val: 0.7768\n",
      "[029/300] train: 0.8244 - val: 0.7780\n",
      "[030/300] train: 0.8235 - val: 0.7784\n",
      "loss improvement on epoch: 31\n",
      "[031/300] train: 0.8255 - val: 0.7727\n",
      "[032/300] train: 0.8187 - val: 0.7783\n",
      "[033/300] train: 0.8196 - val: 0.7731\n",
      "[034/300] train: 0.8150 - val: 0.7761\n",
      "loss improvement on epoch: 35\n",
      "[035/300] train: 0.8147 - val: 0.7703\n",
      "[036/300] train: 0.8144 - val: 0.7715\n",
      "[037/300] train: 0.8136 - val: 0.7712\n",
      "[038/300] train: 0.8118 - val: 0.7798\n",
      "loss improvement on epoch: 39\n",
      "[039/300] train: 0.8138 - val: 0.7649\n",
      "[040/300] train: 0.8073 - val: 0.7700\n",
      "[041/300] train: 0.8080 - val: 0.7739\n",
      "[042/300] train: 0.8027 - val: 0.7766\n",
      "[043/300] train: 0.8014 - val: 0.7773\n",
      "[044/300] train: 0.8013 - val: 0.7711\n",
      "[045/300] train: 0.7992 - val: 0.7736\n",
      "[046/300] train: 0.7994 - val: 0.7705\n",
      "[047/300] train: 0.7986 - val: 0.7736\n",
      "[048/300] train: 0.7956 - val: 0.7738\n",
      "[049/300] train: 0.7949 - val: 0.7711\n",
      "loss improvement on epoch: 50\n",
      "[050/300] train: 0.7940 - val: 0.7638\n",
      "[051/300] train: 0.7932 - val: 0.7669\n",
      "[052/300] train: 0.7902 - val: 0.7714\n",
      "[053/300] train: 0.7864 - val: 0.7697\n",
      "[054/300] train: 0.7918 - val: 0.7673\n",
      "[055/300] train: 0.7904 - val: 0.7709\n",
      "[056/300] train: 0.7876 - val: 0.7666\n",
      "[057/300] train: 0.7817 - val: 0.7724\n",
      "[058/300] train: 0.7834 - val: 0.7656\n",
      "[059/300] train: 0.7834 - val: 0.7685\n",
      "[060/300] train: 0.7789 - val: 0.7722\n",
      "[061/300] train: 0.7779 - val: 0.7665\n",
      "[062/300] train: 0.7775 - val: 0.7699\n",
      "[063/300] train: 0.7786 - val: 0.7658\n",
      "[064/300] train: 0.7738 - val: 0.7709\n",
      "[065/300] train: 0.7801 - val: 0.7659\n",
      "[066/300] train: 0.7754 - val: 0.7674\n",
      "[067/300] train: 0.7793 - val: 0.7645\n",
      "[068/300] train: 0.7724 - val: 0.7744\n",
      "[069/300] train: 0.7730 - val: 0.7648\n",
      "[070/300] train: 0.7684 - val: 0.7742\n",
      "[071/300] train: 0.7704 - val: 0.7737\n",
      "[072/300] train: 0.7652 - val: 0.7647\n",
      "[073/300] train: 0.7712 - val: 0.7672\n",
      "[074/300] train: 0.7695 - val: 0.7732\n",
      "[075/300] train: 0.7648 - val: 0.7664\n",
      "[076/300] train: 0.7645 - val: 0.7736\n",
      "[077/300] train: 0.7630 - val: 0.7665\n",
      "[078/300] train: 0.7628 - val: 0.7762\n",
      "[079/300] train: 0.7639 - val: 0.7705\n",
      "[080/300] train: 0.7635 - val: 0.7703\n",
      "[081/300] train: 0.7614 - val: 0.7709\n",
      "[082/300] train: 0.7625 - val: 0.7724\n",
      "[083/300] train: 0.7623 - val: 0.7660\n",
      "[084/300] train: 0.7573 - val: 0.7754\n",
      "[085/300] train: 0.7572 - val: 0.7764\n",
      "[086/300] train: 0.7566 - val: 0.7768\n",
      "[087/300] train: 0.7548 - val: 0.7687\n",
      "[088/300] train: 0.7566 - val: 0.7723\n",
      "[089/300] train: 0.7552 - val: 0.7726\n",
      "[090/300] train: 0.7564 - val: 0.7723\n",
      "[091/300] train: 0.7530 - val: 0.7683\n",
      "[092/300] train: 0.7552 - val: 0.7745\n",
      "[093/300] train: 0.7511 - val: 0.7754\n",
      "[094/300] train: 0.7532 - val: 0.7728\n",
      "[095/300] train: 0.7523 - val: 0.7713\n",
      "[096/300] train: 0.7515 - val: 0.7726\n",
      "[097/300] train: 0.7472 - val: 0.7697\n",
      "[098/300] train: 0.7524 - val: 0.7723\n",
      "[099/300] train: 0.7508 - val: 0.7784\n",
      "[100/300] train: 0.7513 - val: 0.7719\n",
      "[101/300] train: 0.7488 - val: 0.7709\n",
      "[102/300] train: 0.7445 - val: 0.7741\n",
      "[103/300] train: 0.7482 - val: 0.7749\n",
      "[104/300] train: 0.7452 - val: 0.7770\n",
      "[105/300] train: 0.7468 - val: 0.7833\n",
      "[106/300] train: 0.7438 - val: 0.7743\n",
      "[107/300] train: 0.7502 - val: 0.7765\n",
      "[108/300] train: 0.7436 - val: 0.7711\n",
      "[109/300] train: 0.7435 - val: 0.7768\n",
      "[110/300] train: 0.7458 - val: 0.7725\n",
      "[111/300] train: 0.7437 - val: 0.7748\n",
      "[112/300] train: 0.7416 - val: 0.7752\n",
      "[113/300] train: 0.7464 - val: 0.7701\n",
      "[114/300] train: 0.7451 - val: 0.7743\n",
      "[115/300] train: 0.7441 - val: 0.7729\n",
      "[116/300] train: 0.7434 - val: 0.7782\n",
      "[117/300] train: 0.7430 - val: 0.7711\n",
      "[118/300] train: 0.7438 - val: 0.7778\n",
      "[119/300] train: 0.7405 - val: 0.7797\n",
      "[120/300] train: 0.7396 - val: 0.7703\n",
      "[121/300] train: 0.7403 - val: 0.7754\n",
      "[122/300] train: 0.7414 - val: 0.7738\n",
      "[123/300] train: 0.7413 - val: 0.7753\n",
      "[124/300] train: 0.7387 - val: 0.7723\n",
      "[125/300] train: 0.7383 - val: 0.7798\n",
      "[126/300] train: 0.7339 - val: 0.7792\n",
      "[127/300] train: 0.7355 - val: 0.7749\n",
      "[128/300] train: 0.7375 - val: 0.7726\n",
      "[129/300] train: 0.7383 - val: 0.7749\n",
      "[130/300] train: 0.7350 - val: 0.7754\n",
      "[131/300] train: 0.7349 - val: 0.7767\n",
      "[132/300] train: 0.7358 - val: 0.7785\n",
      "[133/300] train: 0.7365 - val: 0.7764\n",
      "[134/300] train: 0.7386 - val: 0.7761\n",
      "[135/300] train: 0.7342 - val: 0.7803\n",
      "[136/300] train: 0.7350 - val: 0.7781\n",
      "[137/300] train: 0.7335 - val: 0.7809\n",
      "[138/300] train: 0.7355 - val: 0.7774\n",
      "[139/300] train: 0.7354 - val: 0.7799\n",
      "[140/300] train: 0.7330 - val: 0.7842\n",
      "[141/300] train: 0.7347 - val: 0.7784\n",
      "[142/300] train: 0.7336 - val: 0.7755\n",
      "[143/300] train: 0.7316 - val: 0.7760\n",
      "[144/300] train: 0.7330 - val: 0.7747\n",
      "[145/300] train: 0.7326 - val: 0.7797\n",
      "[146/300] train: 0.7311 - val: 0.7767\n",
      "[147/300] train: 0.7306 - val: 0.7793\n",
      "[148/300] train: 0.7291 - val: 0.7784\n",
      "[149/300] train: 0.7314 - val: 0.7734\n",
      "[150/300] train: 0.7311 - val: 0.7785\n",
      "[151/300] train: 0.7267 - val: 0.7796\n",
      "[152/300] train: 0.7298 - val: 0.7747\n",
      "[153/300] train: 0.7307 - val: 0.7752\n",
      "[154/300] train: 0.7298 - val: 0.7779\n",
      "[155/300] train: 0.7255 - val: 0.7797\n",
      "[156/300] train: 0.7279 - val: 0.7787\n",
      "[157/300] train: 0.7306 - val: 0.7790\n",
      "[158/300] train: 0.7259 - val: 0.7810\n",
      "[159/300] train: 0.7290 - val: 0.7785\n",
      "[160/300] train: 0.7308 - val: 0.7831\n",
      "[161/300] train: 0.7299 - val: 0.7784\n",
      "[162/300] train: 0.7283 - val: 0.7778\n",
      "[163/300] train: 0.7269 - val: 0.7817\n",
      "[164/300] train: 0.7255 - val: 0.7788\n",
      "[165/300] train: 0.7274 - val: 0.7778\n",
      "[166/300] train: 0.7264 - val: 0.7790\n",
      "[167/300] train: 0.7251 - val: 0.7792\n",
      "[168/300] train: 0.7253 - val: 0.7794\n",
      "[169/300] train: 0.7239 - val: 0.7768\n",
      "[170/300] train: 0.7267 - val: 0.7791\n",
      "[171/300] train: 0.7282 - val: 0.7821\n",
      "[172/300] train: 0.7210 - val: 0.7796\n",
      "[173/300] train: 0.7232 - val: 0.7794\n",
      "[174/300] train: 0.7235 - val: 0.7798\n",
      "[175/300] train: 0.7267 - val: 0.7778\n",
      "[176/300] train: 0.7227 - val: 0.7847\n",
      "[177/300] train: 0.7232 - val: 0.7810\n",
      "[178/300] train: 0.7235 - val: 0.7791\n",
      "[179/300] train: 0.7227 - val: 0.7778\n",
      "[180/300] train: 0.7228 - val: 0.7826\n",
      "[181/300] train: 0.7207 - val: 0.7831\n",
      "[182/300] train: 0.7209 - val: 0.7869\n",
      "[183/300] train: 0.7245 - val: 0.7830\n",
      "[184/300] train: 0.7165 - val: 0.7843\n",
      "[185/300] train: 0.7207 - val: 0.7820\n",
      "[186/300] train: 0.7216 - val: 0.7828\n",
      "[187/300] train: 0.7188 - val: 0.7858\n",
      "[188/300] train: 0.7226 - val: 0.7786\n",
      "[189/300] train: 0.7209 - val: 0.7821\n",
      "[190/300] train: 0.7194 - val: 0.7797\n",
      "[191/300] train: 0.7195 - val: 0.7870\n",
      "[192/300] train: 0.7191 - val: 0.7866\n",
      "[193/300] train: 0.7199 - val: 0.7847\n",
      "[194/300] train: 0.7208 - val: 0.7886\n",
      "[195/300] train: 0.7214 - val: 0.7776\n",
      "[196/300] train: 0.7172 - val: 0.7892\n",
      "[197/300] train: 0.7184 - val: 0.7853\n",
      "[198/300] train: 0.7195 - val: 0.7901\n",
      "[199/300] train: 0.7182 - val: 0.7889\n",
      "[200/300] train: 0.7166 - val: 0.7795\n",
      "[201/300] train: 0.7200 - val: 0.7901\n",
      "[202/300] train: 0.7154 - val: 0.7859\n",
      "[203/300] train: 0.7171 - val: 0.7862\n",
      "[204/300] train: 0.7168 - val: 0.7844\n",
      "[205/300] train: 0.7172 - val: 0.7832\n",
      "[206/300] train: 0.7184 - val: 0.7888\n",
      "[207/300] train: 0.7195 - val: 0.7807\n",
      "[208/300] train: 0.7210 - val: 0.7829\n",
      "[209/300] train: 0.7175 - val: 0.7843\n",
      "[210/300] train: 0.7166 - val: 0.7880\n",
      "[211/300] train: 0.7131 - val: 0.7815\n",
      "[212/300] train: 0.7140 - val: 0.7882\n",
      "[213/300] train: 0.7178 - val: 0.7813\n",
      "[214/300] train: 0.7148 - val: 0.7883\n",
      "[215/300] train: 0.7176 - val: 0.7858\n",
      "[216/300] train: 0.7183 - val: 0.7877\n",
      "[217/300] train: 0.7205 - val: 0.7804\n",
      "[218/300] train: 0.7155 - val: 0.7848\n",
      "[219/300] train: 0.7164 - val: 0.7802\n",
      "[220/300] train: 0.7168 - val: 0.7848\n",
      "[221/300] train: 0.7143 - val: 0.7888\n",
      "[222/300] train: 0.7129 - val: 0.7876\n",
      "[223/300] train: 0.7168 - val: 0.7876\n",
      "[224/300] train: 0.7136 - val: 0.7846\n",
      "[225/300] train: 0.7148 - val: 0.7880\n",
      "[226/300] train: 0.7127 - val: 0.7822\n",
      "[227/300] train: 0.7164 - val: 0.7866\n",
      "[228/300] train: 0.7183 - val: 0.7858\n",
      "[229/300] train: 0.7164 - val: 0.7890\n",
      "[230/300] train: 0.7151 - val: 0.7843\n",
      "[231/300] train: 0.7121 - val: 0.7867\n",
      "[232/300] train: 0.7159 - val: 0.7867\n",
      "[233/300] train: 0.7135 - val: 0.7882\n",
      "[234/300] train: 0.7120 - val: 0.7888\n",
      "[235/300] train: 0.7113 - val: 0.7908\n",
      "[236/300] train: 0.7138 - val: 0.7828\n",
      "[237/300] train: 0.7144 - val: 0.7909\n",
      "[238/300] train: 0.7136 - val: 0.7812\n",
      "[239/300] train: 0.7110 - val: 0.7897\n",
      "[240/300] train: 0.7135 - val: 0.7776\n",
      "[241/300] train: 0.7113 - val: 0.7844\n",
      "[242/300] train: 0.7138 - val: 0.7793\n",
      "[243/300] train: 0.7130 - val: 0.7794\n",
      "[244/300] train: 0.7137 - val: 0.7753\n",
      "[245/300] train: 0.7158 - val: 0.7844\n",
      "[246/300] train: 0.7135 - val: 0.7877\n",
      "[247/300] train: 0.7140 - val: 0.7861\n",
      "[248/300] train: 0.7126 - val: 0.7849\n",
      "[249/300] train: 0.7151 - val: 0.7903\n",
      "[250/300] train: 0.7134 - val: 0.7812\n",
      "[251/300] train: 0.7099 - val: 0.7838\n",
      "[252/300] train: 0.7125 - val: 0.7867\n",
      "[253/300] train: 0.7140 - val: 0.7801\n",
      "[254/300] train: 0.7133 - val: 0.7820\n",
      "[255/300] train: 0.7121 - val: 0.7803\n",
      "[256/300] train: 0.7129 - val: 0.7901\n",
      "[257/300] train: 0.7123 - val: 0.7860\n",
      "[258/300] train: 0.7087 - val: 0.7844\n",
      "[259/300] train: 0.7116 - val: 0.7804\n",
      "[260/300] train: 0.7123 - val: 0.7810\n",
      "[261/300] train: 0.7098 - val: 0.7836\n",
      "[262/300] train: 0.7135 - val: 0.7903\n",
      "[263/300] train: 0.7122 - val: 0.7818\n",
      "[264/300] train: 0.7144 - val: 0.7814\n",
      "[265/300] train: 0.7104 - val: 0.7830\n",
      "[266/300] train: 0.7113 - val: 0.7835\n",
      "[267/300] train: 0.7134 - val: 0.7824\n",
      "[268/300] train: 0.7086 - val: 0.7887\n",
      "[269/300] train: 0.7139 - val: 0.7894\n",
      "[270/300] train: 0.7111 - val: 0.7867\n",
      "[271/300] train: 0.7128 - val: 0.7892\n",
      "[272/300] train: 0.7121 - val: 0.7841\n",
      "[273/300] train: 0.7089 - val: 0.7890\n",
      "[274/300] train: 0.7087 - val: 0.7833\n",
      "[275/300] train: 0.7075 - val: 0.7873\n",
      "[276/300] train: 0.7107 - val: 0.7840\n",
      "[277/300] train: 0.7090 - val: 0.7840\n",
      "[278/300] train: 0.7073 - val: 0.7872\n",
      "[279/300] train: 0.7098 - val: 0.7764\n",
      "[280/300] train: 0.7092 - val: 0.7883\n",
      "[281/300] train: 0.7085 - val: 0.7839\n",
      "[282/300] train: 0.7116 - val: 0.7900\n",
      "[283/300] train: 0.7109 - val: 0.7893\n",
      "[284/300] train: 0.7023 - val: 0.7775\n",
      "[285/300] train: 0.7124 - val: 0.7853\n",
      "[286/300] train: 0.7116 - val: 0.7859\n",
      "[287/300] train: 0.7090 - val: 0.7899\n",
      "[288/300] train: 0.7065 - val: 0.7864\n",
      "[289/300] train: 0.7092 - val: 0.7905\n",
      "[290/300] train: 0.7086 - val: 0.7914\n",
      "[291/300] train: 0.7115 - val: 0.7823\n",
      "[292/300] train: 0.7056 - val: 0.7865\n",
      "[293/300] train: 0.7095 - val: 0.7836\n",
      "[294/300] train: 0.7057 - val: 0.7830\n",
      "[295/300] train: 0.7098 - val: 0.7906\n",
      "[296/300] train: 0.7117 - val: 0.7887\n",
      "[297/300] train: 0.7121 - val: 0.7901\n",
      "[298/300] train: 0.7072 - val: 0.7847\n",
      "[299/300] train: 0.7078 - val: 0.7881\n",
      "[300/300] train: 0.7046 - val: 0.7831\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "\n",
    "plt.savefig(figure_path + '/ml-100k-medium-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Plot decreasing learning rate\n",
    "\n",
    "#_ = plt.plot(lr_history[:2*iterations_per_epoch-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.9678\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.9781\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "with open('best.weights.small', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 11.5471\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# medium net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=20, hidden=[10 ,10],\n",
    "    embedding_dropout=0.05, dropouts=[0.3, 0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "#iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "#scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 1.4366 - val: 1.1841\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 1.3432 - val: 1.1106\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 1.2552 - val: 1.0356\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 1.1739 - val: 0.9825\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 1.1170 - val: 0.9507\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 1.0736 - val: 0.9187\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 1.0322 - val: 0.8926\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 1.0007 - val: 0.8687\n",
      "loss improvement on epoch: 9\n",
      "[009/300] train: 0.9643 - val: 0.8425\n",
      "loss improvement on epoch: 10\n",
      "[010/300] train: 0.9448 - val: 0.8351\n",
      "loss improvement on epoch: 11\n",
      "[011/300] train: 0.9302 - val: 0.8315\n",
      "loss improvement on epoch: 12\n",
      "[012/300] train: 0.9162 - val: 0.8237\n",
      "loss improvement on epoch: 13\n",
      "[013/300] train: 0.9091 - val: 0.8133\n",
      "[014/300] train: 0.9004 - val: 0.8163\n",
      "[015/300] train: 0.8890 - val: 0.8170\n",
      "loss improvement on epoch: 16\n",
      "[016/300] train: 0.8875 - val: 0.8050\n",
      "[017/300] train: 0.8753 - val: 0.8074\n",
      "loss improvement on epoch: 18\n",
      "[018/300] train: 0.8695 - val: 0.7953\n",
      "[019/300] train: 0.8689 - val: 0.7966\n",
      "loss improvement on epoch: 20\n",
      "[020/300] train: 0.8578 - val: 0.7871\n",
      "[021/300] train: 0.8525 - val: 0.7936\n",
      "[022/300] train: 0.8515 - val: 0.7959\n",
      "[023/300] train: 0.8430 - val: 0.7883\n",
      "[024/300] train: 0.8439 - val: 0.7883\n",
      "[025/300] train: 0.8402 - val: 0.7942\n",
      "[026/300] train: 0.8390 - val: 0.7936\n",
      "[027/300] train: 0.8309 - val: 0.7926\n",
      "[028/300] train: 0.8319 - val: 0.7886\n",
      "loss improvement on epoch: 29\n",
      "[029/300] train: 0.8264 - val: 0.7859\n",
      "[030/300] train: 0.8279 - val: 0.7861\n",
      "loss improvement on epoch: 31\n",
      "[031/300] train: 0.8249 - val: 0.7842\n",
      "[032/300] train: 0.8187 - val: 0.7886\n",
      "[033/300] train: 0.8207 - val: 0.7872\n",
      "[034/300] train: 0.8162 - val: 0.7881\n",
      "loss improvement on epoch: 35\n",
      "[035/300] train: 0.8179 - val: 0.7830\n",
      "[036/300] train: 0.8142 - val: 0.7863\n",
      "loss improvement on epoch: 37\n",
      "[037/300] train: 0.8114 - val: 0.7808\n",
      "[038/300] train: 0.8116 - val: 0.7845\n",
      "[039/300] train: 0.8051 - val: 0.7828\n",
      "[040/300] train: 0.8047 - val: 0.7863\n",
      "[041/300] train: 0.8050 - val: 0.7877\n",
      "[042/300] train: 0.8026 - val: 0.7837\n",
      "[043/300] train: 0.8015 - val: 0.7854\n",
      "[044/300] train: 0.8010 - val: 0.7876\n",
      "[045/300] train: 0.8036 - val: 0.7824\n",
      "[046/300] train: 0.7973 - val: 0.7877\n",
      "[047/300] train: 0.7973 - val: 0.7826\n",
      "[048/300] train: 0.7963 - val: 0.7831\n",
      "[049/300] train: 0.7931 - val: 0.7822\n",
      "[050/300] train: 0.7923 - val: 0.7839\n",
      "[051/300] train: 0.7901 - val: 0.7836\n",
      "[052/300] train: 0.7922 - val: 0.7924\n",
      "[053/300] train: 0.7882 - val: 0.7841\n",
      "[054/300] train: 0.7855 - val: 0.7823\n",
      "[055/300] train: 0.7870 - val: 0.7837\n",
      "[056/300] train: 0.7816 - val: 0.7886\n",
      "[057/300] train: 0.7838 - val: 0.7856\n",
      "[058/300] train: 0.7807 - val: 0.7834\n",
      "[059/300] train: 0.7849 - val: 0.7839\n",
      "[060/300] train: 0.7810 - val: 0.7848\n",
      "[061/300] train: 0.7808 - val: 0.7820\n",
      "[062/300] train: 0.7802 - val: 0.7903\n",
      "[063/300] train: 0.7780 - val: 0.7820\n",
      "[064/300] train: 0.7775 - val: 0.7889\n",
      "[065/300] train: 0.7774 - val: 0.7887\n",
      "[066/300] train: 0.7768 - val: 0.7859\n",
      "[067/300] train: 0.7746 - val: 0.7878\n",
      "[068/300] train: 0.7719 - val: 0.7919\n",
      "[069/300] train: 0.7673 - val: 0.7891\n",
      "[070/300] train: 0.7724 - val: 0.7887\n",
      "[071/300] train: 0.7693 - val: 0.7856\n",
      "[072/300] train: 0.7701 - val: 0.7889\n",
      "[073/300] train: 0.7637 - val: 0.7906\n",
      "[074/300] train: 0.7699 - val: 0.7870\n",
      "[075/300] train: 0.7658 - val: 0.7877\n",
      "[076/300] train: 0.7644 - val: 0.7886\n",
      "[077/300] train: 0.7604 - val: 0.7950\n",
      "[078/300] train: 0.7675 - val: 0.7886\n",
      "[079/300] train: 0.7559 - val: 0.7847\n",
      "[080/300] train: 0.7610 - val: 0.7894\n",
      "[081/300] train: 0.7614 - val: 0.7853\n",
      "[082/300] train: 0.7605 - val: 0.7921\n",
      "[083/300] train: 0.7563 - val: 0.7955\n",
      "[084/300] train: 0.7590 - val: 0.7921\n",
      "[085/300] train: 0.7574 - val: 0.7944\n",
      "[086/300] train: 0.7608 - val: 0.7915\n",
      "[087/300] train: 0.7527 - val: 0.7909\n",
      "[088/300] train: 0.7562 - val: 0.7902\n",
      "[089/300] train: 0.7535 - val: 0.7953\n",
      "[090/300] train: 0.7556 - val: 0.7858\n",
      "[091/300] train: 0.7526 - val: 0.7937\n",
      "[092/300] train: 0.7529 - val: 0.7875\n",
      "[093/300] train: 0.7529 - val: 0.7943\n",
      "[094/300] train: 0.7512 - val: 0.7968\n",
      "[095/300] train: 0.7546 - val: 0.7974\n",
      "[096/300] train: 0.7476 - val: 0.7945\n",
      "[097/300] train: 0.7507 - val: 0.7919\n",
      "[098/300] train: 0.7478 - val: 0.8027\n",
      "[099/300] train: 0.7501 - val: 0.8005\n",
      "[100/300] train: 0.7509 - val: 0.7905\n",
      "[101/300] train: 0.7458 - val: 0.8043\n",
      "[102/300] train: 0.7503 - val: 0.7957\n",
      "[103/300] train: 0.7463 - val: 0.7970\n",
      "[104/300] train: 0.7490 - val: 0.7968\n",
      "[105/300] train: 0.7434 - val: 0.7990\n",
      "[106/300] train: 0.7457 - val: 0.8083\n",
      "[107/300] train: 0.7438 - val: 0.8069\n",
      "[108/300] train: 0.7460 - val: 0.7973\n",
      "[109/300] train: 0.7408 - val: 0.8109\n",
      "[110/300] train: 0.7423 - val: 0.8020\n",
      "[111/300] train: 0.7419 - val: 0.8086\n",
      "[112/300] train: 0.7437 - val: 0.7992\n",
      "[113/300] train: 0.7419 - val: 0.8033\n",
      "[114/300] train: 0.7404 - val: 0.8031\n",
      "[115/300] train: 0.7430 - val: 0.7974\n",
      "[116/300] train: 0.7399 - val: 0.7978\n",
      "[117/300] train: 0.7405 - val: 0.7997\n",
      "[118/300] train: 0.7363 - val: 0.8004\n",
      "[119/300] train: 0.7383 - val: 0.7999\n",
      "[120/300] train: 0.7404 - val: 0.8043\n",
      "[121/300] train: 0.7351 - val: 0.8022\n",
      "[122/300] train: 0.7410 - val: 0.8072\n",
      "[123/300] train: 0.7378 - val: 0.8039\n",
      "[124/300] train: 0.7362 - val: 0.8008\n",
      "[125/300] train: 0.7369 - val: 0.8078\n",
      "[126/300] train: 0.7298 - val: 0.8114\n",
      "[127/300] train: 0.7340 - val: 0.8088\n",
      "[128/300] train: 0.7333 - val: 0.8058\n",
      "[129/300] train: 0.7349 - val: 0.8064\n",
      "[130/300] train: 0.7353 - val: 0.8076\n",
      "[131/300] train: 0.7359 - val: 0.8132\n",
      "[132/300] train: 0.7384 - val: 0.8062\n",
      "[133/300] train: 0.7336 - val: 0.8031\n",
      "[134/300] train: 0.7328 - val: 0.8003\n",
      "[135/300] train: 0.7300 - val: 0.8072\n",
      "[136/300] train: 0.7333 - val: 0.8072\n",
      "[137/300] train: 0.7323 - val: 0.8087\n",
      "[138/300] train: 0.7345 - val: 0.8058\n",
      "[139/300] train: 0.7317 - val: 0.8072\n",
      "[140/300] train: 0.7272 - val: 0.8056\n",
      "[141/300] train: 0.7325 - val: 0.8028\n",
      "[142/300] train: 0.7275 - val: 0.8127\n",
      "[143/300] train: 0.7278 - val: 0.8132\n",
      "[144/300] train: 0.7343 - val: 0.8084\n",
      "[145/300] train: 0.7245 - val: 0.8121\n",
      "[146/300] train: 0.7254 - val: 0.8134\n",
      "[147/300] train: 0.7266 - val: 0.8075\n",
      "[148/300] train: 0.7305 - val: 0.8075\n",
      "[149/300] train: 0.7299 - val: 0.8109\n",
      "[150/300] train: 0.7284 - val: 0.8133\n",
      "[151/300] train: 0.7285 - val: 0.8079\n",
      "[152/300] train: 0.7248 - val: 0.8136\n",
      "[153/300] train: 0.7248 - val: 0.8117\n",
      "[154/300] train: 0.7270 - val: 0.8171\n",
      "[155/300] train: 0.7238 - val: 0.8185\n",
      "[156/300] train: 0.7276 - val: 0.8095\n",
      "[157/300] train: 0.7247 - val: 0.8132\n",
      "[158/300] train: 0.7251 - val: 0.8077\n",
      "[159/300] train: 0.7244 - val: 0.8189\n",
      "[160/300] train: 0.7255 - val: 0.8082\n",
      "[161/300] train: 0.7281 - val: 0.8145\n",
      "[162/300] train: 0.7215 - val: 0.8150\n",
      "[163/300] train: 0.7227 - val: 0.8171\n",
      "[164/300] train: 0.7224 - val: 0.8173\n",
      "[165/300] train: 0.7279 - val: 0.8111\n",
      "[166/300] train: 0.7239 - val: 0.8151\n",
      "[167/300] train: 0.7232 - val: 0.8204\n",
      "[168/300] train: 0.7249 - val: 0.8178\n",
      "[169/300] train: 0.7246 - val: 0.8208\n",
      "[170/300] train: 0.7214 - val: 0.8161\n",
      "[171/300] train: 0.7202 - val: 0.8098\n",
      "[172/300] train: 0.7247 - val: 0.8093\n",
      "[173/300] train: 0.7233 - val: 0.8170\n",
      "[174/300] train: 0.7226 - val: 0.8198\n",
      "[175/300] train: 0.7232 - val: 0.8197\n",
      "[176/300] train: 0.7190 - val: 0.8190\n",
      "[177/300] train: 0.7222 - val: 0.8123\n",
      "[178/300] train: 0.7222 - val: 0.8205\n",
      "[179/300] train: 0.7205 - val: 0.8182\n",
      "[180/300] train: 0.7187 - val: 0.8202\n",
      "[181/300] train: 0.7196 - val: 0.8127\n",
      "[182/300] train: 0.7231 - val: 0.8208\n",
      "[183/300] train: 0.7203 - val: 0.8295\n",
      "[184/300] train: 0.7153 - val: 0.8203\n",
      "[185/300] train: 0.7206 - val: 0.8182\n",
      "[186/300] train: 0.7175 - val: 0.8267\n",
      "[187/300] train: 0.7197 - val: 0.8167\n",
      "[188/300] train: 0.7185 - val: 0.8232\n",
      "[189/300] train: 0.7173 - val: 0.8165\n",
      "[190/300] train: 0.7207 - val: 0.8198\n",
      "[191/300] train: 0.7203 - val: 0.8158\n",
      "[192/300] train: 0.7184 - val: 0.8163\n",
      "[193/300] train: 0.7167 - val: 0.8200\n",
      "[194/300] train: 0.7179 - val: 0.8215\n",
      "[195/300] train: 0.7183 - val: 0.8196\n",
      "[196/300] train: 0.7200 - val: 0.8151\n",
      "[197/300] train: 0.7194 - val: 0.8240\n",
      "[198/300] train: 0.7184 - val: 0.8196\n",
      "[199/300] train: 0.7153 - val: 0.8235\n",
      "[200/300] train: 0.7168 - val: 0.8232\n",
      "[201/300] train: 0.7159 - val: 0.8291\n",
      "[202/300] train: 0.7125 - val: 0.8296\n",
      "[203/300] train: 0.7163 - val: 0.8249\n",
      "[204/300] train: 0.7191 - val: 0.8128\n",
      "[205/300] train: 0.7180 - val: 0.8217\n",
      "[206/300] train: 0.7149 - val: 0.8252\n",
      "[207/300] train: 0.7153 - val: 0.8096\n",
      "[208/300] train: 0.7150 - val: 0.8255\n",
      "[209/300] train: 0.7170 - val: 0.8144\n",
      "[210/300] train: 0.7127 - val: 0.8202\n",
      "[211/300] train: 0.7148 - val: 0.8263\n",
      "[212/300] train: 0.7106 - val: 0.8206\n",
      "[213/300] train: 0.7111 - val: 0.8209\n",
      "[214/300] train: 0.7128 - val: 0.8299\n",
      "[215/300] train: 0.7110 - val: 0.8252\n",
      "[216/300] train: 0.7156 - val: 0.8290\n",
      "[217/300] train: 0.7158 - val: 0.8266\n",
      "[218/300] train: 0.7109 - val: 0.8191\n",
      "[219/300] train: 0.7110 - val: 0.8268\n",
      "[220/300] train: 0.7144 - val: 0.8187\n",
      "[221/300] train: 0.7168 - val: 0.8193\n",
      "[222/300] train: 0.7113 - val: 0.8190\n",
      "[223/300] train: 0.7119 - val: 0.8200\n",
      "[224/300] train: 0.7104 - val: 0.8229\n",
      "[225/300] train: 0.7167 - val: 0.8261\n",
      "[226/300] train: 0.7124 - val: 0.8258\n",
      "[227/300] train: 0.7115 - val: 0.8308\n",
      "[228/300] train: 0.7107 - val: 0.8294\n",
      "[229/300] train: 0.7113 - val: 0.8271\n",
      "[230/300] train: 0.7091 - val: 0.8368\n",
      "[231/300] train: 0.7112 - val: 0.8166\n",
      "[232/300] train: 0.7109 - val: 0.8267\n",
      "[233/300] train: 0.7109 - val: 0.8291\n",
      "[234/300] train: 0.7112 - val: 0.8287\n",
      "[235/300] train: 0.7129 - val: 0.8259\n",
      "[236/300] train: 0.7107 - val: 0.8216\n",
      "[237/300] train: 0.7127 - val: 0.8173\n",
      "[238/300] train: 0.7060 - val: 0.8230\n",
      "[239/300] train: 0.7066 - val: 0.8273\n",
      "[240/300] train: 0.7074 - val: 0.8304\n",
      "[241/300] train: 0.7125 - val: 0.8321\n",
      "[242/300] train: 0.7116 - val: 0.8243\n",
      "[243/300] train: 0.7103 - val: 0.8259\n",
      "[244/300] train: 0.7138 - val: 0.8219\n",
      "[245/300] train: 0.7130 - val: 0.8312\n",
      "[246/300] train: 0.7063 - val: 0.8278\n",
      "[247/300] train: 0.7087 - val: 0.8280\n",
      "[248/300] train: 0.7057 - val: 0.8265\n",
      "[249/300] train: 0.7073 - val: 0.8206\n",
      "[250/300] train: 0.7110 - val: 0.8186\n",
      "[251/300] train: 0.7113 - val: 0.8181\n",
      "[252/300] train: 0.7117 - val: 0.8330\n",
      "[253/300] train: 0.7052 - val: 0.8268\n",
      "[254/300] train: 0.7087 - val: 0.8295\n",
      "[255/300] train: 0.7102 - val: 0.8241\n",
      "[256/300] train: 0.7111 - val: 0.8266\n",
      "[257/300] train: 0.7060 - val: 0.8319\n",
      "[258/300] train: 0.7096 - val: 0.8252\n",
      "[259/300] train: 0.7068 - val: 0.8186\n",
      "[260/300] train: 0.7033 - val: 0.8306\n",
      "[261/300] train: 0.7026 - val: 0.8246\n",
      "[262/300] train: 0.7096 - val: 0.8316\n",
      "[263/300] train: 0.7058 - val: 0.8240\n",
      "[264/300] train: 0.7086 - val: 0.8290\n",
      "[265/300] train: 0.7071 - val: 0.8230\n",
      "[266/300] train: 0.7058 - val: 0.8220\n",
      "[267/300] train: 0.7036 - val: 0.8336\n",
      "[268/300] train: 0.7102 - val: 0.8277\n",
      "[269/300] train: 0.7071 - val: 0.8237\n",
      "[270/300] train: 0.7074 - val: 0.8241\n",
      "[271/300] train: 0.7062 - val: 0.8280\n",
      "[272/300] train: 0.7087 - val: 0.8318\n",
      "[273/300] train: 0.7119 - val: 0.8300\n",
      "[274/300] train: 0.7068 - val: 0.8277\n",
      "[275/300] train: 0.7057 - val: 0.8362\n",
      "[276/300] train: 0.7080 - val: 0.8253\n",
      "[277/300] train: 0.7050 - val: 0.8278\n",
      "[278/300] train: 0.7025 - val: 0.8254\n",
      "[279/300] train: 0.7067 - val: 0.8267\n",
      "[280/300] train: 0.7077 - val: 0.8309\n",
      "[281/300] train: 0.7075 - val: 0.8308\n",
      "[282/300] train: 0.7073 - val: 0.8287\n",
      "[283/300] train: 0.7055 - val: 0.8322\n",
      "[284/300] train: 0.7067 - val: 0.8349\n",
      "[285/300] train: 0.7085 - val: 0.8284\n",
      "[286/300] train: 0.7094 - val: 0.8335\n",
      "[287/300] train: 0.7078 - val: 0.8367\n",
      "[288/300] train: 0.7036 - val: 0.8286\n",
      "[289/300] train: 0.7030 - val: 0.8271\n",
      "[290/300] train: 0.7052 - val: 0.8263\n",
      "[291/300] train: 0.7059 - val: 0.8216\n",
      "[292/300] train: 0.7070 - val: 0.8325\n",
      "[293/300] train: 0.7060 - val: 0.8325\n",
      "[294/300] train: 0.7051 - val: 0.8290\n",
      "[295/300] train: 0.7061 - val: 0.8311\n",
      "[296/300] train: 0.7074 - val: 0.8250\n",
      "[297/300] train: 0.7070 - val: 0.8299\n",
      "[298/300] train: 0.7036 - val: 0.8342\n",
      "[299/300] train: 0.6990 - val: 0.8303\n",
      "[300/300] train: 0.7009 - val: 0.8231\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEQCAYAAABcE6TVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5lUlEQVR4nO3dd3hUVf7H8ffJtPRGQoAECBB6VYqCgrggggq7NsSCq2tbdS1b3LXvLu6u/Fx1VVx7x4IN+6oICCpFadI7hJAEQkJ6mUxm5vz+OJNKgCSkMfN9PU+eSe7ce+fMXPjcM9977r1Ka40QQojAENTWDRBCCNF6JPSFECKASOgLIUQAkdAXQogAIqEvhBABxNrWDTieuLg4nZyc3NbNEEKIk8aaNWtytNbx9T3X7kM/OTmZ1atXt3UzhBDipKGU2ne056S8I4QQAURCXwghAoiEvhBCBBAJfSGECCAS+kIIEUAk9IUQIoC0+yGbQoj2q6CggJycHFwuV1s3JSDY7Xbi4uKIiopq8jr8NvTnLNrJkK7RnNWn3vMThBAnyOl0kpWVRVJSEiEhISil2rpJfk1rTVlZGenp6TgcDoKDg5u0Hr8t7zy3dDff7chu62YI4beys7OJj48nNDRUAr8VKKUIDQ0lLi6O7OymZ5vfhn6I3UKpy9PWzRDCbzmdTsLDw9u6GQEnIiICp9PZ5OX9OvSdFRL6QrQUt9uN1eq3FeJ2y2q14na7m7y834Z+qM1KqavpH4wQ4vikrNP6TvQz99vQD5byjhBCHKFBoa+USlJKzVFKrVBKlSqltFIqubEvppS6x7fsD41uaSOF2iyUSegLIUQtDe3ppwDTgTzg+6a8kFKqJ3AfcKgpyzdWqN1CmdT0hRCN8PHHH/P44483+3qvueYa2st9QRoa+t9prRO01ucB7zfxtZ4F3gK2NnH5RgmxS09fCNE4LRX6DzzwAB999FGzr7cpGnToXWvtPZEXUUpdAZwKXA7MP5F1NVSITWr6QoiWUV5ejsPhaPD8vXr1asHWNE6LH8hVSsUA/wH+rLXObenXqyTlHSFEY1xzzTW8/vrrZGRkoJRCKUVycjJLlixBKcX8+fO54YYbiI+PJyEhAYBdu3Yxc+ZMevToQUhICD179uTmm28mLy/viHXXLO+kpqailOL555/nwQcfpHPnzkRHRzN16lTS09Nb9H22xiDbfwM7gNcauoBS6kbgRoBu3bo16UVD7FYp7wjRBv7+2Wa2ZBa2aRsGdInkr1MHNmqZBx54gOzsbFatWsWnn34KgMPhoKCgAIDbbruNKVOmMHfu3KqTozIzM0lKSuKJJ54gJiaGPXv28K9//YvzzjuPFStWHPc1H374YcaMGcMrr7zCoUOH+OMf/8iVV17J0qVLG/mOG65FQ18pNRa4GjhVa60bupzW+gXgBYARI0Y0eLmaQmwWXB4vbo8Xq8VvR6YKIZpJr169iI+Px263c/rpp1dNX7JkCQCjRo3ipZdeqrXMuHHjGDduXNXfY8aMISUlhbFjx7Ju3TpOOeWUY75m9+7defvtt6v+zs7O5q677iIzM5MuXbo0w7s6Ukv39J8HXgbSlVLRNV7T4vu7TGtd3hIvHGq3AFBa4SFSQl+IVtPYHvbJ4sILLzximsvl4tFHH+WNN95g3759tS6PsH379uOG/vnnn1/r78GDBwOQlpZ20oZ+f9/Pb+t5Lg/4PfBES7xwiC/0nS4PkcG2lngJIUQA6dy58xHT7rnnHubMmcODDz7ImDFjiIiIID09nYsuuqhB18eJjY2t9XflweETubbO8bR06J9dz7QnAAtwG7CrpV64qqcvdX0hRDOo7/IH8+bN4+qrr+b++++vmlZcXNyazWq0Boe+UuoS36/DfY9TlFLZQLbWeqlSqjuwG5iltZ4FoLVeUs968gFrfc81pxCbhL4QonEcDgdlZWUNnr+0tBSbrXYl4dVXX23uZjWrxvT0656U9YzvcSkwHlCYHny7KKBXlndk2KYQoqEGDBhAbm4uzz77LCNGjDjujUomT57M66+/zuDBg0lJSWH+/PksX768lVrbNA0Ofa31MS/tprVOxQT/8dYzvqGveSJC7eatybBNIURDXX/99axcuZJ7772X/Px8unfvzmuvvXbU+efMmYPWmvvuuw+A8847j3feeYdRo0a1Uosbz28vhl1d3pHLKwshGiYsLIx33nnniOlHG3EeFxfHvHnzjjt/3R1HcnJyvescP378UV+rubSLUkxLkPKOEEIcyW9Dv3L0jpR3hBCimt+HvozeEUKIan4b+sE2Ke8IIURdfhv6DmsQQUrKO0IIUZPfhr5SilC7Vco7QghRg9+GPpgST1mFDNkUQohKfh36oXa5e5YQQtTk96EvNX0hhKjm16EfIrdMFEKIWvw79OXm6EKINlB5D9xjXbenrfh16Et5RwghavPr0A+xW6W8I4QQNfh36NuC5CqbQogGee+991BKsWHDhiOemzJlCsOGDQPg6aefZvTo0cTGxhIdHc3pp5/OF1980cqtbTq/vbQyICdnCdEWvrwbDm5s2zZ0GgxTZjdqkWnTphEVFcWbb77JI488UjU9KyuLhQsXMnu2WV9qairXX389ycnJuN1uPvvsMy644AL+97//MWXKlGZ9Gy3Br0M/xG7BKeUdIUQDBAcHc+mll/L2228ze/ZsgoJMIeSdd95Ba80VV1wBwKOPPlq1jNfrZcKECezYsYPnnntOQr+thdosVHg0FR4vNotfV7KEaD8a2cNuT2bOnMlLL73E4sWLmThxIgBz585l4sSJdO7cGYA1a9bw17/+lVWrVpGdnV1105O+ffu2Wbsbw6+TMEQuryyEaISxY8eSnJzM3LlzAdi6dStr165l5syZAOzfv58JEyaQm5vLnDlzWL58OatWrWLy5Mk4nc62bHqD+XVPvzL0nRUeokJsx5lbCBHolFJcddVVPPHEEzz77LPMnTuX8PBwLrzwQgC++uorCgoKeO+990hKSqparrS0tK2a3Gh+3dOXG6kIIRpr5syZFBcXM3/+fN566y0uvvhiQkNDgepwt9mqO5E7duxg2bJlbdLWpvDr0JebowshGqtPnz6cdtpp3H333aSlpVWVdgAmTpyI1Wrl6quvZsGCBbz++utMmjSJbt26tWGLG8e/Q99uqldyVq4QojFmzpxJRkYGiYmJnH322VXTBw4cyFtvvcW+ffuYNm0ajzzyCLNnz2bcuHFt2NrG8euaftXN0WXYphCiEW699VZuvfXWep+bPn0606dPrzVtxowZtf5OTk6uGtXT3vh3T98mNX0hhKjJv0O/sqcvoS+EEICfh76Ud4QQojb/Dn2bOWQh5R0hhDD8OvSD7ebtlcmQTSFaRHs9WOnPTvQz9+vQt1uCsAQp6ekL0QJsNhtlZWVt3YyAU1ZWVuvksMby69BXShEqt0wUokV07NiRjIwMSktLpcffCrTWlJaWkpGRQceOHZu8Hr8epw8Q6pBbJgrREiIjIwHIzMykoqKijVsTGGw2GwkJCVWffVP4feiH2a2USE1fiBYRGRl5QgEkWp9fl3fA9PSlvCOEEIb/h77dSkm59PSFEAICIPTD7NLTF0KISn4f+qEOqekLIUQlvw/9MLuF0nLp6QshBARA6IfK6B0hhKji96Ef5hunLyePCCFEA0NfKZWklJqjlFqhlCpVSmmlVHIDlhuhlHpBKbXNt1yaUuotpVSPE255A4Xarbi9GpfH21ovKYQQ7VZDe/opwHQgD/i+EeufAQwEngKmAHcDpwKrlVJdG7GeJgurvDm61PWFEKLBZ+R+p7VOAFBKXQ9MauBy/6e1zq45QSm1DNgL3AA82NCGNlWow7zFEpebmDB7S7+cEEK0aw3q6Wutm1QbqRv4vmn7gGwgsSnrbKwwu1xTXwghKrX6gVylVH+gI7C1NV6v8u5ZclauEEK0cugrpazAc5ie/sut8ZqVoS89fSGEaP2e/tPAGOAqrXXe0WZSSt2olFqtlFqdnX1EhahRwipr+tLTF0KI1gt9pdTDwI3Ab7TWC441r9b6Ba31CK31iPj4+BN6XenpCyFEtVa5nr5S6j7McM3btdZzW+M1K4XVGL0jhBCBrsV7+kqp24F/APdpree09OtVef4sWD6nuqcv4/SFEKLhPX2l1CW+X4f7HqcopbKBbK31UqVUd2A3MEtrPcu3zAzgCeArYLFS6vQaqyzUWm850TdwVHl7IT+NULv09IUQolJjyjvv1/n7Gd/jUmA8oAALtb89TPZNn+z7qalyuZZhj4DyYixBimBbkNT0hRCCRoS+1lod5/lUTMDXnHYNcE0T2nXiHOHgKgLMCVrFMnpHCCH8+Cqb9nAoLwYgMsRGYVlFGzdICCHanv+GviMcXNWhXyChL4QQ/hz6EVU9/SgJfSGEAPw59O0RVT19CX0hhDD8N/Qd4VBeCEBUiFVCXwgh8OfQrzyQqzVRvgO5Xq/cMlEIEdj8N/Qd4aA94HYSFWLDq6FYTtASQgQ4/w19e4R5LC8mOsTcMaugVEo8QojA5r+h7wg3j64iIkNsAFLXF0IEPP8Nfbsv9MuLifKFvpygJYQIdP4b+g5fecdVHfrS0xdCBDr/D/3yYqJCJfSFEAL8OfTt1TV96ekLIYThv6HvqK7ph9ktWIKUhL4QIuD5b+hXHcgtQikll2IQQggCIfR919+JCbWRW+JqwwYJIUTb89/Qt1jBGgLl5kYqceEOcorL27hRQgjRtvw39KHWNfXjIhzkFEtPXwgR2Pw79GvcPSs+3EFOkfT0hRCBzb9D31F9Tf24cDtF5W6cFXKDdCFE4PL/0C+vDH0HgNT1hRABzb9D3x4OruoDuYDU9YUQAc2/Q99RXdOPi/CFvtT1hRABzL9D3x5eq6YPUt4RQgQ2/w59R0StcfogoS+ECGz+Hfr2cKgoBa+HYJuFCIdVavpCiIDm36HvqH0pBnOClvT0hRCBy89Dv/qa+mDq+hL6QohA5t+hX+eia+b6O1LeEUIELv8O/SN6+lLeEUIENv8O/Rp3zwIT+vmlFVR4vG3YKCGEaDv+Hfo17p4FEBdhxuoflhKPECJA+Xfo11PTBxmrL4QIXP4d+lU1/donaGVL6AshApR/h36N++RCjUsxyPV3hBAByr9D3xYCylJPeUdq+kKIwOTfoa+U70qbpqcf5rASYrNITV8IEbD8O/QBgqPBWVD1Z3yEg2wp7wghApT/h35IDJTlVf3ZOSqYAwVlbdggIYRoO/4f+qGxUJpb9WdidAgZeRL6QojA5P+hX6ennxgTwsFCp5yVK4QISA0KfaVUklJqjlJqhVKqVCmllVLJDVw2WCn1b6XUAaVUmW8d406o1Y1RN/SjQ/BqOFjgbLUmCCFEe9HQnn4KMB3IA75v5Gu8DNwAPAhcABwAvlZKDWvkepomJAac+eA1PfvEmBAAMvKlxCOECDwNDf3vtNYJWuvzgPcbunKl1FDgCuD3WusXtdaLMDuPNGBWo1vbFCGxoL1QbkbwdIk2oZ8poS+ECEANCn2tdVML4NOACuDdGutyA/OAc5VSjiaut+FCYsyjr8ST6At9OZgrhAhELX0gdyCwV2tdWmf6ZsCOKRu1rDqhH2yzEBdul/KOECIgtXTox2KOA9SVW+P5IyilblRKrVZKrc7Ozj6xFoT6XqK05lj9EDLlQK4QIgC1dOgrQB9l+lFprV/QWo/QWo+Ij48/sRbU6ekDJEQGc6hQQl8IEXhaOvRzqb83H1Pj+ZZVT+h3inJwUEJfCBGAWjr0NwM9lFKhdaYPAFzArhZ+fXPtHYCy6v1Lp8hg8ksrcFZ4WvzlhRCiPWnp0P8UsAGXVk5QSlmBy4AFWuuWv/KZxQqOqFqXYkiIDAYgS3r7QogAY23ojEqpS3y/Dvc9TlFKZQPZWuulSqnuwG5gltZ6FoDW+mel1LvAE0opG7AXuBnoAVzZXG/iuMI7QvHBqj+rQ7+c7h3CWq0ZQgjR1hoc+hx5UtYzvselwHjMwVkLR357uBb4J/APIBpYD0zWWq9tZFubLrorFKRX/dkpyoS+1PWFEIGmwaGvtT7eiJtU6hmVo7UuA/7g+2kbUUlwcFPVn1U9fRm2KYQIMP5/lU2AqG5QcggqTMhHBps7aElPXwgRaAIk9JPMY2EGAEopEiIdcqVNIUTACazQL9hfNalXfDg7soraqEFCCNE2AiP0o7uax/zq0B+YGMXu7GJKXe42apQQQrS+wAj9iC6AqjWCZ1CXSLwath6Q3r4QInAERuhb7RDRuVZ5Z1BiFACbMwvaqlVCCNHqAiP0wdT1a4R+56hgYsPsbEyX0BdCBI7ACf06J2gppRjWNZrV++q78rMQQvinwAn9qCQT+t7qm4CdkRLH3pwS0vPq3uNFCCH8UwCFflfwuKCk+qYsZ6bEAbB81+G2apUQQrSqwAp9qFXX75MQTly4gx925bRRo4QQonUFUOgfeYKWUoozUzqwfHcOWtd3gy8hhPAvgRP69ZygBaaun1PsYrucnSuECACBE/rBUeCIrNXTBxP6AD/slBKPEML/BU7oA8R0h7zUWpO6RIfQMz6MBVuy2qZNQgjRigIr9DukwOEjb8t7xahu/LQ3V3r7Qgi/F3ihn7cP3K5ak2eO7k5idAiPfbO9jRomhBCtI8BCvzdozxElHofVwo3jerIuLZ+1aXKGrhDCfwVY6KeYx3pKPJcMTyIi2Mqry1Jbt01CCNGKAiz0e5nHekI/zGHlV8MS+WbLQbnGvhDCbwVW6IdEQ1g8HN5Z79PnDe6Ms8LL4m2HWrddQgjRSgIr9ME3gmd3vU+N6hFLXLiDF77bI7dSFEL4pQAM/V71lncALEGKP03qw57sEn7z2iq5NIMQwu8EYOinQHEWOAvrfXrGqG48OHUA6XllbM6sfx4hhDhZBWDo9zaPR+ntA0zo15EghZylK4TwOwEY+pXDNuuv6wN0CHcwonssH6/LwFnhaaWGCSFEywu80I/tASroqCN4Kt02IYW03FL+/MEGuY+uEMJvBF7oWx0Q3e2Y5R2Asb3jufaMZD5dn8nMV37E5fYec34hhDgZBF7ow1EvvFbXX6cO5IWZw8kvrWCZ3F1LCOEHAjj0d0MDhmSO79uRyGArn63PbIWGCSFEywrc0HcVQ9HB485qtwZxwdAufL7hAFtkCKcQ4iQXuKEPDSrxAPxpUl+iQm1c+dJKHv9mRws2TAghWlaAh/6xR/BUig2z8+o1IxnQJZKnFu1kU4aM5hFCnJwCM/QjE8Eacsyx+nUNSozimSuHE2a3cM/8jcxZtJMKj4zoEUKcXAIz9IOCIL4v7F3aoIO5laJCbPx6TDJbDhTy2Dc7+PUrP7Fi9+EWbKgQQjSvwAx9gFE3wsGNsO2LRi1217l92TprMv+6cDBbDhRy5Usr2Xe4pIUaKYQfW/pv2DS/rVvROFrD8jmQu+fY8xVkQHmxuTXroodg4wcNX7+3ZSsIgRv6Qy4ztf3P7oADGxq8mFIKuzWIK07rxtd3jsMaFMQ/v9jK5xtkSKcQx+UsgAon5O+Hb/8JP714/GW8Xtj+JexaWD2toswEa30y1sKnt9W+F3Z5kVlHZaBWlIHXA7u/rf1tv+ggPD8O0n6snqY1bP0c8tNg92JYcL/ZYdVUchiytpjXXPkcPDkU3pkB714J3z8KX/zBtKHS1s/g41vh57ehNBeKs03bPrgW/jsKCtKP/7k0kbXF1tzeWaxw+bvwxjT44Ddw648QZGnUKhIig7no1ETmrdrPgi1Z5Ja46N85khHdY1BKtVDDhfBZ+SyU5MCEB05sPTm7YMF94HXD1CchKun4y5TkwLszYeR1kLEGep8DvX5hQs9ig/r+/RekwwvjzTxxvQFtvm2XF8MP/zG95z7nmg5Z5fJFWfDe1bB/JViD4Y4NEJEAn/8eNn0IZ99rLqLY+xxztj3Amldh7RsmSFUQ/OoZ+ORW2PY5XPgChHeEty6FAb+ETR/AObOg+BCccYdZ54H18PHNcPMy85pf3Q0/PgdBVgjraF5j2+ew5zJIGGzuuf36VKgogdAOUHoY4vpA6vdm3pE3wKoXYfE/4Ky/QHAUfPFHKMuDn980rxESCwOmweaPwGKHNy+B3/5gcqqZqfZ+zfgRI0bo1atXt9wLbP4I3r8GLnkVBl3U6MVLyt1sSC/g4S+3ssF3jZ5fDevCY9OHYQmS4BctpDQX/jMQ3E4ThMvnQOZauO4b8LiqA7A+bhdkb4VOQ8xghvk3+E5W9Jhvv9d9A0WZsO5NGPEbWPxPE4ylOfDhdTB5NqStMCFW08S/m/A++z447cbq6bl7Tc87axN4KszOYeunYHGAp9yE9uGdZoBFYQacMhOmzTGh+PIkM+2sP8OiWRDX1+wwtn9pdi4VpeY1YnrATUtNoD451ARxpejukL8PHFFgD4Wuo2DLJ0d+LgN+aXr6h3eb99rvArODWP0KjLzefDNY8xqkTKj+1uGIMu8hPMG0cfWr0H00TPgrvD0d4vvB5Ifh/Wths6+UlTgCMlbDJa+YbyWHd8GOrwENw68163/3KrMDHn5N4/5d+Cil1mitR9T7XMCHvtcDz5wOjgi4YXGTV5OeV8r/Nh6goKyC/367m9sn9KZXfBhTh3QhSMJf1CdjrelVp/4AnYdW38MZTLmgYL8JwvB4OLTVBKYjwvQE178Dix8CFJxyJax/F7wV0PU002u9YbHpuYd3ND3pdW+a8sTI60xwLX8KEoebXjqYANLahPqUf8OXd5npvSbA7kUw8W8maPf/CFHdzI4lKsmE7KkzzU6ncl3hneB3P5ke7M5vTC8bDSnnmHl7joeDm6AwE96+1Cwz8W8w5g5YPMvsOM78Axz42Xw2Mz+G5DPMjmPTR+bESjTcshJsIaZn/v41MPRyE7xPDoXx90KnwXBwAyz9PzjjTug9CV6dbF6v4wCznlN/Dd/+C7qPqe6Zn32f+Zy/utv8fdrNJriVMt9wgqPh49+aHWT2NtO7P+NOiO569G2ttdkpr38Xfnoe7OFw1y7TfjDlouytcOHz5hvFy5PM9r99XfU8jSChfzzLnzZfb6/5wtQJO6RA0vAmrUprzVUv/8iyXWZUz9ShXbBbgvjLlL50jAhuzlaL9sJdDt8/BrsWwS//Cx37mdB+dQqc/yj0GAeuEhPUhQdMSBdmmpJAkM30FKO6wo1LICzOHNz89DZfuGF6vjsXmDBXyvRcXSUm1OxhpteMMr17t9MsY48wPfdfPQPLnoTMdSZMgmzVPWSvG8bcBikTocdZZqfy75Tq56iRDdYQcJeZARA/vw3aC1e+D8lnmud3L4a5F5owPbSl9ufTcSDMeBNie9aeXlEG/0o07+mP281719ocZ1v7upnn/MdMLxtMzVt7YesnphQ07q7qdS38m9lZOCKhvBB+uww6DTLrcxaY+2ODKeVu+hCmz4X+U81rOwvAFgarX4b01TDpIYjoBNnbzWdWc2d8orSGJbPNznL0LUefL321+dbR7/z6S2XHccKhr5TqCvwHOAdQwELgTq11WgOW7QY8BJwNxAHpwHvAw1rr4w57aZXQL8qCx/uZf1Bgele/39ykDxsgM7+MD9ekszenhPnrzMGmXvFhvPzrkXTvECr1/raQv9/cMS2p3v8HtXk9JkhVEPSfBmkrIWcHnHKVOe5Tmmt6sH0mmR509jbzGGSFgRdB/wtMr3rB/SZQLQ7TYy33ndTX5RTzb84WbEobHXrBqpdNXfr8x+CJIdB5CIy53Ywu2zDPLDf0chPMm3wjQWZ+bEoVK58xr5G7B/Z8a9a/cyGExpqyhsUOl74GnYeZnm5+Gsz8yPQ2u46q/d4/vB42vg+Dp5va9O5FZkfhrTA99Jkfmx1LkK12vVlrE6Y9x5vPwuMy0+J6Q98pR++tvjTRXPX2kleqp3ncpift9ZjpDfn/orWps2+ab0o4U+eYodl1FR+CVS/B2D+B1X789Z6kTij0lVKhwHqgHLgfs/v/BxAKDDlWcCulwoB1gA34G5AGjAT+Dnyqtb7seI1vldAHmH8j5Ow0/0m/e8R8PU5sWm+/kser2X6wiEJnBTfNXUOhs4IQm4X3bhrNoMSoZmq4HygvNj1W7TWhc+rV0LG/ObjV2P+YrlITGKW5ptcd092s/7kzTC/79rW1D1Q6C02vObJz9bQls2HJw+b3zkNN+QDg3IdN7/r9a0zNt7IGDdW90VUv+VaiqNVTPuUqGHaVCeZPbjG14Gu/MOsD801h0SxIGmnKPretNj3j8mJ4eqTpeVaWH18513y7uHFJ7UD0uE04W+ymt+6pMLX3hEHmcwBTX9+3HIZdUX+Ybv8K5l0O1y80I1sWPwRj/2iWm/i36vU0F1ep2ZEe6xiEaLQTDf07gMeBvlrrXb5pPYCdwJ+11o8fY9lJwNfAuVrrBTWmzwb+BERqrUuP9fqtFvpam/8EpbnwSA8zbeT1pufVDDLyy5j3Uxpv/5hGclwYf5s6EKVgYJfIwOr5e721e2CFB+DpERAWD2fcbkZlxPUxZbaRv4FJ/zj6uir/7X51j3k8Z5YZ8rbtC7MTURYYOsOEXNYm0xMfMA0uesn0Zn943HwDcJeZr9HlRTDsSlj4d4hLMV/Bt3xietzZ20z5BkzvNb6veW7EdSaoB15oRqe8OsWUB9OWmxryzgUm7H/13+o2L59jSj5dhlW/F3c5vHYBpP9k6szTnqp+riDd9OTD483frhKzg3REnNCmOKqSwxDWwQxBfO18+M3XEN+nZV5LtIgTDf1FQLDW+ow605cCaK3POsayFwCfAaO11itrTL8b+BcQcbwST6uFfk1vXgK7vjG/37Xb1BqbyXur9/PnD6rPCxjVI5YrRnVDKXhteSoPXDCAU7vFNNvrtTlXqQnX/lMhJAaeGW1KDb3PMc9X9qqDo03o6hq3pwyOgr7nmWA+887qZQDK8uH1C8xOurK33XEgHNoMEx6EQRfDR781veaEAaYWnZdqDur1nmRqpiEx0PMss45di0zQVY76uPQ189oHN5pvfCXZ5uBnkM0M7bM6zM6l/9TavVStTT181cswZDqkrzIHCRsa0M5CU3aprzQhRAOdaOgfBD7RWt9UZ/ozwKVa6/hjLBsMbAAOADdjyjujgLeAj7TWxziSYbRJ6Jflwf6fzJCraU+bEQfNaGN6AZkFZWTml/Hfb3eRU1x9Ekm/ThH857Jh9IwPw2Ft3HkD7UZZvvkMY3uYkSKf3WHq4wMvNHXfbqPh8nmmZvza+ebgX+ch5kBcfH+zbJdTYMeXgDJllPIimPofWD/P1NjdThOwMcnmgF3f8+CT35kd9G1rqmvIld/gKn9f9ZL5ZuB1myF+nYdWP6c1/PQC7PsBLn5ZSg7ipHWioe8CHtda311n+j+Au7XWxzx7QCnVEfgQOLPG5JeAm7SuPHJ6xDI3AjcCdOvWbfi+ffuO2cYWoTU8MdgM0ep2Gsx429RdSw/DBU+AM98MUes0xAyLayKPV7PtYCG5JS4Kyir43dvrAAi1W7h7Sj+uHp3cLG+nQbI2mzLGoItrT9/9rSlTjLjOjKfuM9kEaV6qCfExt5seqiMCvnnQnMiCNgcD81JN/bs013xmdVlD4KoPILILzBluRmScdbdZ/2d3mF5y0kh47kxTpw6LN+OplcWcyJMyoXpdOTvNzuV4oy0yfzYHMwdMO6GPS4j2qjlC/zGt9T11pv8T+MuxQt/X0/8S6IIZwVPZ038QeEtrffPxGt8mPf1Kq14yp4lnbzMHw7I2melXvA8r/wt7lpi/Ow2GK94zwXWC1qXlsT+vjA/WpPPdjmw6RjiYfko85274A+UjbmLExOnHXkHuHnOQMKxD9TStTS/a7aw9aiHzZ1MbTjzVDJ/77ygThtcthK4jTf19x1fmRJGaZZeUieZn7VxTTukz2ewUUiaax+HXmiFyy5406x9/rymPrHoRBl9qetkdepvRJf3ON6M3wBww7dDbjL6oK3u72XF0HmLq9UKIozrR0M8CPm5ieedW4GkgRWu9u8b0G4AXgGFa6/XHev02DX0wZYXH+pkx0+PvgXVvmR5reaEZ1RAcZU6siEgwo0Wiu5s68PePmh2FqwSmzDY94cqRD1qbGvLepWactNsJP78Dwy6HDe/C0CvwRHTh/dX7+XrzQTrs+oBHbc+zxdudTVM/J8ZWwbiN9+LoPtKcxFJZ/3WVwH8GmZ1QSDTsW2GCODQWVjxt5rFHVPeOt3xsDm6eerUJ3Iw1ZocR3c0Mbdz5jQnt0A4w7k/mLMTobub0/7JcQEFwpBnnXGnAL2H6G+b3tJWm1z95tgn9F8abnWPN3rkQotmdaOgvBuxa6zPrTF/iW/5YB3KfA6ZrrWPrTB8K/AxcrrWed6zXb/PQB/j6PnPyyY1LYM9SMy660yCYOMsE7r4V8N5ME2xghszZw0zv2eMyBwxLD8PZ95uzDIOsJnABIpNM+cPtNIHsKjIHDk+/xZQyUr+nYv37WIszUR4XD1VcyYigHUyxrAKgIH4EqyuSGcBeOkeHVp9VCGaESOoy00s/9WpzWvn2/5lx1F6P2YmlLTdjyBMGmnJMXG9453KzTJDV9Mp//Tn0GFu9Xq3NeGdXsTm1fPE/zBmJe5eay1nE9qj/c3QWmp2EEKJFnWjo3wk8CvTRWu/xTUvGDNm8W2t91DGNSqm/AX8FelcO9/RNvxF4Hhintf7+KIsD7ST0ofYBwfqU5Jjee/Y202O+6EXT+18+x9S5IzqbUSbKYgJ1zO2QPBY+v9NciyS6O3z7D+h+BuxbVr1eZTFnUJ7/GHrVS6hMU/OfXTGDw0TyZ+s8wnGyTyfQL2g/aY7edPZkYo3qgrplhTl9X6nq8eBg2ldRVn02pcdd+0Sb7V+aUSeDLzWnyw+59Ojvu8JpdjQpE5t8MpsQonmdaOiHYU7OKqP65KyHgAjMyVnFvvm6A7uBWVrrWb5pyZjROweBf2Jq+iOAB4AdwKijHcyt1G5C/0Q4C03PeOn/masCwpG9Ya3NdUISBpkTYTzlpr6eOLz6QLHXa8ZxRybywW5FXLidrzZkclqvDuzKLsG1cylrCiPRRVm4HVEUhCbTIdzOxP4J3DC2J3arDAMUIhA0x2UYulH7MgyLMJdhSK0xTzKwF/i71vpvNaYPwJyNOxpzGYb9wKfAP7XWecd7bb8I/Vbk8Wo+35DJ6tQ8ipwV7M8rY82+PPp1iuCx6UNxVngoLvdwVp+jHooRQpzk5IJrAe6bLVnc//FGnBVe3B4vJS4P/TpFMLBLFEO7RrE5o5CHfjUIuzUIl9tLqctNdKj/XpdECH93rNAP3JuoBJBzBiTQNyGCaf/9AZs1iKuHJ/HT3lw+XJvO/HXp5qqvBWXcObEPb/24jx925rDs7l9gs0g5SAh/I6EfILp1COXTW8/EozU94sJwe7yc/9QPHCgo44axPXnx+z1c9vwK3F7zzW/+2nSyCsvxeDVn9Y2vujREfqmLLQcKGdOr+S5NIYRoPVLeCWB5JS6Ky910jQ2lyFnBVS//REZeGaUuN6UuczJW5YCcaUO7sDenhPzSCtJyS5l/yxh6xoVJGUiIdkhq+qJB3B4vJeUe7v9kE59vyOTN605jcFIU1766ijX78uiTEE5uiQuX24vG3CryjJQ4th4o4i+T+9K9QxhBCkLtVl5fnspdk/sSFy7XrxGitUnoi0bJKnSyJ7uE0b3MpRxKyt3szSlhUGIUWmueWLiTJxftZGRyDOv3F5AUG8Ke7CMvljppQAIxoXZ+eUoXlu86zLaDhdwxoQ/LducwbWgXPF5NUkxIYF1aWohWIKEvmpXHq9mbU0JKx3AqPF60hh/3HiZIKXKKy1m2K4eyCi+frc+sWsYSpLBbgqjweHF7NdGhNvJLK/jtWb2Y0L8j3WJDWZWay+ieHegg3w6EOCES+qLV5Ze6eP67PZw7sBOLtx1i2tAuHCp08pvXV3HxqUks3naIyGAb27OKai03MjmGK07rRqnLw7fbskmKCeGykV35ZksWAzpHMnFAwhGv5fZ4sQQp+cYghI+Evmg3yt2eqvsEFDkruPejTZzaLZqDhU68Xs2L3++tmjc+wkF+qYsKT/W/0U6RwZw3uDPj+8bz1KKdDEqMYn16Pi63l+dnDicppp4rdPrsO1xCbomLU/zpJjVC1ENCX5w0Pt+QSeeoYOLDg+kcHUxeqYvP1h8gpWM4K/ccZlNGAd/vzAEg3GGluNwNgMMahMdXNhqZHMsTM4aRVVBO6uESVu45TFpuKQu2ZOH1at658XRGJptrAGqtySl2kXq4pGpaJbfHy+7sEvp2aqHbEgrRQiT0hd/QWvPi93twWC1cOiKJ3765loQIB7dP6M3clfvYmF7Aij2HiY9wkF1UDpjjCYnRIYzoHsPatDxSD5cyrGs0STEhfLvtEBoodXm4bERXzhvSmXdXpTH74iE88+1unv9uN1/eMZZ+nSLxeDWbMgqIj3DQJTqkbT8IIY5BQl/4La11rVp+udvDLx5dSk5xOX84pw9dokOYNDChqqSUmV/Gh2vSeXV5KrklLs4f0pkwu4WIYBsv/7CXIAVebe5dvC4tjwqP5poxydw9pR/3zt/I/HXmfrxDk6LoFBXM3VP6kxgdwk97cxnWLZqP1mVw7sAEOkYEA5BdVM7LP+xlxsiuJMeFobXmzZX7OK1nB/okyDcI0TIk9EVASc0podztPWZZJruonMz8MoZ2ja6aNuuzLXywZj+XjezKa8tT6RoTSpfoEH5KzQXA5fZy01k9iQqxsWjrIXZmFWG1BBFqt5CeV0ZEsJUip5sOYXYSIoOJDbOzfn8+ReVuTusRy6OXDuWrTQf55/+2Ehtm5/ZfpLByTy5lFR5mjOzKuQM78eiC7Xg1jOtjznju3ymSqBAbpRUeQm0WgoLMDu5QkZMKjyZRvnGIekjoC9FAlQeavV5NUJBiU0YBsz7bwtCuUZzdtyNjUqovP7Ejq4jZX27D7dUM6xrNWyv3cfXoZNan56O15lBROf06RRIXYef5pXuqlhuZHMOBAifpeWXERzgItVvYd7iUIUlRbEgvqPq2AZAYHUK4w8r2rCISo0O47sweJMeFctf7GygudzP74sHEhNrZm1PCuD7x7M8t5fSeHVix5zBfbTxIn04RXDoiichgGwBbDxSyKjWX7h3CGNE9hjBH7SuxeL2afbmldI0JwSrXXjppSegL0QrqlpoquT1eHvtmBx0jHMSG2flFv46E2a0cKHQSH+5Ao3l8wQ4++TmTcwcmcOfEPmzMKCC/rIJ752/EZlFcd2YPlu7IZlWquRp5YnQIiTEhrNmXh82icFZU35YixGah3O0h1G4OdEc4rAzpGsXG9AIKne6q+cIdVn73ixTySlwM7RrN6J4duOPdn/luRzYxoTYe+tUgesSFkV9awZebDnDL+BQ6RjiO2BlsyijgYIGTM3vHEWyzUFBWwavL9jJ5UCf6dTJ3Sntv1X76d45kcFJUS3z0og4JfSFOUvtzSwm2WYiPMCesrd+fT16pi5HJsXi0ZtqcH8grreCms3pyqLCccX3iWLztENagIP4yuR+7s4t5duluth8sYlSPWFLiwzlnQAKph0v499fba32ziAqxUebycMvZvVi09RAbMwpqtaVjhIP80goemDqAcb3jWLA5C5fHy7+/3g6YM7Bvn9CbG95YzYECJ907hDL7oiHkFJdz2zvriAi28sjFQxjVI5YgpYgItuL2aoqcbsIcFspcHhZuzSLYZiHMbiUi2MppPc1Z4dsOFrI5o5CxfeL434YDfLs9m8mDOnH5qG612phb4iKnuByHNYjuHcIAszMud3sJtllOaFtsP1hEz/iwk+LqsxL6Qvip/FIXpS5Pk0YTlbs97DpUTO+OETyzZBevLkvlyRnDGN+3I84KDwu2ZGG3KLwa7JYg/vLhBmLD7Ow8VFxrPaN6xDI2JY7HvtkBmHMpbjm7F3/9dDOV8dI1NgS3R3OgwFm1XNfYEIqcbvJLK+ptX7jDypK7xuPVmvOe/IGc4vKq5+LCHeQUl/Ofy4YSHWLnrD7x3PfxJt75KQ0Aa5DijetGsWBzFl9sPECRs4KHfjmIn/fn89uzetE1NpSc4nKeX7qbq07vzs6sYk7pFk2HcAdZhU7+9P56rjytG6N7xhHmsPDogh08t3Q3F56SyOPTh7LvcCmdo4OrBggcKnJSXuEl1G4hNsxchHDFnsMs2Z5NQmQwl43sSrjj6Bc1dnu8uDxeQu3Nc+FjCX0hxHEdrTxVU5nLwxsrUrFZghjbO46f9+czaUAnIkOsfPJzJjnF5Uwd2oWEyGBWpeZS7HSzNi2Pif0T6Nspgg3pBfy8Pw+vhi83HSQ6xMaE/h0pKfdgtwYxrGsU2UUusgqdPPT5FmLC7OSXurAEKZ6acQo7DxUTZrdw8fAkJjy2lEO+YbldooLJLHAy8/TujEiO4cFPNlNQVoHNojhnQAI/p+WT6dvhRAZbeeHqEXy0NoN3V++v+qbjsAZx4SmJ5Ja4WLAlq+o9Vx6gH9A5ki0HChmUGMmmjEIGdonkXxcOZtbnW1izr/omgL07hqOBXYeKsVkUFR5Nv04RvHvTaFbuOcyXGw/w495ctIbTe8aigSXbsykoq2BwYhQvXj2CTlHBJ7QtJfSFECedF7/bw3c7sxnYJYopgzrVGmkF8P3ObBZuySIqxMZPqblcOrwrFw9PAuCDNek8vmA7c644heHdY9mQns9zvl79g59sZm9OCV6tmdCvI0VON5cMT2JtWj7z16ZT7vZy7RnJJHcIo8TlZktmIecP7sykgZ14cuEOlu7IZmBiFJ+tz6TI6cZuDeL3E/sQH+Egr8TF5xsPEGwN4uJTk5g2rAvLd+dw09w1eLW5blVcuJ3TfWWrlXty0Vpzdj9z/akXvttDbJidZ648lfS8MiYP6tSkz05CXwgRcI72zSW3xMUrP+zlYKGTB84fQFSordZz3+0wxwuOdwwgM7+Mpxbt5NyBnTi7X8djzrsqNZdFWw/RMy6Mi4cnYQmq/xvV2rQ8ZrywEpfbS1SIjR/vndCkYxES+kIIcZJYtDWLn1Jz+fXo5Caf+S33yBVCiJPEhP4JTOh/5NVkm0v7H3skhBCi2UjoCyFEAJHQF0KIACKhL4QQAURCXwghAoiEvhBCBBAJfSGECCAS+kIIEUDa/Rm5SqlsYF8TFo0Dcpq5OeLEyXZpf2SbtE8nsl26a63j63ui3Yd+UymlVh/tNGTRdmS7tD+yTdqnltouUt4RQogAIqEvhBABxJ9D/4W2boCol2yX9ke2SfvUItvFb2v6QgghjuTPPX0hhBB1SOgLIUQA8avQV0p1VUp9oJQqUEoVKqXmK6W6tXW7/JFSKkkpNUcptUIpVaqU0kqp5Hrmi1FKvaSUylFKlSilFiqlBtczX7BS6t9KqQNKqTLfese1ypvxE0qpS5RSHyql9vk+w+1KqYeVUhF15pNt0oqUUucqpRYrpQ4qpcqVUulKqfeUUgPqzNcq28VvQl8pFQosBvoBvwZmAr2Bb5VSYW3ZNj+VAkwH8oDv65tBmRuUfgpMBm4DLgZsmG2SVGf2l4EbgAeBC4ADwNdKqWEt0Xg/9SfAA9yL+cyfBW4GvlFKBYFskzYSC6wBfgdMAu4BBgIrlVLdoZW3i9baL36AOzD/4FNqTOsBuIE/tHX7/O0HCKrx+/WABpLrzPNL3/Sza0yLAnKBp2pMG+qb79oa06zAduDTtn6vJ8sPEF/PtKt9n+0vZJu0nx+gr+/z/WNrbxe/6ekD04CVWutdlRO01nuBZZgPVDQjrbW3AbNNAzK11t/WWK4A+Iza22QaUAG8W2M+NzAPOFcp5WiWRvs5rXV2PZNX+R4TfY+yTdqHw77HCt9jq20Xfwr9gcCmeqZvBgbUM120vGNtk25KqfAa8+3VWpfWM58dU0oSTXOW73Gr71G2SRtRSlmUUnalVG/geeAgJqyhFbeLP4V+LKa+XFcuENPKbRHGsbYJVG+X480X28ztCghKqURgFrBQa73aN1m2Sdv5ESgHdgBDMCW3Q77nWm27+FPog6l11aVavRWikqJh26Sh84kG8vUMP8Ec07q25lPINmkrM4HTgSuAQswB9mTfc622Xfwp9POofy8XQ/17RtHycjn6NoHq7XK8+XLreU4chVIqGDMSpCdwrtY6vcbTsk3aiNZ6q9b6R631O8AEIBy42/d0q20Xfwr9zZh6V10DgC2t3BZhHGubpGmti2vM18M37LbufC5gF6JBlFI24ENgFHCe1npjnVlkm7QDWut8zGdYWYNvte3iT6H/KXC6Uqpn5QTfV6czfM+J1vcpkKiUqjyYiFIqEphK7W3yKWZM8qU15rMClwELtNblrdPck5tvLP5bmF7kL7XWK+uZTbZJO6CUSsCcU7TbN6nVtovfXHDNdwLWeqAMuB9T93oIiACG1NhTimailLrE9+sE4LfALUA2kK21XuoLoR+ArsBdmK+o92AOYg3VWu+vsa55wLm++fZiTiq6ABijtV7bOu/o5KaUehazHf4JfF7n6XStdbpsk9anlPoIWAtswNTy+wC/BzoBo7TWO1p1u7T1SQrNfMJDN8xX20KgCPiYOicMyU+zft76KD9LaswTC7yCqTWWAot8/4jrrisEeBwzjM2JGekwvq3f48n0A6QeY5v8TbZJm22Xv2DOyM33fd7bMUM2k+vM1yrbxW96+kIIIY7Pn2r6QgghjkNCXwghAoiEvhBCBBAJfSGECCAS+kIIEUAk9IUQIoBI6AvRBpRSqUqpN9u6HSLwSOgLIUQAkdAXQogAIqEv/J5SaqhS6lOlVJ5SqkwptUwpNbbG868ppdKVUmOUUquUUk5f+eW2etY1Sim1UClVrJQqUUotUkqNqme+s5RS3yilCnzzrVdKXVfPfDOUUlt986xWSp3Z/J+AENUk9IVfU0qdCizHXNfkBuBizP1JFyqlhteYNRJz39HXgV8BS4CnlFLX1FjXEGAp5trl12BuOh4JLFVKDa0x3y8x102xAzdh7nH6CtC9TvPGAn8EHsBcJdECfK6Uij7Bty3EUcm1d4RfU0otArpgLlzl8k2zYO5Hul1r/Sul1GvAr4HLtdbzaiz7DeaKiMlaa62U+gCY6Ps73zdPJOZCZ0u01hcppRTmyoc5mCso1nsDeaVUKhAF9NRa5/mmjcDcyPxKrfXbzfpBCOEjPX3ht5RSIZgbg78PeJVSVt+1xxWwEBhXY3YP5gqtNc3DXLk10ff3OODzysAH0FoXYq5xXnkd9L6YHv1LRwv8GlZUBr5P5Q1Puh3/3QnRNBL6wp/FYkomDwAVdX5+B8T4rmMOkKe1rqizfJbvsTL0Y4ED9bzOQapvV9fB95hez3x11bq1na6+AUZwA5YVokmsbd0AIVpQPuAF/gu8Ud8MWmuvqcgQo5Sy1Qn+BN9jhu8xF3Pji7o6UR3gOb7HxHrmE6LNSegLv6W1LlFKfQ8MBdYep9xiwRzknVdj2gwgjerQXwqcr5SK0FoXASilIjC3tFvim2cHpsZ/vVLqBS0HzUQ7I6Ev/N0fgO+Ar5VSL2PKM3HAqYBFa323b74i4BGlVBywE7gcc9D2mhrB/RDmtnSLlFL/h7kj1V+AUGAWgO+A753AfGCxUuo5zC0k+wMdtdZ/beH3K8QxSU1f+DVt7hk6EjNM8ylgAfAkMBizM6hUiOnZ/xr4BDgbuENr/XqNdW0AxvvmfR2YCxQDZ2mt19eY7xPgHN+fL2MO9N6I+QYgRJuSIZsi4PmGbE7UWie1dVuEaGnS0xdCiAAioS+EEAFEyjtCCBFApKcvhBABREJfCCECiIS+EEIEEAl9IYQIIBL6QggRQP4fEhiknxb4eDQAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "\n",
    "plt.savefig(figure_path + '/ml-100k-large-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Plot decreasing learning rate\n",
    "\n",
    "#_ = plt.plot(lr_history[:2*iterations_per_epoch-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.9803\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.9894\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "with open('best.weights.medium', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 9.4395\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# big net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=50, hidden=[100, 100, 100],\n",
    "    embedding_dropout=0.05, dropouts=[0.3, 0.3, 0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "#iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "#scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 1.2442 - val: 1.0223\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 1.1244 - val: 0.9061\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.9872 - val: 0.8208\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.9078 - val: 0.7912\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.8622 - val: 0.7699\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.8344 - val: 0.7552\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 0.8155 - val: 0.7520\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 0.8030 - val: 0.7375\n",
      "[009/300] train: 0.7883 - val: 0.7383\n",
      "loss improvement on epoch: 10\n",
      "[010/300] train: 0.7774 - val: 0.7364\n",
      "[011/300] train: 0.7708 - val: 0.7394\n",
      "[012/300] train: 0.7599 - val: 0.7423\n",
      "[013/300] train: 0.7509 - val: 0.7434\n",
      "[014/300] train: 0.7392 - val: 0.7534\n",
      "[015/300] train: 0.7292 - val: 0.7509\n",
      "[016/300] train: 0.7194 - val: 0.7564\n",
      "[017/300] train: 0.7047 - val: 0.7593\n",
      "[018/300] train: 0.6929 - val: 0.7684\n",
      "[019/300] train: 0.6763 - val: 0.7768\n",
      "[020/300] train: 0.6644 - val: 0.7887\n",
      "[021/300] train: 0.6466 - val: 0.7982\n",
      "[022/300] train: 0.6278 - val: 0.8049\n",
      "[023/300] train: 0.6165 - val: 0.8007\n",
      "[024/300] train: 0.6028 - val: 0.8159\n",
      "[025/300] train: 0.5897 - val: 0.8230\n",
      "[026/300] train: 0.5743 - val: 0.8244\n",
      "[027/300] train: 0.5664 - val: 0.8330\n",
      "[028/300] train: 0.5517 - val: 0.8392\n",
      "[029/300] train: 0.5446 - val: 0.8436\n",
      "[030/300] train: 0.5330 - val: 0.8430\n",
      "[031/300] train: 0.5238 - val: 0.8461\n",
      "[032/300] train: 0.5180 - val: 0.8511\n",
      "[033/300] train: 0.5059 - val: 0.8513\n",
      "[034/300] train: 0.5023 - val: 0.8624\n",
      "[035/300] train: 0.4942 - val: 0.8506\n",
      "[036/300] train: 0.4852 - val: 0.8662\n",
      "[037/300] train: 0.4832 - val: 0.8767\n",
      "[038/300] train: 0.4766 - val: 0.8621\n",
      "[039/300] train: 0.4698 - val: 0.8722\n",
      "[040/300] train: 0.4661 - val: 0.8732\n",
      "[041/300] train: 0.4610 - val: 0.8802\n",
      "[042/300] train: 0.4528 - val: 0.8819\n",
      "[043/300] train: 0.4495 - val: 0.8769\n",
      "[044/300] train: 0.4434 - val: 0.8765\n",
      "[045/300] train: 0.4432 - val: 0.8814\n",
      "[046/300] train: 0.4385 - val: 0.8913\n",
      "[047/300] train: 0.4344 - val: 0.8872\n",
      "[048/300] train: 0.4316 - val: 0.8823\n",
      "[049/300] train: 0.4308 - val: 0.8839\n",
      "[050/300] train: 0.4252 - val: 0.8825\n",
      "[051/300] train: 0.4216 - val: 0.8896\n",
      "[052/300] train: 0.4176 - val: 0.8899\n",
      "[053/300] train: 0.4147 - val: 0.8843\n",
      "[054/300] train: 0.4157 - val: 0.8806\n",
      "[055/300] train: 0.4111 - val: 0.8825\n",
      "[056/300] train: 0.4078 - val: 0.9078\n",
      "[057/300] train: 0.4081 - val: 0.8952\n",
      "[058/300] train: 0.4046 - val: 0.9048\n",
      "[059/300] train: 0.4024 - val: 0.9002\n",
      "[060/300] train: 0.3989 - val: 0.8860\n",
      "[061/300] train: 0.4016 - val: 0.8874\n",
      "[062/300] train: 0.3950 - val: 0.8913\n",
      "[063/300] train: 0.3923 - val: 0.8890\n",
      "[064/300] train: 0.3898 - val: 0.9107\n",
      "[065/300] train: 0.3906 - val: 0.8971\n",
      "[066/300] train: 0.3842 - val: 0.8995\n",
      "[067/300] train: 0.3859 - val: 0.8937\n",
      "[068/300] train: 0.3850 - val: 0.8820\n",
      "[069/300] train: 0.3860 - val: 0.9053\n",
      "[070/300] train: 0.3786 - val: 0.8990\n",
      "[071/300] train: 0.3812 - val: 0.8882\n",
      "[072/300] train: 0.3772 - val: 0.8867\n",
      "[073/300] train: 0.3786 - val: 0.8926\n",
      "[074/300] train: 0.3762 - val: 0.9104\n",
      "[075/300] train: 0.3767 - val: 0.8921\n",
      "[076/300] train: 0.3709 - val: 0.8953\n",
      "[077/300] train: 0.3692 - val: 0.8942\n",
      "[078/300] train: 0.3674 - val: 0.9034\n",
      "[079/300] train: 0.3691 - val: 0.9030\n",
      "[080/300] train: 0.3650 - val: 0.9037\n",
      "[081/300] train: 0.3652 - val: 0.9049\n",
      "[082/300] train: 0.3625 - val: 0.8911\n",
      "[083/300] train: 0.3621 - val: 0.8935\n",
      "[084/300] train: 0.3627 - val: 0.9029\n",
      "[085/300] train: 0.3625 - val: 0.9009\n",
      "[086/300] train: 0.3590 - val: 0.9078\n",
      "[087/300] train: 0.3565 - val: 0.8934\n",
      "[088/300] train: 0.3582 - val: 0.9100\n",
      "[089/300] train: 0.3543 - val: 0.9033\n",
      "[090/300] train: 0.3540 - val: 0.9063\n",
      "[091/300] train: 0.3553 - val: 0.8975\n",
      "[092/300] train: 0.3532 - val: 0.9072\n",
      "[093/300] train: 0.3532 - val: 0.9061\n",
      "[094/300] train: 0.3543 - val: 0.8998\n",
      "[095/300] train: 0.3507 - val: 0.8948\n",
      "[096/300] train: 0.3486 - val: 0.9094\n",
      "[097/300] train: 0.3464 - val: 0.9105\n",
      "[098/300] train: 0.3491 - val: 0.9014\n",
      "[099/300] train: 0.3471 - val: 0.9149\n",
      "[100/300] train: 0.3474 - val: 0.9107\n",
      "[101/300] train: 0.3423 - val: 0.9150\n",
      "[102/300] train: 0.3448 - val: 0.9004\n",
      "[103/300] train: 0.3434 - val: 0.9069\n",
      "[104/300] train: 0.3440 - val: 0.9076\n",
      "[105/300] train: 0.3437 - val: 0.9023\n",
      "[106/300] train: 0.3420 - val: 0.9139\n",
      "[107/300] train: 0.3397 - val: 0.9131\n",
      "[108/300] train: 0.3385 - val: 0.9040\n",
      "[109/300] train: 0.3413 - val: 0.9042\n",
      "[110/300] train: 0.3371 - val: 0.9140\n",
      "[111/300] train: 0.3397 - val: 0.9182\n",
      "[112/300] train: 0.3404 - val: 0.9157\n",
      "[113/300] train: 0.3367 - val: 0.9138\n",
      "[114/300] train: 0.3359 - val: 0.9127\n",
      "[115/300] train: 0.3319 - val: 0.9169\n",
      "[116/300] train: 0.3325 - val: 0.9135\n",
      "[117/300] train: 0.3332 - val: 0.9164\n",
      "[118/300] train: 0.3367 - val: 0.9176\n",
      "[119/300] train: 0.3308 - val: 0.8998\n",
      "[120/300] train: 0.3310 - val: 0.9004\n",
      "[121/300] train: 0.3321 - val: 0.9037\n",
      "[122/300] train: 0.3293 - val: 0.9191\n",
      "[123/300] train: 0.3288 - val: 0.9115\n",
      "[124/300] train: 0.3300 - val: 0.9247\n",
      "[125/300] train: 0.3293 - val: 0.9019\n",
      "[126/300] train: 0.3313 - val: 0.9077\n",
      "[127/300] train: 0.3272 - val: 0.9126\n",
      "[128/300] train: 0.3271 - val: 0.9023\n",
      "[129/300] train: 0.3284 - val: 0.9036\n",
      "[130/300] train: 0.3243 - val: 0.9096\n",
      "[131/300] train: 0.3282 - val: 0.9093\n",
      "[132/300] train: 0.3255 - val: 0.9237\n",
      "[133/300] train: 0.3254 - val: 0.9095\n",
      "[134/300] train: 0.3227 - val: 0.9078\n",
      "[135/300] train: 0.3217 - val: 0.9023\n",
      "[136/300] train: 0.3253 - val: 0.9327\n",
      "[137/300] train: 0.3238 - val: 0.9067\n",
      "[138/300] train: 0.3196 - val: 0.9061\n",
      "[139/300] train: 0.3181 - val: 0.9190\n",
      "[140/300] train: 0.3191 - val: 0.9120\n",
      "[141/300] train: 0.3201 - val: 0.9249\n",
      "[142/300] train: 0.3211 - val: 0.9164\n",
      "[143/300] train: 0.3159 - val: 0.9149\n",
      "[144/300] train: 0.3216 - val: 0.9087\n",
      "[145/300] train: 0.3178 - val: 0.8998\n",
      "[146/300] train: 0.3184 - val: 0.9199\n",
      "[147/300] train: 0.3195 - val: 0.9076\n",
      "[148/300] train: 0.3173 - val: 0.9197\n",
      "[149/300] train: 0.3146 - val: 0.9100\n",
      "[150/300] train: 0.3143 - val: 0.9086\n",
      "[151/300] train: 0.3158 - val: 0.9117\n",
      "[152/300] train: 0.3162 - val: 0.9143\n",
      "[153/300] train: 0.3132 - val: 0.9161\n",
      "[154/300] train: 0.3132 - val: 0.9094\n",
      "[155/300] train: 0.3131 - val: 0.9118\n",
      "[156/300] train: 0.3147 - val: 0.9197\n",
      "[157/300] train: 0.3162 - val: 0.9044\n",
      "[158/300] train: 0.3108 - val: 0.9120\n",
      "[159/300] train: 0.3120 - val: 0.9164\n",
      "[160/300] train: 0.3129 - val: 0.9200\n",
      "[161/300] train: 0.3113 - val: 0.9252\n",
      "[162/300] train: 0.3125 - val: 0.9121\n",
      "[163/300] train: 0.3117 - val: 0.9076\n",
      "[164/300] train: 0.3124 - val: 0.9165\n",
      "[165/300] train: 0.3081 - val: 0.9306\n",
      "[166/300] train: 0.3107 - val: 0.9265\n",
      "[167/300] train: 0.3107 - val: 0.9151\n",
      "[168/300] train: 0.3110 - val: 0.9237\n",
      "[169/300] train: 0.3076 - val: 0.9195\n",
      "[170/300] train: 0.3069 - val: 0.9198\n",
      "[171/300] train: 0.3056 - val: 0.9138\n",
      "[172/300] train: 0.3057 - val: 0.9203\n",
      "[173/300] train: 0.3039 - val: 0.9156\n",
      "[174/300] train: 0.3041 - val: 0.9118\n",
      "[175/300] train: 0.3036 - val: 0.9206\n",
      "[176/300] train: 0.3054 - val: 0.9216\n",
      "[177/300] train: 0.3050 - val: 0.9123\n",
      "[178/300] train: 0.3048 - val: 0.8999\n",
      "[179/300] train: 0.3029 - val: 0.9071\n",
      "[180/300] train: 0.3069 - val: 0.9172\n",
      "[181/300] train: 0.3037 - val: 0.9252\n",
      "[182/300] train: 0.3019 - val: 0.9131\n",
      "[183/300] train: 0.3038 - val: 0.9347\n",
      "[184/300] train: 0.3056 - val: 0.9132\n",
      "[185/300] train: 0.3014 - val: 0.9173\n",
      "[186/300] train: 0.3034 - val: 0.9065\n",
      "[187/300] train: 0.3026 - val: 0.9259\n",
      "[188/300] train: 0.3028 - val: 0.9233\n",
      "[189/300] train: 0.3010 - val: 0.9082\n",
      "[190/300] train: 0.3021 - val: 0.9080\n",
      "[191/300] train: 0.3029 - val: 0.9129\n",
      "[192/300] train: 0.3027 - val: 0.9081\n",
      "[193/300] train: 0.3001 - val: 0.9163\n",
      "[194/300] train: 0.3018 - val: 0.9076\n",
      "[195/300] train: 0.3002 - val: 0.9180\n",
      "[196/300] train: 0.2999 - val: 0.9174\n",
      "[197/300] train: 0.2967 - val: 0.9236\n",
      "[198/300] train: 0.3021 - val: 0.9168\n",
      "[199/300] train: 0.3002 - val: 0.8972\n",
      "[200/300] train: 0.2972 - val: 0.9182\n",
      "[201/300] train: 0.2997 - val: 0.9136\n",
      "[202/300] train: 0.2988 - val: 0.9235\n",
      "[203/300] train: 0.2982 - val: 0.9144\n",
      "[204/300] train: 0.2986 - val: 0.9089\n",
      "[205/300] train: 0.2959 - val: 0.9203\n",
      "[206/300] train: 0.2945 - val: 0.9204\n",
      "[207/300] train: 0.2955 - val: 0.9226\n",
      "[208/300] train: 0.2968 - val: 0.9154\n",
      "[209/300] train: 0.2946 - val: 0.9263\n",
      "[210/300] train: 0.2948 - val: 0.9061\n",
      "[211/300] train: 0.2969 - val: 0.9215\n",
      "[212/300] train: 0.2973 - val: 0.9096\n",
      "[213/300] train: 0.2967 - val: 0.9125\n",
      "[214/300] train: 0.2934 - val: 0.9232\n",
      "[215/300] train: 0.2944 - val: 0.9157\n",
      "[216/300] train: 0.2934 - val: 0.9285\n",
      "[217/300] train: 0.2956 - val: 0.9240\n",
      "[218/300] train: 0.2966 - val: 0.9067\n",
      "[219/300] train: 0.2946 - val: 0.9138\n",
      "[220/300] train: 0.2947 - val: 0.9264\n",
      "[221/300] train: 0.2975 - val: 0.9156\n",
      "[222/300] train: 0.2930 - val: 0.9166\n",
      "[223/300] train: 0.2899 - val: 0.9165\n",
      "[224/300] train: 0.2903 - val: 0.9202\n",
      "[225/300] train: 0.2932 - val: 0.9189\n",
      "[226/300] train: 0.2907 - val: 0.9208\n",
      "[227/300] train: 0.2929 - val: 0.9131\n",
      "[228/300] train: 0.2920 - val: 0.9153\n",
      "[229/300] train: 0.2956 - val: 0.9139\n",
      "[230/300] train: 0.2890 - val: 0.9121\n",
      "[231/300] train: 0.2910 - val: 0.9348\n",
      "[232/300] train: 0.2907 - val: 0.9119\n",
      "[233/300] train: 0.2935 - val: 0.9137\n",
      "[234/300] train: 0.2913 - val: 0.9108\n",
      "[235/300] train: 0.2882 - val: 0.9109\n",
      "[236/300] train: 0.2873 - val: 0.9142\n",
      "[237/300] train: 0.2906 - val: 0.9132\n",
      "[238/300] train: 0.2913 - val: 0.9137\n",
      "[239/300] train: 0.2917 - val: 0.9175\n",
      "[240/300] train: 0.2887 - val: 0.9126\n",
      "[241/300] train: 0.2900 - val: 0.9203\n",
      "[242/300] train: 0.2917 - val: 0.9181\n",
      "[243/300] train: 0.2896 - val: 0.9113\n",
      "[244/300] train: 0.2902 - val: 0.9189\n",
      "[245/300] train: 0.2875 - val: 0.9177\n",
      "[246/300] train: 0.2863 - val: 0.9244\n",
      "[247/300] train: 0.2860 - val: 0.9156\n",
      "[248/300] train: 0.2873 - val: 0.9186\n",
      "[249/300] train: 0.2867 - val: 0.9151\n",
      "[250/300] train: 0.2861 - val: 0.9110\n",
      "[251/300] train: 0.2855 - val: 0.9208\n",
      "[252/300] train: 0.2881 - val: 0.9137\n",
      "[253/300] train: 0.2866 - val: 0.9102\n",
      "[254/300] train: 0.2863 - val: 0.9257\n",
      "[255/300] train: 0.2839 - val: 0.9116\n",
      "[256/300] train: 0.2842 - val: 0.9100\n",
      "[257/300] train: 0.2854 - val: 0.9170\n",
      "[258/300] train: 0.2872 - val: 0.9255\n",
      "[259/300] train: 0.2858 - val: 0.9294\n",
      "[260/300] train: 0.2873 - val: 0.9208\n",
      "[261/300] train: 0.2853 - val: 0.9225\n",
      "[262/300] train: 0.2867 - val: 0.9145\n",
      "[263/300] train: 0.2850 - val: 0.9093\n",
      "[264/300] train: 0.2866 - val: 0.9194\n",
      "[265/300] train: 0.2841 - val: 0.9280\n",
      "[266/300] train: 0.2858 - val: 0.9299\n",
      "[267/300] train: 0.2832 - val: 0.9285\n",
      "[268/300] train: 0.2886 - val: 0.9162\n",
      "[269/300] train: 0.2834 - val: 0.9086\n",
      "[270/300] train: 0.2841 - val: 0.9161\n",
      "[271/300] train: 0.2830 - val: 0.9133\n",
      "[272/300] train: 0.2833 - val: 0.9267\n",
      "[273/300] train: 0.2833 - val: 0.9163\n",
      "[274/300] train: 0.2808 - val: 0.9258\n",
      "[275/300] train: 0.2820 - val: 0.9129\n",
      "[276/300] train: 0.2813 - val: 0.9249\n",
      "[277/300] train: 0.2813 - val: 0.9183\n",
      "[278/300] train: 0.2823 - val: 0.8987\n",
      "[279/300] train: 0.2836 - val: 0.9166\n",
      "[280/300] train: 0.2809 - val: 0.9251\n",
      "[281/300] train: 0.2822 - val: 0.9095\n",
      "[282/300] train: 0.2820 - val: 0.9229\n",
      "[283/300] train: 0.2813 - val: 0.9235\n",
      "[284/300] train: 0.2830 - val: 0.9102\n",
      "[285/300] train: 0.2820 - val: 0.9133\n",
      "[286/300] train: 0.2822 - val: 0.9190\n",
      "[287/300] train: 0.2820 - val: 0.9178\n",
      "[288/300] train: 0.2878 - val: 0.9249\n",
      "[289/300] train: 0.2808 - val: 0.9132\n",
      "[290/300] train: 0.2813 - val: 0.9296\n",
      "[291/300] train: 0.2846 - val: 0.9173\n",
      "[292/300] train: 0.2823 - val: 0.9241\n",
      "[293/300] train: 0.2823 - val: 0.9142\n",
      "[294/300] train: 0.2821 - val: 0.9039\n",
      "[295/300] train: 0.2795 - val: 0.9174\n",
      "[296/300] train: 0.2818 - val: 0.9136\n",
      "[297/300] train: 0.2789 - val: 0.9126\n",
      "[298/300] train: 0.2813 - val: 0.9211\n",
      "[299/300] train: 0.2801 - val: 0.9187\n",
      "[300/300] train: 0.2783 - val: 0.9104\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "\n",
    "plt.savefig(figure_path + '/ml-100k-small-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# Plot decreasing learning rate\n",
    "\n",
    "#_ = plt.plot(lr_history[:2*iterations_per_epoch-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.9497\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE: 0.9549\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "with open('best.weights.big', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 10.4322\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f57757a1",
   "language": "python",
   "display_name": "PyCharm (rs-via-gnn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}