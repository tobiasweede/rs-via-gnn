{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MovieLens negative sampling\n",
    "\n",
    "# https://petamind.com/create-bipartite-graph-from-a-rating-matrix/\n",
    "\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:  ['ml-100k', 'ml-latest-small', 'ml-latest']\n",
      "You selected ml-100k\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'ml-100k': '/home/weiss/rs_data/ml-100k/',\n",
    "    'ml-latest-small': '/home/weiss/rs_data/ml-latest-small/',\n",
    "    'ml-latest': '/home/weiss/rs_data/ml-latest/'\n",
    "}\n",
    "\n",
    "print('Available datasets: ', [key for key in datasets])\n",
    "#dt = input('Dataset name = ')\n",
    "#dt='ml-latest-small'\n",
    "dt='ml-100k'\n",
    "\n",
    "print('You selected {}'.format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weiss/rs_data/ml-100k/\n",
      "/\n",
      "    README\n",
      "    u2.test\n",
      "    u4.test\n",
      "    u2.base\n",
      "    allbut.pl\n",
      "    u3.base\n",
      "    u.data\n",
      "    u.occupation\n",
      "    ua.test\n",
      "    u5.base\n",
      "    u.genre\n",
      "    u3.test\n",
      "    ub.test\n",
      "    mku.sh\n",
      "    u.user\n",
      "    u1.test\n",
      "    ua.base\n",
      "    u1.base\n",
      "    u.item\n",
      "    u5.test\n",
      "    ub.base\n",
      "    u4.base\n",
      "    ml-100k.pkl\n",
      "    u.info\n",
      "processed/\n",
      "    rX_val.csv\n",
      "    rX_test_ns.csv\n",
      "    rX_test.csv\n",
      "    rX_train.csv\n",
      "    rX_val_ns.csv\n",
      "    rX_train_ns.csv\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check structure\n",
    "def list_files(startpath):\n",
    "    print(startpath)\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print('{}{}'.format(subindent, f))\n",
    "dirs = [x[0] for x in os.walk(datasets[dt])]\n",
    "ml = filter(lambda dirName: dirName if ('ml' in dirName) else '', list(dirs))\n",
    "dt_dir_name= list(ml)[0]\n",
    "print(list_files(dt_dir_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ratings and tags\n",
    "if dt=='ml-100k':\n",
    "  ratings_data= pd.read_csv(dt_dir_name +'/'+ 'u.data', delimiter='\\t', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "  user_data= pd.read_csv(dt_dir_name +'/'+ 'u.user', delimiter='|', names=['user id', 'age' ,'gender' ,'occupation' , 'zip code'])\n",
    "  ratings_data.shape\n",
    "elif dt=='ml-latest-small':\n",
    "  ratings_data=pd.read_csv(dt_dir_name +'/'+ 'ratings.csv')\n",
    "  tag_data=pd.read_csv(dt_dir_name +'/'+ 'tags.csv')\n",
    "  ratings_data.shape\n",
    "elif dt=='ml-latest':\n",
    "  rating_data=pd.read_csv(dt_dir_name +'/'+ 'ratings.csv')\n",
    "  tag_data=pd.read_csv(dt_dir_name +'/'+ 'tags.csv')\n",
    "  rating_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0     196      242       3  881250949\n",
      "1     186      302       3  891717742\n",
      "2      22      377       1  878887116\n",
      "3     244       51       2  880606923\n",
      "4     166      346       1  886397596\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype\n",
      "---  ------     --------------   -----\n",
      " 0   userId     100000 non-null  int64\n",
      " 1   movieId    100000 non-null  int64\n",
      " 2   rating     100000 non-null  int64\n",
      " 3   timestamp  100000 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.1 MB\n",
      "None\n",
      "Ratings null?\n",
      " userId       False\n",
      "movieId      False\n",
      "rating       False\n",
      "timestamp    False\n",
      "dtype: bool\n",
      "   user id  age gender  occupation zip code\n",
      "0        1   24      M  technician    85711\n",
      "1        2   53      F       other    94043\n",
      "2        3   23      M      writer    32067\n",
      "3        4   24      M  technician    43537\n",
      "4        5   33      F       other    15213\n",
      "Users null?\n",
      " user id       False\n",
      "age           False\n",
      "gender        False\n",
      "occupation    False\n",
      "zip code      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print(ratings_data.head())\n",
    "print(ratings_data.info())\n",
    "print('Ratings null?\\n', ratings_data.isnull().any())\n",
    "if dt == 'ml-100k':\n",
    "    print(user_data.head())\n",
    "    print('Users null?\\n', user_data.isnull().any())\n",
    "if dt == 'ml-latest-small' or dt == 'ml-latest':\n",
    "    print(tag_data.head())\n",
    "    print('Tags null?\\n', tag_data.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 3) (10000, 3) (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create naive train, test, validation Split (80/10/10)\n",
    "# for original ratings\n",
    "\n",
    "train, test = train_test_split(ratings_data[['userId', 'movieId', 'rating']], test_size=0.2, random_state = RANDOM)\n",
    "test, val = train_test_split(test, test_size=0.5, random_state = RANDOM)\n",
    "print(train.shape, test.shape, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data_frames, out_file_names, outdir=dt_dir_name+'processed/'):\n",
    "    \"\"\"\n",
    "    Save Train, Test, Validation Split to csv files\n",
    "    \"\"\"\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    assert len(data_frames)==len(out_file_names), \"number of dataframes must equal number of file names\"\n",
    "    for i in range(len(out_file_names)):\n",
    "        data_frames[i].to_csv(outdir+out_file_names[i], header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  movieId  rating\n",
      "10700     269      401       3\n",
      "38152      90      497       5\n",
      "87439     925      447       4\n",
      "52613     450      832       2\n",
      "93091     901       88       5\n"
     ]
    }
   ],
   "source": [
    "# Check negative sampling train dataset\n",
    "print(train.head())\n",
    "\n",
    "# Save train, test, validation to CSV\n",
    "save_to_csv([train, test, val], ['train.csv', 'test.csv', 'val.csv'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users 943\n",
      "# movies 1682\n",
      "user 196 processed ... 0.00% after 0.00 sec\n"
     ]
    }
   ],
   "source": [
    "# Negative Sampling\n",
    "# Create implicit data (interaction or not)\n",
    "import random\n",
    "import time\n",
    "\n",
    "def negative_sampling(r):\n",
    "    \"\"\"\n",
    "    Create negative samples, i.e. user-movie combinations with no ratings\n",
    "    \n",
    "    parameters:\n",
    "    input rating data -- pd dataframe: userId, movieId, rating\n",
    "    \n",
    "    returns:\n",
    "    negative sampled set -- pd dataframe: userId, movieId, interact (implicit)\n",
    "    \"\"\"\n",
    "    users = r['userId'].drop_duplicates()  # get unique userIds\n",
    "    movies = r['movieId'].drop_duplicates()  # get unique movieIds\n",
    "    print('# users', len(users))\n",
    "    print('# movies', len(movies))\n",
    "    negative_samples = r[['userId', 'movieId', 'timestamp']]  # starting point\n",
    "    negative_samples['interact'] = negative_samples.apply(lambda row: 1, axis=1)\n",
    "    negative_tmp_data = []  # list to craft interaction [userId, movieId, timestamp, interaction]\n",
    "    start_time = time.time()\n",
    "    stop_time = time.time()\n",
    "    for i, row in r.iterrows():\n",
    "        user = row['userId']  # current user\n",
    "        if i%5000==0:\n",
    "            stop_time = time.time()\n",
    "            print('user', user, 'processed ... {0:0.2f}% after {1:0.2f} sec'.format(float(i)*100.0 / len(r), stop_time - start_time))\n",
    "            start_time = stop_time\n",
    "        j = 2  # amount of negative samples\n",
    "        while j > 0:\n",
    "            movie = movies.sample(n=1).values[0]  # get random movieId\n",
    "            # insert negative samples if u-m relation does not exist\n",
    "            if (not ((negative_samples['userId'] == user) & (negative_samples['movieId'] == movie)).any()):\n",
    "                j -= 1\n",
    "                negative_tmp_data.append([user, movie, int(time.time()), -1])\n",
    "    negative_temp_df = pd.DataFrame(data=negative_tmp_data, columns=['userId', 'movieId', 'timestamp', 'interact'])\n",
    "    negative_samples = pd.concat([negative_samples, negative_temp_df], ignore_index=True)\n",
    "    return negative_samples\n",
    "\n",
    "ns = negative_sampling(ratings_data)\n",
    "print(ns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create Train, Test, Validation Split (80/10/10)\n",
    "# for negative samples\n",
    "train_ns, test_ns = train_test_split(ns, test_size=0.2, random_state = RANDOM)\n",
    "test_ns, val_ns = train_test_split(test_ns, test_size=0.5, random_state= RANDOM)\n",
    "print(train_ns.shape, test_ns.shape, val_ns.shape)\n",
    "\n",
    "# Check negative sampling train dataset\n",
    "train_ns.head()\n",
    "\n",
    "# Save negative sampling datasets\n",
    "save_to_csv([train_ns, test_ns, val_ns], ['train_ns.csv', 'test_ns.csv', 'val_ns.csv'] )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f57757a1",
   "language": "python",
   "display_name": "PyCharm (rs-via-gnn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}