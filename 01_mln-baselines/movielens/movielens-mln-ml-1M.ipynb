{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MovieLens MLN Recommendation via PyTorch\n",
    "\n",
    "adapted from https://github.com/fastai/fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import time\n",
    "\n",
    "figure_path = '/home/weiss/git/thesis/doc/figures/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)\n",
    "\n",
    "RANDOM_STATE = 2021\n",
    "set_random_seed(RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    files = {}\n",
    "    path = Path(path)\n",
    "    for filename in path.glob('*'):\n",
    "        if filename.suffix == '.csv':\n",
    "            files[filename.stem] = pd.read_csv(filename)\n",
    "        elif filename.suffix == '.dat': # ml-1m\n",
    "            if filename.stem == 'ratings':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "            else:\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "            data = pd.read_csv(filename, sep='::', names=columns, engine='python')\n",
    "            files[filename.stem] = data\n",
    "        elif filename.suffix == '.data':  # ml-100k\n",
    "            if filename.stem == 'u':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "                data = pd.read_csv(filename, sep='\\t', names=columns, engine='python')\n",
    "                files['ratings'] = data\n",
    "        elif filename.suffix == '.item':  # ml-100k\n",
    "            if filename.stem == 'u':\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "                data = pd.read_csv(filename, sep='|', names=columns, engine='python')\n",
    "                files['movies'] = data\n",
    "    return files['ratings'], files['movies']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "dataset = 'ml-10m'\n",
    "\n",
    "# pick one of the available folders\n",
    "ratings, movies = read_data('/home/weiss/rs_data/'+dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "   userId  movieId  rating  timestamp\n0       1      122     5.0  838985046\n1       1      185     5.0  838983525\n2       1      231     5.0  838983392\n3       1      292     5.0  838983421\n4       1      316     5.0  838983392",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>122</td>\n      <td>5.0</td>\n      <td>838985046</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>185</td>\n      <td>5.0</td>\n      <td>838983525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>231</td>\n      <td>5.0</td>\n      <td>838983392</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>292</td>\n      <td>5.0</td>\n      <td>838983421</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>316</td>\n      <td>5.0</td>\n      <td>838983392</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 69878 users, 10677 movies\n",
      "Dataset shape: (10000054, 2)\n",
      "Target shape: (10000054,)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    if top is not None:\n",
    "        ratings.groupby('userId')['rating'].count()\n",
    "\n",
    "    unique_users = ratings.userId.unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = ratings.userId.map(user_to_index)\n",
    "\n",
    "    unique_movies = ratings.movieId.unique()\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)}\n",
    "    new_movies = ratings.movieId.map(movie_to_index)\n",
    "\n",
    "    n_users = unique_users.shape[0]\n",
    "    n_movies = unique_movies.shape[0]\n",
    "\n",
    "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_movies})\n",
    "    y = ratings['rating'].astype(np.float32)\n",
    "    return (n_users, n_movies), (X, y), (user_to_index, movie_to_index)\n",
    "\n",
    "(n, m), (X, y), _ = create_dataset(ratings)\n",
    "print(f'Embeddings: {n} users, {m} movies')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, random_state=RANDOM_STATE)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=RANDOM_STATE)\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid), 'test': (X_test, y_test)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_valid), 'test': len(X_test)}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "class RatingsIterator:\n",
    "\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in RatingsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "class RecommenderNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates dense MLN with embedding layers.\n",
    "\n",
    "    Args:\n",
    "        n_users:\n",
    "            Number of unique users in the dataset.\n",
    "\n",
    "        n_movies:\n",
    "            Number of unique movies in the dataset.\n",
    "\n",
    "        n_factors:\n",
    "            Number of columns in the embeddings matrix.\n",
    "\n",
    "        embedding_dropout:\n",
    "            Dropout rate to apply right after embeddings layer.\n",
    "\n",
    "        hidden:\n",
    "            A single integer or a list of integers defining the number of\n",
    "            units in hidden layer(s).\n",
    "\n",
    "        dropouts:\n",
    "            A single integer or a list of integers defining the dropout\n",
    "            layers rates applied right after each of hidden layers.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_movies,\n",
    "                 n_factors=50, embedding_dropout=0.02,\n",
    "                 hidden=10, dropouts=0.2):\n",
    "\n",
    "        super().__init__()\n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "\n",
    "        def gen_layers(n_in):\n",
    "            \"\"\"\n",
    "            A generator that yields a sequence of hidden layers and\n",
    "            their activations/dropouts.\n",
    "\n",
    "            Note that the function captures `hidden` and `dropouts`\n",
    "            values from the outer scope.\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "\n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self._init()\n",
    "\n",
    "    def forward(self, users, movies, minmax=None):\n",
    "        features = torch.cat([self.u(users), self.m(movies)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        #out = self.relu(self.fc(x))  # relu delivers worse rsme\n",
    "        if minmax is not None:\n",
    "            min_rating, max_rating = minmax\n",
    "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "        return out\n",
    "\n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Setup embeddings and hidden layers with reasonable initial values.\n",
    "        \"\"\"\n",
    "\n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)\n",
    "\n",
    "\n",
    "def get_list(n):\n",
    "    if isinstance(n, (int, float)):\n",
    "        return [n]\n",
    "    elif hasattr(n, '__iter__'):\n",
    "        return list(n)\n",
    "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "def plot_lr(schedule):\n",
    "    ts = list(range(1000))\n",
    "    y = [schedule(t, 0.001) for t in ts]\n",
    "    plt.plot(ts, y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5, 5.0)"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = float(ratings.rating.min()), float(ratings.rating.max())\n",
    "minmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "# small net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=10, hidden=[10],\n",
    "    embedding_dropout=0.05, dropouts=[0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.8454 - val: 0.7826\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7685 - val: 0.7729\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.7585 - val: 0.7700\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.7538 - val: 0.7681\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.7501 - val: 0.7671\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.7468 - val: 0.7660\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 0.7443 - val: 0.7652\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 0.7419 - val: 0.7643\n",
      "[009/300] train: 0.7402 - val: 0.7643\n",
      "loss improvement on epoch: 10\n",
      "[010/300] train: 0.7385 - val: 0.7639\n",
      "loss improvement on epoch: 11\n",
      "[011/300] train: 0.7372 - val: 0.7631\n",
      "loss improvement on epoch: 12\n",
      "[012/300] train: 0.7359 - val: 0.7624\n",
      "loss improvement on epoch: 13\n",
      "[013/300] train: 0.7342 - val: 0.7619\n",
      "loss improvement on epoch: 14\n",
      "[014/300] train: 0.7330 - val: 0.7615\n",
      "[015/300] train: 0.7314 - val: 0.7615\n",
      "loss improvement on epoch: 16\n",
      "[016/300] train: 0.7306 - val: 0.7610\n",
      "loss improvement on epoch: 17\n",
      "[017/300] train: 0.7295 - val: 0.7609\n",
      "loss improvement on epoch: 18\n",
      "[018/300] train: 0.7285 - val: 0.7606\n",
      "[019/300] train: 0.7280 - val: 0.7611\n",
      "loss improvement on epoch: 20\n",
      "[020/300] train: 0.7265 - val: 0.7599\n",
      "[021/300] train: 0.7258 - val: 0.7603\n",
      "loss improvement on epoch: 22\n",
      "[022/300] train: 0.7248 - val: 0.7599\n",
      "[023/300] train: 0.7239 - val: 0.7609\n",
      "[024/300] train: 0.7234 - val: 0.7606\n",
      "[025/300] train: 0.7227 - val: 0.7603\n",
      "[026/300] train: 0.7222 - val: 0.7605\n",
      "[027/300] train: 0.7217 - val: 0.7607\n",
      "[028/300] train: 0.7216 - val: 0.7607\n",
      "[029/300] train: 0.7209 - val: 0.7606\n",
      "[030/300] train: 0.7207 - val: 0.7607\n",
      "[031/300] train: 0.7203 - val: 0.7612\n",
      "[032/300] train: 0.7202 - val: 0.7606\n",
      "[033/300] train: 0.7196 - val: 0.7606\n",
      "[034/300] train: 0.7197 - val: 0.7609\n",
      "[035/300] train: 0.7191 - val: 0.7609\n",
      "[036/300] train: 0.7188 - val: 0.7606\n",
      "[037/300] train: 0.7184 - val: 0.7612\n",
      "[038/300] train: 0.7187 - val: 0.7612\n",
      "[039/300] train: 0.7181 - val: 0.7609\n",
      "[040/300] train: 0.7177 - val: 0.7604\n",
      "[041/300] train: 0.7175 - val: 0.7609\n",
      "[042/300] train: 0.7177 - val: 0.7610\n",
      "[043/300] train: 0.7170 - val: 0.7611\n",
      "[044/300] train: 0.7170 - val: 0.7610\n",
      "[045/300] train: 0.7169 - val: 0.7607\n",
      "[046/300] train: 0.7166 - val: 0.7609\n",
      "[047/300] train: 0.7165 - val: 0.7607\n",
      "[048/300] train: 0.7163 - val: 0.7607\n",
      "[049/300] train: 0.7164 - val: 0.7611\n",
      "[050/300] train: 0.7160 - val: 0.7607\n",
      "[051/300] train: 0.7159 - val: 0.7610\n",
      "[052/300] train: 0.7158 - val: 0.7613\n",
      "[053/300] train: 0.7157 - val: 0.7611\n",
      "[054/300] train: 0.7154 - val: 0.7614\n",
      "[055/300] train: 0.7153 - val: 0.7614\n",
      "[056/300] train: 0.7151 - val: 0.7611\n",
      "[057/300] train: 0.7154 - val: 0.7615\n",
      "[058/300] train: 0.7151 - val: 0.7613\n",
      "[059/300] train: 0.7147 - val: 0.7609\n",
      "[060/300] train: 0.7148 - val: 0.7611\n",
      "[061/300] train: 0.7145 - val: 0.7611\n",
      "[062/300] train: 0.7147 - val: 0.7612\n",
      "[063/300] train: 0.7144 - val: 0.7619\n",
      "[064/300] train: 0.7142 - val: 0.7606\n",
      "[065/300] train: 0.7140 - val: 0.7623\n",
      "[066/300] train: 0.7142 - val: 0.7609\n",
      "[067/300] train: 0.7142 - val: 0.7615\n",
      "[068/300] train: 0.7137 - val: 0.7617\n",
      "[069/300] train: 0.7138 - val: 0.7616\n",
      "[070/300] train: 0.7139 - val: 0.7610\n",
      "[071/300] train: 0.7138 - val: 0.7615\n",
      "[072/300] train: 0.7136 - val: 0.7614\n",
      "[073/300] train: 0.7137 - val: 0.7611\n",
      "[074/300] train: 0.7137 - val: 0.7616\n",
      "[075/300] train: 0.7135 - val: 0.7618\n",
      "[076/300] train: 0.7135 - val: 0.7615\n",
      "[077/300] train: 0.7132 - val: 0.7614\n",
      "[078/300] train: 0.7130 - val: 0.7618\n",
      "[079/300] train: 0.7129 - val: 0.7614\n",
      "[080/300] train: 0.7131 - val: 0.7618\n",
      "[081/300] train: 0.7129 - val: 0.7612\n",
      "[082/300] train: 0.7128 - val: 0.7612\n",
      "[083/300] train: 0.7128 - val: 0.7615\n",
      "[084/300] train: 0.7126 - val: 0.7616\n",
      "[085/300] train: 0.7130 - val: 0.7619\n",
      "[086/300] train: 0.7126 - val: 0.7621\n",
      "[087/300] train: 0.7126 - val: 0.7615\n",
      "[088/300] train: 0.7128 - val: 0.7614\n",
      "[089/300] train: 0.7126 - val: 0.7625\n",
      "[090/300] train: 0.7124 - val: 0.7613\n",
      "[091/300] train: 0.7125 - val: 0.7614\n",
      "[092/300] train: 0.7125 - val: 0.7613\n",
      "[093/300] train: 0.7119 - val: 0.7614\n",
      "[094/300] train: 0.7121 - val: 0.7616\n",
      "[095/300] train: 0.7120 - val: 0.7613\n",
      "[096/300] train: 0.7121 - val: 0.7611\n",
      "[097/300] train: 0.7121 - val: 0.7619\n",
      "[098/300] train: 0.7119 - val: 0.7616\n",
      "[099/300] train: 0.7121 - val: 0.7614\n",
      "[100/300] train: 0.7120 - val: 0.7615\n",
      "[101/300] train: 0.7117 - val: 0.7615\n",
      "[102/300] train: 0.7118 - val: 0.7614\n",
      "[103/300] train: 0.7118 - val: 0.7620\n",
      "[104/300] train: 0.7115 - val: 0.7612\n",
      "[105/300] train: 0.7118 - val: 0.7611\n",
      "[106/300] train: 0.7117 - val: 0.7606\n",
      "[107/300] train: 0.7116 - val: 0.7624\n",
      "[108/300] train: 0.7115 - val: 0.7614\n",
      "[109/300] train: 0.7113 - val: 0.7622\n",
      "[110/300] train: 0.7113 - val: 0.7617\n",
      "[111/300] train: 0.7113 - val: 0.7626\n",
      "[112/300] train: 0.7117 - val: 0.7617\n",
      "[113/300] train: 0.7114 - val: 0.7621\n",
      "[114/300] train: 0.7114 - val: 0.7622\n",
      "[115/300] train: 0.7114 - val: 0.7619\n",
      "[116/300] train: 0.7110 - val: 0.7622\n",
      "[117/300] train: 0.7109 - val: 0.7615\n",
      "[118/300] train: 0.7112 - val: 0.7617\n",
      "[119/300] train: 0.7106 - val: 0.7618\n",
      "[120/300] train: 0.7108 - val: 0.7627\n",
      "[121/300] train: 0.7110 - val: 0.7620\n",
      "[122/300] train: 0.7108 - val: 0.7617\n",
      "[123/300] train: 0.7111 - val: 0.7621\n",
      "[124/300] train: 0.7108 - val: 0.7625\n",
      "[125/300] train: 0.7108 - val: 0.7621\n",
      "[126/300] train: 0.7105 - val: 0.7626\n",
      "[127/300] train: 0.7106 - val: 0.7621\n",
      "[128/300] train: 0.7105 - val: 0.7620\n",
      "[129/300] train: 0.7106 - val: 0.7620\n",
      "[130/300] train: 0.7104 - val: 0.7611\n",
      "[131/300] train: 0.7103 - val: 0.7627\n",
      "[132/300] train: 0.7107 - val: 0.7617\n",
      "[133/300] train: 0.7105 - val: 0.7617\n",
      "[134/300] train: 0.7104 - val: 0.7620\n",
      "[135/300] train: 0.7108 - val: 0.7619\n",
      "[136/300] train: 0.7104 - val: 0.7621\n",
      "[137/300] train: 0.7102 - val: 0.7622\n",
      "[138/300] train: 0.7101 - val: 0.7616\n",
      "[139/300] train: 0.7103 - val: 0.7619\n",
      "[140/300] train: 0.7104 - val: 0.7618\n",
      "[141/300] train: 0.7101 - val: 0.7623\n",
      "[142/300] train: 0.7102 - val: 0.7617\n",
      "[143/300] train: 0.7104 - val: 0.7620\n",
      "[144/300] train: 0.7099 - val: 0.7609\n",
      "[145/300] train: 0.7101 - val: 0.7625\n",
      "[146/300] train: 0.7102 - val: 0.7615\n",
      "[147/300] train: 0.7100 - val: 0.7623\n",
      "[148/300] train: 0.7099 - val: 0.7624\n",
      "[149/300] train: 0.7102 - val: 0.7623\n",
      "[150/300] train: 0.7103 - val: 0.7619\n",
      "[151/300] train: 0.7101 - val: 0.7627\n",
      "[152/300] train: 0.7100 - val: 0.7624\n",
      "[153/300] train: 0.7101 - val: 0.7624\n",
      "[154/300] train: 0.7101 - val: 0.7617\n",
      "[155/300] train: 0.7101 - val: 0.7622\n",
      "[156/300] train: 0.7101 - val: 0.7629\n",
      "[157/300] train: 0.7102 - val: 0.7620\n",
      "[158/300] train: 0.7097 - val: 0.7623\n",
      "[159/300] train: 0.7097 - val: 0.7622\n",
      "[160/300] train: 0.7097 - val: 0.7623\n",
      "[161/300] train: 0.7095 - val: 0.7624\n",
      "[162/300] train: 0.7094 - val: 0.7616\n",
      "[163/300] train: 0.7095 - val: 0.7618\n",
      "[164/300] train: 0.7098 - val: 0.7615\n",
      "[165/300] train: 0.7096 - val: 0.7622\n",
      "[166/300] train: 0.7099 - val: 0.7625\n",
      "[167/300] train: 0.7095 - val: 0.7623\n",
      "[168/300] train: 0.7093 - val: 0.7621\n",
      "[169/300] train: 0.7098 - val: 0.7622\n",
      "[170/300] train: 0.7096 - val: 0.7615\n",
      "[171/300] train: 0.7096 - val: 0.7618\n",
      "[172/300] train: 0.7096 - val: 0.7627\n",
      "[173/300] train: 0.7096 - val: 0.7631\n",
      "[174/300] train: 0.7093 - val: 0.7623\n",
      "[175/300] train: 0.7096 - val: 0.7623\n",
      "[176/300] train: 0.7094 - val: 0.7622\n",
      "[177/300] train: 0.7095 - val: 0.7612\n",
      "[178/300] train: 0.7094 - val: 0.7622\n",
      "[179/300] train: 0.7094 - val: 0.7625\n",
      "[180/300] train: 0.7091 - val: 0.7621\n",
      "[181/300] train: 0.7095 - val: 0.7622\n",
      "[182/300] train: 0.7094 - val: 0.7624\n",
      "[183/300] train: 0.7092 - val: 0.7615\n",
      "[184/300] train: 0.7093 - val: 0.7627\n",
      "[185/300] train: 0.7091 - val: 0.7620\n",
      "[186/300] train: 0.7093 - val: 0.7617\n",
      "[187/300] train: 0.7089 - val: 0.7623\n",
      "[188/300] train: 0.7092 - val: 0.7623\n",
      "[189/300] train: 0.7090 - val: 0.7615\n",
      "[190/300] train: 0.7093 - val: 0.7626\n",
      "[191/300] train: 0.7092 - val: 0.7619\n",
      "[192/300] train: 0.7092 - val: 0.7628\n",
      "[193/300] train: 0.7087 - val: 0.7624\n",
      "[194/300] train: 0.7090 - val: 0.7628\n",
      "[195/300] train: 0.7088 - val: 0.7627\n",
      "[196/300] train: 0.7090 - val: 0.7630\n",
      "[197/300] train: 0.7088 - val: 0.7627\n",
      "[198/300] train: 0.7088 - val: 0.7622\n",
      "[199/300] train: 0.7092 - val: 0.7626\n",
      "[200/300] train: 0.7088 - val: 0.7623\n",
      "[201/300] train: 0.7089 - val: 0.7633\n",
      "[202/300] train: 0.7088 - val: 0.7624\n",
      "[203/300] train: 0.7085 - val: 0.7614\n",
      "[204/300] train: 0.7087 - val: 0.7625\n",
      "[205/300] train: 0.7089 - val: 0.7628\n",
      "[206/300] train: 0.7087 - val: 0.7629\n",
      "[207/300] train: 0.7087 - val: 0.7622\n",
      "[208/300] train: 0.7088 - val: 0.7630\n",
      "[209/300] train: 0.7088 - val: 0.7620\n",
      "[210/300] train: 0.7087 - val: 0.7615\n",
      "[211/300] train: 0.7086 - val: 0.7628\n",
      "[212/300] train: 0.7086 - val: 0.7623\n",
      "[213/300] train: 0.7084 - val: 0.7623\n",
      "[214/300] train: 0.7084 - val: 0.7626\n",
      "[215/300] train: 0.7087 - val: 0.7622\n",
      "[216/300] train: 0.7086 - val: 0.7620\n",
      "[217/300] train: 0.7087 - val: 0.7623\n",
      "[218/300] train: 0.7084 - val: 0.7627\n",
      "[219/300] train: 0.7084 - val: 0.7631\n",
      "[220/300] train: 0.7084 - val: 0.7627\n",
      "[221/300] train: 0.7086 - val: 0.7627\n",
      "[222/300] train: 0.7085 - val: 0.7620\n",
      "[223/300] train: 0.7085 - val: 0.7634\n",
      "[224/300] train: 0.7083 - val: 0.7627\n",
      "[225/300] train: 0.7084 - val: 0.7621\n",
      "[226/300] train: 0.7083 - val: 0.7619\n",
      "[227/300] train: 0.7084 - val: 0.7628\n",
      "[228/300] train: 0.7085 - val: 0.7624\n",
      "[229/300] train: 0.7083 - val: 0.7623\n",
      "[230/300] train: 0.7084 - val: 0.7627\n",
      "[231/300] train: 0.7085 - val: 0.7625\n",
      "[232/300] train: 0.7082 - val: 0.7624\n",
      "[233/300] train: 0.7081 - val: 0.7633\n",
      "[234/300] train: 0.7081 - val: 0.7627\n",
      "[235/300] train: 0.7085 - val: 0.7626\n",
      "[236/300] train: 0.7083 - val: 0.7625\n",
      "[237/300] train: 0.7086 - val: 0.7625\n",
      "[238/300] train: 0.7079 - val: 0.7626\n",
      "[239/300] train: 0.7082 - val: 0.7629\n",
      "[240/300] train: 0.7082 - val: 0.7622\n",
      "[241/300] train: 0.7083 - val: 0.7626\n",
      "[242/300] train: 0.7080 - val: 0.7631\n",
      "[243/300] train: 0.7084 - val: 0.7624\n",
      "[244/300] train: 0.7082 - val: 0.7623\n",
      "[245/300] train: 0.7084 - val: 0.7636\n",
      "[246/300] train: 0.7083 - val: 0.7634\n",
      "[247/300] train: 0.7082 - val: 0.7620\n",
      "[248/300] train: 0.7080 - val: 0.7625\n",
      "[249/300] train: 0.7079 - val: 0.7629\n",
      "[250/300] train: 0.7083 - val: 0.7623\n",
      "[251/300] train: 0.7079 - val: 0.7634\n",
      "[252/300] train: 0.7078 - val: 0.7622\n",
      "[253/300] train: 0.7082 - val: 0.7634\n",
      "[254/300] train: 0.7079 - val: 0.7625\n",
      "[255/300] train: 0.7079 - val: 0.7623\n",
      "[256/300] train: 0.7079 - val: 0.7625\n",
      "[257/300] train: 0.7077 - val: 0.7627\n",
      "[258/300] train: 0.7078 - val: 0.7624\n",
      "[259/300] train: 0.7082 - val: 0.7627\n",
      "[260/300] train: 0.7077 - val: 0.7634\n",
      "[261/300] train: 0.7080 - val: 0.7629\n",
      "[262/300] train: 0.7078 - val: 0.7630\n",
      "[263/300] train: 0.7078 - val: 0.7631\n",
      "[264/300] train: 0.7080 - val: 0.7635\n",
      "[265/300] train: 0.7079 - val: 0.7625\n",
      "[266/300] train: 0.7077 - val: 0.7627\n",
      "[267/300] train: 0.7078 - val: 0.7629\n",
      "[268/300] train: 0.7078 - val: 0.7626\n",
      "[269/300] train: 0.7080 - val: 0.7625\n",
      "[270/300] train: 0.7080 - val: 0.7617\n",
      "[271/300] train: 0.7078 - val: 0.7622\n",
      "[272/300] train: 0.7079 - val: 0.7627\n",
      "[273/300] train: 0.7076 - val: 0.7629\n",
      "[274/300] train: 0.7077 - val: 0.7629\n",
      "[275/300] train: 0.7078 - val: 0.7632\n",
      "[276/300] train: 0.7079 - val: 0.7623\n",
      "[277/300] train: 0.7079 - val: 0.7627\n",
      "[278/300] train: 0.7077 - val: 0.7623\n",
      "[279/300] train: 0.7075 - val: 0.7627\n",
      "[280/300] train: 0.7077 - val: 0.7626\n",
      "[281/300] train: 0.7076 - val: 0.7625\n",
      "[282/300] train: 0.7075 - val: 0.7627\n",
      "[283/300] train: 0.7076 - val: 0.7624\n",
      "[284/300] train: 0.7078 - val: 0.7632\n",
      "[285/300] train: 0.7079 - val: 0.7635\n",
      "[286/300] train: 0.7076 - val: 0.7624\n",
      "[287/300] train: 0.7076 - val: 0.7627\n",
      "[288/300] train: 0.7079 - val: 0.7629\n",
      "[289/300] train: 0.7078 - val: 0.7632\n",
      "[290/300] train: 0.7079 - val: 0.7628\n",
      "[291/300] train: 0.7077 - val: 0.7625\n",
      "[292/300] train: 0.7075 - val: 0.7621\n",
      "[293/300] train: 0.7078 - val: 0.7635\n",
      "[294/300] train: 0.7074 - val: 0.7625\n",
      "[295/300] train: 0.7074 - val: 0.7625\n",
      "[296/300] train: 0.7075 - val: 0.7619\n",
      "[297/300] train: 0.7073 - val: 0.7623\n",
      "[298/300] train: 0.7074 - val: 0.7626\n",
      "[299/300] train: 0.7077 - val: 0.7632\n",
      "[300/300] train: 0.7075 - val: 0.7628\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    with open(f'logs/small.txt', 'a') as f:\n",
    "        print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "        f.write('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8723\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8722\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Test RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 881.0528\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 26\n",
    "plt.rcParams['axes.labelsize'] = 26\n",
    "plt.rcParams['xtick.labelsize'] = 26\n",
    "plt.rcParams['ytick.labelsize'] = 26\n",
    "plt.rcParams['legend.fontsize'] = 26\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim([0.2, 1.3])\n",
    "\n",
    "plt.savefig(figure_path + '/' + dataset +'-small-loss.png', dpi=300, bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "with open('best.weights.small', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "# medium net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=20, hidden=[10 ,10],\n",
    "    embedding_dropout=0.05, dropouts=[0.3, 0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.8778 - val: 0.7960\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7761 - val: 0.7788\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.7622 - val: 0.7744\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.7550 - val: 0.7715\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.7495 - val: 0.7700\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.7452 - val: 0.7690\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 0.7415 - val: 0.7679\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 0.7387 - val: 0.7669\n",
      "[009/300] train: 0.7367 - val: 0.7669\n",
      "[010/300] train: 0.7345 - val: 0.7671\n",
      "loss improvement on epoch: 11\n",
      "[011/300] train: 0.7330 - val: 0.7664\n",
      "loss improvement on epoch: 12\n",
      "[012/300] train: 0.7312 - val: 0.7653\n",
      "[013/300] train: 0.7302 - val: 0.7655\n",
      "[014/300] train: 0.7290 - val: 0.7659\n",
      "[015/300] train: 0.7278 - val: 0.7659\n",
      "[016/300] train: 0.7267 - val: 0.7658\n",
      "[017/300] train: 0.7258 - val: 0.7656\n",
      "[018/300] train: 0.7248 - val: 0.7663\n",
      "[019/300] train: 0.7240 - val: 0.7655\n",
      "[020/300] train: 0.7237 - val: 0.7654\n",
      "[021/300] train: 0.7229 - val: 0.7656\n",
      "[022/300] train: 0.7222 - val: 0.7657\n",
      "[023/300] train: 0.7218 - val: 0.7661\n",
      "[024/300] train: 0.7212 - val: 0.7664\n",
      "[025/300] train: 0.7205 - val: 0.7660\n",
      "[026/300] train: 0.7201 - val: 0.7659\n",
      "[027/300] train: 0.7196 - val: 0.7657\n",
      "[028/300] train: 0.7190 - val: 0.7655\n",
      "[029/300] train: 0.7186 - val: 0.7663\n",
      "[030/300] train: 0.7183 - val: 0.7667\n",
      "[031/300] train: 0.7179 - val: 0.7666\n",
      "[032/300] train: 0.7172 - val: 0.7662\n",
      "[033/300] train: 0.7168 - val: 0.7674\n",
      "[034/300] train: 0.7167 - val: 0.7662\n",
      "[035/300] train: 0.7167 - val: 0.7668\n",
      "[036/300] train: 0.7161 - val: 0.7666\n",
      "[037/300] train: 0.7162 - val: 0.7663\n",
      "[038/300] train: 0.7158 - val: 0.7672\n",
      "[039/300] train: 0.7155 - val: 0.7673\n",
      "[040/300] train: 0.7149 - val: 0.7676\n",
      "[041/300] train: 0.7144 - val: 0.7671\n",
      "[042/300] train: 0.7141 - val: 0.7667\n",
      "[043/300] train: 0.7144 - val: 0.7663\n",
      "[044/300] train: 0.7138 - val: 0.7664\n",
      "[045/300] train: 0.7141 - val: 0.7678\n",
      "[046/300] train: 0.7134 - val: 0.7672\n",
      "[047/300] train: 0.7131 - val: 0.7685\n",
      "[048/300] train: 0.7126 - val: 0.7672\n",
      "[049/300] train: 0.7129 - val: 0.7676\n",
      "[050/300] train: 0.7127 - val: 0.7674\n",
      "[051/300] train: 0.7123 - val: 0.7680\n",
      "[052/300] train: 0.7122 - val: 0.7677\n",
      "[053/300] train: 0.7117 - val: 0.7687\n",
      "[054/300] train: 0.7115 - val: 0.7668\n",
      "[055/300] train: 0.7116 - val: 0.7677\n",
      "[056/300] train: 0.7115 - val: 0.7688\n",
      "[057/300] train: 0.7111 - val: 0.7674\n",
      "[058/300] train: 0.7110 - val: 0.7685\n",
      "[059/300] train: 0.7105 - val: 0.7671\n",
      "[060/300] train: 0.7108 - val: 0.7678\n",
      "[061/300] train: 0.7105 - val: 0.7682\n",
      "[062/300] train: 0.7105 - val: 0.7687\n",
      "[063/300] train: 0.7104 - val: 0.7683\n",
      "[064/300] train: 0.7101 - val: 0.7686\n",
      "[065/300] train: 0.7102 - val: 0.7682\n",
      "[066/300] train: 0.7099 - val: 0.7691\n",
      "[067/300] train: 0.7092 - val: 0.7686\n",
      "[068/300] train: 0.7094 - val: 0.7694\n",
      "[069/300] train: 0.7093 - val: 0.7694\n",
      "[070/300] train: 0.7091 - val: 0.7683\n",
      "[071/300] train: 0.7091 - val: 0.7689\n",
      "[072/300] train: 0.7092 - val: 0.7691\n",
      "[073/300] train: 0.7091 - val: 0.7696\n",
      "[074/300] train: 0.7086 - val: 0.7688\n",
      "[075/300] train: 0.7089 - val: 0.7691\n",
      "[076/300] train: 0.7087 - val: 0.7697\n",
      "[077/300] train: 0.7082 - val: 0.7697\n",
      "[078/300] train: 0.7086 - val: 0.7688\n",
      "[079/300] train: 0.7082 - val: 0.7690\n",
      "[080/300] train: 0.7083 - val: 0.7693\n",
      "[081/300] train: 0.7081 - val: 0.7693\n",
      "[082/300] train: 0.7080 - val: 0.7696\n",
      "[083/300] train: 0.7078 - val: 0.7694\n",
      "[084/300] train: 0.7077 - val: 0.7694\n",
      "[085/300] train: 0.7076 - val: 0.7694\n",
      "[086/300] train: 0.7076 - val: 0.7690\n",
      "[087/300] train: 0.7075 - val: 0.7692\n",
      "[088/300] train: 0.7074 - val: 0.7692\n",
      "[089/300] train: 0.7073 - val: 0.7693\n",
      "[090/300] train: 0.7073 - val: 0.7695\n",
      "[091/300] train: 0.7072 - val: 0.7697\n",
      "[092/300] train: 0.7070 - val: 0.7691\n",
      "[093/300] train: 0.7071 - val: 0.7694\n",
      "[094/300] train: 0.7070 - val: 0.7694\n",
      "[095/300] train: 0.7067 - val: 0.7694\n",
      "[096/300] train: 0.7067 - val: 0.7685\n",
      "[097/300] train: 0.7067 - val: 0.7697\n",
      "[098/300] train: 0.7068 - val: 0.7696\n",
      "[099/300] train: 0.7066 - val: 0.7702\n",
      "[100/300] train: 0.7066 - val: 0.7689\n",
      "[101/300] train: 0.7066 - val: 0.7697\n",
      "[102/300] train: 0.7066 - val: 0.7709\n",
      "[103/300] train: 0.7061 - val: 0.7699\n",
      "[104/300] train: 0.7061 - val: 0.7700\n",
      "[105/300] train: 0.7061 - val: 0.7703\n",
      "[106/300] train: 0.7061 - val: 0.7705\n",
      "[107/300] train: 0.7062 - val: 0.7699\n",
      "[108/300] train: 0.7058 - val: 0.7702\n",
      "[109/300] train: 0.7054 - val: 0.7700\n",
      "[110/300] train: 0.7057 - val: 0.7697\n",
      "[111/300] train: 0.7055 - val: 0.7709\n",
      "[112/300] train: 0.7052 - val: 0.7696\n",
      "[113/300] train: 0.7055 - val: 0.7688\n",
      "[114/300] train: 0.7052 - val: 0.7705\n",
      "[115/300] train: 0.7052 - val: 0.7704\n",
      "[116/300] train: 0.7052 - val: 0.7699\n",
      "[117/300] train: 0.7054 - val: 0.7705\n",
      "[118/300] train: 0.7052 - val: 0.7704\n",
      "[119/300] train: 0.7052 - val: 0.7702\n",
      "[120/300] train: 0.7050 - val: 0.7712\n",
      "[121/300] train: 0.7050 - val: 0.7699\n",
      "[122/300] train: 0.7050 - val: 0.7698\n",
      "[123/300] train: 0.7049 - val: 0.7704\n",
      "[124/300] train: 0.7050 - val: 0.7692\n",
      "[125/300] train: 0.7047 - val: 0.7710\n",
      "[126/300] train: 0.7046 - val: 0.7700\n",
      "[127/300] train: 0.7047 - val: 0.7705\n",
      "[128/300] train: 0.7046 - val: 0.7698\n",
      "[129/300] train: 0.7047 - val: 0.7705\n",
      "[130/300] train: 0.7046 - val: 0.7715\n",
      "[131/300] train: 0.7049 - val: 0.7713\n",
      "[132/300] train: 0.7043 - val: 0.7706\n",
      "[133/300] train: 0.7043 - val: 0.7703\n",
      "[134/300] train: 0.7045 - val: 0.7720\n",
      "[135/300] train: 0.7041 - val: 0.7709\n",
      "[136/300] train: 0.7040 - val: 0.7708\n",
      "[137/300] train: 0.7045 - val: 0.7712\n",
      "[138/300] train: 0.7043 - val: 0.7692\n",
      "[139/300] train: 0.7043 - val: 0.7708\n",
      "[140/300] train: 0.7042 - val: 0.7714\n",
      "[141/300] train: 0.7038 - val: 0.7708\n",
      "[142/300] train: 0.7040 - val: 0.7720\n",
      "[143/300] train: 0.7037 - val: 0.7703\n",
      "[144/300] train: 0.7044 - val: 0.7711\n",
      "[145/300] train: 0.7037 - val: 0.7704\n",
      "[146/300] train: 0.7039 - val: 0.7708\n",
      "[147/300] train: 0.7036 - val: 0.7713\n",
      "[148/300] train: 0.7039 - val: 0.7721\n",
      "[149/300] train: 0.7036 - val: 0.7708\n",
      "[150/300] train: 0.7039 - val: 0.7714\n",
      "[151/300] train: 0.7037 - val: 0.7709\n",
      "[152/300] train: 0.7034 - val: 0.7706\n",
      "[153/300] train: 0.7032 - val: 0.7708\n",
      "[154/300] train: 0.7033 - val: 0.7707\n",
      "[155/300] train: 0.7038 - val: 0.7712\n",
      "[156/300] train: 0.7033 - val: 0.7713\n",
      "[157/300] train: 0.7033 - val: 0.7721\n",
      "[158/300] train: 0.7037 - val: 0.7718\n",
      "[159/300] train: 0.7031 - val: 0.7711\n",
      "[160/300] train: 0.7034 - val: 0.7712\n",
      "[161/300] train: 0.7030 - val: 0.7722\n",
      "[162/300] train: 0.7033 - val: 0.7722\n",
      "[163/300] train: 0.7031 - val: 0.7718\n",
      "[164/300] train: 0.7034 - val: 0.7718\n",
      "[165/300] train: 0.7032 - val: 0.7713\n",
      "[166/300] train: 0.7032 - val: 0.7714\n",
      "[167/300] train: 0.7032 - val: 0.7713\n",
      "[168/300] train: 0.7030 - val: 0.7705\n",
      "[169/300] train: 0.7028 - val: 0.7719\n",
      "[170/300] train: 0.7028 - val: 0.7723\n",
      "[171/300] train: 0.7026 - val: 0.7712\n",
      "[172/300] train: 0.7026 - val: 0.7714\n",
      "[173/300] train: 0.7029 - val: 0.7711\n",
      "[174/300] train: 0.7029 - val: 0.7712\n",
      "[175/300] train: 0.7031 - val: 0.7705\n",
      "[176/300] train: 0.7030 - val: 0.7724\n",
      "[177/300] train: 0.7027 - val: 0.7718\n",
      "[178/300] train: 0.7029 - val: 0.7717\n",
      "[179/300] train: 0.7026 - val: 0.7717\n",
      "[180/300] train: 0.7027 - val: 0.7720\n",
      "[181/300] train: 0.7025 - val: 0.7714\n",
      "[182/300] train: 0.7028 - val: 0.7718\n",
      "[183/300] train: 0.7026 - val: 0.7714\n",
      "[184/300] train: 0.7025 - val: 0.7722\n",
      "[185/300] train: 0.7026 - val: 0.7716\n",
      "[186/300] train: 0.7024 - val: 0.7712\n",
      "[187/300] train: 0.7026 - val: 0.7713\n",
      "[188/300] train: 0.7023 - val: 0.7703\n",
      "[189/300] train: 0.7023 - val: 0.7719\n",
      "[190/300] train: 0.7024 - val: 0.7717\n",
      "[191/300] train: 0.7025 - val: 0.7710\n",
      "[192/300] train: 0.7022 - val: 0.7717\n",
      "[193/300] train: 0.7022 - val: 0.7716\n",
      "[194/300] train: 0.7022 - val: 0.7708\n",
      "[195/300] train: 0.7024 - val: 0.7703\n",
      "[196/300] train: 0.7024 - val: 0.7723\n",
      "[197/300] train: 0.7022 - val: 0.7715\n",
      "[198/300] train: 0.7025 - val: 0.7710\n",
      "[199/300] train: 0.7026 - val: 0.7722\n",
      "[200/300] train: 0.7021 - val: 0.7713\n",
      "[201/300] train: 0.7020 - val: 0.7715\n",
      "[202/300] train: 0.7023 - val: 0.7719\n",
      "[203/300] train: 0.7016 - val: 0.7715\n",
      "[204/300] train: 0.7022 - val: 0.7715\n",
      "[205/300] train: 0.7020 - val: 0.7724\n",
      "[206/300] train: 0.7022 - val: 0.7716\n",
      "[207/300] train: 0.7022 - val: 0.7717\n",
      "[208/300] train: 0.7020 - val: 0.7726\n",
      "[209/300] train: 0.7015 - val: 0.7724\n",
      "[210/300] train: 0.7023 - val: 0.7717\n",
      "[211/300] train: 0.7017 - val: 0.7728\n",
      "[212/300] train: 0.7023 - val: 0.7725\n",
      "[213/300] train: 0.7018 - val: 0.7717\n",
      "[214/300] train: 0.7020 - val: 0.7722\n",
      "[215/300] train: 0.7019 - val: 0.7713\n",
      "[216/300] train: 0.7020 - val: 0.7722\n",
      "[217/300] train: 0.7017 - val: 0.7742\n",
      "[218/300] train: 0.7017 - val: 0.7718\n",
      "[219/300] train: 0.7015 - val: 0.7718\n",
      "[220/300] train: 0.7017 - val: 0.7714\n",
      "[221/300] train: 0.7016 - val: 0.7734\n",
      "[222/300] train: 0.7014 - val: 0.7725\n",
      "[223/300] train: 0.7016 - val: 0.7713\n",
      "[224/300] train: 0.7018 - val: 0.7710\n",
      "[225/300] train: 0.7015 - val: 0.7716\n",
      "[226/300] train: 0.7018 - val: 0.7712\n",
      "[227/300] train: 0.7011 - val: 0.7726\n",
      "[228/300] train: 0.7016 - val: 0.7727\n",
      "[229/300] train: 0.7017 - val: 0.7700\n",
      "[230/300] train: 0.7015 - val: 0.7728\n",
      "[231/300] train: 0.7013 - val: 0.7705\n",
      "[232/300] train: 0.7015 - val: 0.7712\n",
      "[233/300] train: 0.7017 - val: 0.7728\n",
      "[234/300] train: 0.7012 - val: 0.7720\n",
      "[235/300] train: 0.7015 - val: 0.7721\n",
      "[236/300] train: 0.7014 - val: 0.7724\n",
      "[237/300] train: 0.7015 - val: 0.7721\n",
      "[238/300] train: 0.7012 - val: 0.7728\n",
      "[239/300] train: 0.7017 - val: 0.7735\n",
      "[240/300] train: 0.7014 - val: 0.7719\n",
      "[241/300] train: 0.7013 - val: 0.7733\n",
      "[242/300] train: 0.7011 - val: 0.7722\n",
      "[243/300] train: 0.7011 - val: 0.7721\n",
      "[244/300] train: 0.7014 - val: 0.7727\n",
      "[245/300] train: 0.7013 - val: 0.7728\n",
      "[246/300] train: 0.7010 - val: 0.7735\n",
      "[247/300] train: 0.7014 - val: 0.7737\n",
      "[248/300] train: 0.7014 - val: 0.7741\n",
      "[249/300] train: 0.7011 - val: 0.7724\n",
      "[250/300] train: 0.7009 - val: 0.7721\n",
      "[251/300] train: 0.7010 - val: 0.7719\n",
      "[252/300] train: 0.7011 - val: 0.7733\n",
      "[253/300] train: 0.7007 - val: 0.7713\n",
      "[254/300] train: 0.7010 - val: 0.7731\n",
      "[255/300] train: 0.7007 - val: 0.7724\n",
      "[256/300] train: 0.7009 - val: 0.7713\n",
      "[257/300] train: 0.7007 - val: 0.7743\n",
      "[258/300] train: 0.7009 - val: 0.7728\n",
      "[259/300] train: 0.7012 - val: 0.7727\n",
      "[260/300] train: 0.7008 - val: 0.7726\n",
      "[261/300] train: 0.7009 - val: 0.7730\n",
      "[262/300] train: 0.7010 - val: 0.7734\n",
      "[263/300] train: 0.7011 - val: 0.7734\n",
      "[264/300] train: 0.7010 - val: 0.7714\n",
      "[265/300] train: 0.7008 - val: 0.7724\n",
      "[266/300] train: 0.7006 - val: 0.7731\n",
      "[267/300] train: 0.7009 - val: 0.7721\n",
      "[268/300] train: 0.7006 - val: 0.7725\n",
      "[269/300] train: 0.7008 - val: 0.7729\n",
      "[270/300] train: 0.7006 - val: 0.7725\n",
      "[271/300] train: 0.7008 - val: 0.7717\n",
      "[272/300] train: 0.7005 - val: 0.7724\n",
      "[273/300] train: 0.7008 - val: 0.7738\n",
      "[274/300] train: 0.7009 - val: 0.7739\n",
      "[275/300] train: 0.7007 - val: 0.7717\n",
      "[276/300] train: 0.7010 - val: 0.7719\n",
      "[277/300] train: 0.7008 - val: 0.7729\n",
      "[278/300] train: 0.7011 - val: 0.7716\n",
      "[279/300] train: 0.7006 - val: 0.7722\n",
      "[280/300] train: 0.7005 - val: 0.7722\n",
      "[281/300] train: 0.7010 - val: 0.7724\n",
      "[282/300] train: 0.7009 - val: 0.7727\n",
      "[283/300] train: 0.7008 - val: 0.7742\n",
      "[284/300] train: 0.7006 - val: 0.7731\n",
      "[285/300] train: 0.7004 - val: 0.7723\n",
      "[286/300] train: 0.7007 - val: 0.7727\n",
      "[287/300] train: 0.7005 - val: 0.7736\n",
      "[288/300] train: 0.7004 - val: 0.7746\n",
      "[289/300] train: 0.7006 - val: 0.7722\n",
      "[290/300] train: 0.7006 - val: 0.7725\n",
      "[291/300] train: 0.7006 - val: 0.7721\n",
      "[292/300] train: 0.7004 - val: 0.7745\n",
      "[293/300] train: 0.7009 - val: 0.7730\n",
      "[294/300] train: 0.7004 - val: 0.7729\n",
      "[295/300] train: 0.6999 - val: 0.7718\n",
      "[296/300] train: 0.7007 - val: 0.7717\n",
      "[297/300] train: 0.7003 - val: 0.7731\n",
      "[298/300] train: 0.7004 - val: 0.7729\n",
      "[299/300] train: 0.7002 - val: 0.7732\n",
      "[300/300] train: 0.7004 - val: 0.7728\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    with open(f'logs/medium.txt', 'a') as f:\n",
    "        print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "        f.write('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8755\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8752\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Test RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 1105.3203\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "with open('best.weights.medium', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 26\n",
    "plt.rcParams['axes.labelsize'] = 26\n",
    "plt.rcParams['xtick.labelsize'] = 26\n",
    "plt.rcParams['ytick.labelsize'] = 26\n",
    "plt.rcParams['legend.fontsize'] = 26\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim([0.2, 1.3])\n",
    "\n",
    "plt.savefig(figure_path + '/' + dataset +'-medium-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "# large net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=50, hidden=[100, 100, 100],\n",
    "    embedding_dropout=0.05, dropouts=[0.3, 0.3, 0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.7883 - val: 0.7387\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7133 - val: 0.7173\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.6867 - val: 0.7073\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.6664 - val: 0.7017\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.6484 - val: 0.6974\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.6326 - val: 0.6968\n",
      "[007/300] train: 0.6177 - val: 0.6975\n",
      "[008/300] train: 0.6046 - val: 0.6977\n",
      "[009/300] train: 0.5933 - val: 0.6984\n",
      "[010/300] train: 0.5833 - val: 0.7004\n",
      "[011/300] train: 0.5743 - val: 0.7023\n",
      "[012/300] train: 0.5665 - val: 0.7090\n",
      "[013/300] train: 0.5594 - val: 0.7048\n",
      "[014/300] train: 0.5532 - val: 0.7081\n",
      "[015/300] train: 0.5473 - val: 0.7108\n",
      "[016/300] train: 0.5419 - val: 0.7143\n",
      "[017/300] train: 0.5369 - val: 0.7157\n",
      "[018/300] train: 0.5328 - val: 0.7152\n",
      "[019/300] train: 0.5287 - val: 0.7198\n",
      "[020/300] train: 0.5247 - val: 0.7172\n",
      "[021/300] train: 0.5211 - val: 0.7216\n",
      "[022/300] train: 0.5180 - val: 0.7194\n",
      "[023/300] train: 0.5148 - val: 0.7218\n",
      "[024/300] train: 0.5119 - val: 0.7239\n",
      "[025/300] train: 0.5094 - val: 0.7257\n",
      "[026/300] train: 0.5067 - val: 0.7263\n",
      "[027/300] train: 0.5039 - val: 0.7272\n",
      "[028/300] train: 0.5020 - val: 0.7288\n",
      "[029/300] train: 0.4998 - val: 0.7335\n",
      "[030/300] train: 0.4974 - val: 0.7339\n",
      "[031/300] train: 0.4955 - val: 0.7357\n",
      "[032/300] train: 0.4935 - val: 0.7379\n",
      "[033/300] train: 0.4917 - val: 0.7385\n",
      "[034/300] train: 0.4902 - val: 0.7333\n",
      "[035/300] train: 0.4886 - val: 0.7372\n",
      "[036/300] train: 0.4871 - val: 0.7384\n",
      "[037/300] train: 0.4854 - val: 0.7390\n",
      "[038/300] train: 0.4838 - val: 0.7386\n",
      "[039/300] train: 0.4828 - val: 0.7372\n",
      "[040/300] train: 0.4815 - val: 0.7422\n",
      "[041/300] train: 0.4800 - val: 0.7465\n",
      "[042/300] train: 0.4788 - val: 0.7399\n",
      "[043/300] train: 0.4777 - val: 0.7422\n",
      "[044/300] train: 0.4768 - val: 0.7465\n",
      "[045/300] train: 0.4755 - val: 0.7465\n",
      "[046/300] train: 0.4745 - val: 0.7472\n",
      "[047/300] train: 0.4735 - val: 0.7486\n",
      "[048/300] train: 0.4725 - val: 0.7479\n",
      "[049/300] train: 0.4717 - val: 0.7464\n",
      "[050/300] train: 0.4708 - val: 0.7499\n",
      "[051/300] train: 0.4697 - val: 0.7463\n",
      "[052/300] train: 0.4690 - val: 0.7477\n",
      "[053/300] train: 0.4680 - val: 0.7488\n",
      "[054/300] train: 0.4676 - val: 0.7543\n",
      "[055/300] train: 0.4666 - val: 0.7483\n",
      "[056/300] train: 0.4660 - val: 0.7510\n",
      "[057/300] train: 0.4650 - val: 0.7519\n",
      "[058/300] train: 0.4642 - val: 0.7492\n",
      "[059/300] train: 0.4638 - val: 0.7501\n",
      "[060/300] train: 0.4633 - val: 0.7567\n",
      "[061/300] train: 0.4625 - val: 0.7496\n",
      "[062/300] train: 0.4617 - val: 0.7505\n",
      "[063/300] train: 0.4615 - val: 0.7520\n",
      "[064/300] train: 0.4606 - val: 0.7576\n",
      "[065/300] train: 0.4600 - val: 0.7551\n",
      "[066/300] train: 0.4592 - val: 0.7456\n",
      "[067/300] train: 0.4591 - val: 0.7540\n",
      "[068/300] train: 0.4586 - val: 0.7538\n",
      "[069/300] train: 0.4579 - val: 0.7524\n",
      "[070/300] train: 0.4574 - val: 0.7511\n",
      "[071/300] train: 0.4571 - val: 0.7624\n",
      "[072/300] train: 0.4563 - val: 0.7569\n",
      "[073/300] train: 0.4559 - val: 0.7585\n",
      "[074/300] train: 0.4559 - val: 0.7577\n",
      "[075/300] train: 0.4552 - val: 0.7611\n",
      "[076/300] train: 0.4545 - val: 0.7599\n",
      "[077/300] train: 0.4544 - val: 0.7605\n",
      "[078/300] train: 0.4535 - val: 0.7569\n",
      "[079/300] train: 0.4538 - val: 0.7548\n",
      "[080/300] train: 0.4533 - val: 0.7553\n",
      "[081/300] train: 0.4522 - val: 0.7645\n",
      "[082/300] train: 0.4522 - val: 0.7598\n",
      "[083/300] train: 0.4520 - val: 0.7610\n",
      "[084/300] train: 0.4513 - val: 0.7673\n",
      "[085/300] train: 0.4509 - val: 0.7595\n",
      "[086/300] train: 0.4507 - val: 0.7534\n",
      "[087/300] train: 0.4508 - val: 0.7655\n",
      "[088/300] train: 0.4500 - val: 0.7640\n",
      "[089/300] train: 0.4497 - val: 0.7630\n",
      "[090/300] train: 0.4495 - val: 0.7593\n",
      "[091/300] train: 0.4488 - val: 0.7648\n",
      "[092/300] train: 0.4487 - val: 0.7604\n",
      "[093/300] train: 0.4483 - val: 0.7657\n",
      "[094/300] train: 0.4479 - val: 0.7626\n",
      "[095/300] train: 0.4475 - val: 0.7683\n",
      "[096/300] train: 0.4477 - val: 0.7586\n",
      "[097/300] train: 0.4477 - val: 0.7640\n",
      "[098/300] train: 0.4469 - val: 0.7689\n",
      "[099/300] train: 0.4469 - val: 0.7647\n",
      "[100/300] train: 0.4467 - val: 0.7634\n",
      "[101/300] train: 0.4462 - val: 0.7650\n",
      "[102/300] train: 0.4460 - val: 0.7606\n",
      "[103/300] train: 0.4456 - val: 0.7610\n",
      "[104/300] train: 0.4454 - val: 0.7627\n",
      "[105/300] train: 0.4453 - val: 0.7667\n",
      "[106/300] train: 0.4448 - val: 0.7596\n",
      "[107/300] train: 0.4446 - val: 0.7602\n",
      "[108/300] train: 0.4443 - val: 0.7661\n",
      "[109/300] train: 0.4441 - val: 0.7671\n",
      "[110/300] train: 0.4442 - val: 0.7697\n",
      "[111/300] train: 0.4436 - val: 0.7639\n",
      "[112/300] train: 0.4437 - val: 0.7674\n",
      "[113/300] train: 0.4434 - val: 0.7684\n",
      "[114/300] train: 0.4430 - val: 0.7613\n",
      "[115/300] train: 0.4429 - val: 0.7635\n",
      "[116/300] train: 0.4424 - val: 0.7684\n",
      "[117/300] train: 0.4423 - val: 0.7688\n",
      "[118/300] train: 0.4423 - val: 0.7711\n",
      "[119/300] train: 0.4418 - val: 0.7619\n",
      "[120/300] train: 0.4418 - val: 0.7624\n",
      "[121/300] train: 0.4417 - val: 0.7689\n",
      "[122/300] train: 0.4413 - val: 0.7638\n",
      "[123/300] train: 0.4413 - val: 0.7661\n",
      "[124/300] train: 0.4409 - val: 0.7641\n",
      "[125/300] train: 0.4408 - val: 0.7676\n",
      "[126/300] train: 0.4407 - val: 0.7732\n",
      "[127/300] train: 0.4403 - val: 0.7725\n",
      "[128/300] train: 0.4402 - val: 0.7693\n",
      "[129/300] train: 0.4401 - val: 0.7740\n",
      "[130/300] train: 0.4396 - val: 0.7726\n",
      "[131/300] train: 0.4397 - val: 0.7724\n",
      "[132/300] train: 0.4396 - val: 0.7652\n",
      "[133/300] train: 0.4391 - val: 0.7674\n",
      "[134/300] train: 0.4391 - val: 0.7717\n",
      "[135/300] train: 0.4388 - val: 0.7730\n",
      "[136/300] train: 0.4391 - val: 0.7704\n",
      "[137/300] train: 0.4387 - val: 0.7638\n",
      "[138/300] train: 0.4387 - val: 0.7655\n",
      "[139/300] train: 0.4383 - val: 0.7732\n",
      "[140/300] train: 0.4381 - val: 0.7639\n",
      "[141/300] train: 0.4381 - val: 0.7672\n",
      "[142/300] train: 0.4379 - val: 0.7712\n",
      "[143/300] train: 0.4376 - val: 0.7685\n",
      "[144/300] train: 0.4377 - val: 0.7594\n",
      "[145/300] train: 0.4376 - val: 0.7716\n",
      "[146/300] train: 0.4374 - val: 0.7697\n",
      "[147/300] train: 0.4371 - val: 0.7680\n",
      "[148/300] train: 0.4368 - val: 0.7702\n",
      "[149/300] train: 0.4368 - val: 0.7738\n",
      "[150/300] train: 0.4365 - val: 0.7625\n",
      "[151/300] train: 0.4364 - val: 0.7690\n",
      "[152/300] train: 0.4365 - val: 0.7769\n",
      "[153/300] train: 0.4361 - val: 0.7751\n",
      "[154/300] train: 0.4359 - val: 0.7748\n",
      "[155/300] train: 0.4358 - val: 0.7754\n",
      "[156/300] train: 0.4361 - val: 0.7685\n",
      "[157/300] train: 0.4358 - val: 0.7719\n",
      "[158/300] train: 0.4357 - val: 0.7696\n",
      "[159/300] train: 0.4353 - val: 0.7798\n",
      "[160/300] train: 0.4353 - val: 0.7707\n",
      "[161/300] train: 0.4352 - val: 0.7678\n",
      "[162/300] train: 0.4353 - val: 0.7650\n",
      "[163/300] train: 0.4353 - val: 0.7751\n",
      "[164/300] train: 0.4350 - val: 0.7725\n",
      "[165/300] train: 0.4348 - val: 0.7644\n",
      "[166/300] train: 0.4345 - val: 0.7702\n",
      "[167/300] train: 0.4343 - val: 0.7717\n",
      "[168/300] train: 0.4345 - val: 0.7778\n",
      "[169/300] train: 0.4344 - val: 0.7669\n",
      "[170/300] train: 0.4341 - val: 0.7709\n",
      "[171/300] train: 0.4341 - val: 0.7722\n",
      "[172/300] train: 0.4340 - val: 0.7812\n",
      "[173/300] train: 0.4340 - val: 0.7733\n",
      "[174/300] train: 0.4339 - val: 0.7781\n",
      "[175/300] train: 0.4337 - val: 0.7660\n",
      "[176/300] train: 0.4333 - val: 0.7737\n",
      "[177/300] train: 0.4333 - val: 0.7728\n",
      "[178/300] train: 0.4334 - val: 0.7728\n",
      "[179/300] train: 0.4331 - val: 0.7911\n",
      "[180/300] train: 0.4331 - val: 0.7682\n",
      "[181/300] train: 0.4331 - val: 0.7707\n",
      "[182/300] train: 0.4330 - val: 0.7659\n",
      "[183/300] train: 0.4329 - val: 0.7798\n",
      "[184/300] train: 0.4322 - val: 0.7673\n",
      "[185/300] train: 0.4325 - val: 0.7776\n",
      "[186/300] train: 0.4324 - val: 0.7726\n",
      "[187/300] train: 0.4324 - val: 0.7747\n",
      "[188/300] train: 0.4319 - val: 0.7701\n",
      "[189/300] train: 0.4322 - val: 0.7777\n",
      "[190/300] train: 0.4322 - val: 0.7751\n",
      "[191/300] train: 0.4317 - val: 0.7793\n",
      "[192/300] train: 0.4319 - val: 0.7692\n",
      "[193/300] train: 0.4315 - val: 0.7694\n",
      "[194/300] train: 0.4316 - val: 0.7740\n",
      "[195/300] train: 0.4313 - val: 0.7685\n",
      "[196/300] train: 0.4318 - val: 0.7803\n",
      "[197/300] train: 0.4311 - val: 0.7803\n",
      "[198/300] train: 0.4313 - val: 0.7722\n",
      "[199/300] train: 0.4311 - val: 0.7791\n",
      "[200/300] train: 0.4312 - val: 0.7763\n",
      "[201/300] train: 0.4309 - val: 0.7736\n",
      "[202/300] train: 0.4309 - val: 0.7661\n",
      "[203/300] train: 0.4308 - val: 0.7765\n",
      "[204/300] train: 0.4310 - val: 0.7736\n",
      "[205/300] train: 0.4308 - val: 0.7751\n",
      "[206/300] train: 0.4308 - val: 0.7733\n",
      "[207/300] train: 0.4306 - val: 0.7774\n",
      "[208/300] train: 0.4306 - val: 0.7739\n",
      "[209/300] train: 0.4304 - val: 0.7700\n",
      "[210/300] train: 0.4302 - val: 0.7782\n",
      "[211/300] train: 0.4299 - val: 0.7823\n",
      "[212/300] train: 0.4303 - val: 0.7721\n",
      "[213/300] train: 0.4299 - val: 0.7770\n",
      "[214/300] train: 0.4300 - val: 0.7741\n",
      "[215/300] train: 0.4298 - val: 0.7808\n",
      "[216/300] train: 0.4297 - val: 0.7761\n",
      "[217/300] train: 0.4298 - val: 0.7761\n",
      "[218/300] train: 0.4293 - val: 0.7764\n",
      "[219/300] train: 0.4296 - val: 0.7781\n",
      "[220/300] train: 0.4295 - val: 0.7767\n",
      "[221/300] train: 0.4295 - val: 0.7706\n",
      "[222/300] train: 0.4295 - val: 0.7828\n",
      "[223/300] train: 0.4292 - val: 0.7752\n",
      "[224/300] train: 0.4292 - val: 0.7680\n",
      "[225/300] train: 0.4293 - val: 0.7765\n",
      "[226/300] train: 0.4292 - val: 0.7746\n",
      "[227/300] train: 0.4290 - val: 0.7737\n",
      "[228/300] train: 0.4289 - val: 0.7733\n",
      "[229/300] train: 0.4289 - val: 0.7800\n",
      "[230/300] train: 0.4287 - val: 0.7751\n",
      "[231/300] train: 0.4285 - val: 0.7752\n",
      "[232/300] train: 0.4286 - val: 0.7763\n",
      "[233/300] train: 0.4284 - val: 0.7775\n",
      "[234/300] train: 0.4286 - val: 0.7745\n",
      "[235/300] train: 0.4284 - val: 0.7714\n",
      "[236/300] train: 0.4283 - val: 0.7737\n",
      "[237/300] train: 0.4280 - val: 0.7746\n",
      "[238/300] train: 0.4278 - val: 0.7697\n",
      "[239/300] train: 0.4280 - val: 0.7705\n",
      "[240/300] train: 0.4278 - val: 0.7709\n",
      "[241/300] train: 0.4283 - val: 0.7735\n",
      "[242/300] train: 0.4281 - val: 0.7728\n",
      "[243/300] train: 0.4276 - val: 0.7746\n",
      "[244/300] train: 0.4278 - val: 0.7796\n",
      "[245/300] train: 0.4280 - val: 0.7819\n",
      "[246/300] train: 0.4277 - val: 0.7788\n",
      "[247/300] train: 0.4275 - val: 0.7801\n",
      "[248/300] train: 0.4276 - val: 0.7788\n",
      "[249/300] train: 0.4275 - val: 0.7804\n",
      "[250/300] train: 0.4274 - val: 0.7710\n",
      "[251/300] train: 0.4271 - val: 0.7782\n",
      "[252/300] train: 0.4272 - val: 0.7723\n",
      "[253/300] train: 0.4271 - val: 0.7725\n",
      "[254/300] train: 0.4273 - val: 0.7724\n",
      "[255/300] train: 0.4271 - val: 0.7793\n",
      "[256/300] train: 0.4272 - val: 0.7761\n",
      "[257/300] train: 0.4269 - val: 0.7853\n",
      "[258/300] train: 0.4268 - val: 0.7847\n",
      "[259/300] train: 0.4268 - val: 0.7828\n",
      "[260/300] train: 0.4270 - val: 0.7843\n",
      "[261/300] train: 0.4269 - val: 0.7747\n",
      "[262/300] train: 0.4267 - val: 0.7693\n",
      "[263/300] train: 0.4264 - val: 0.7800\n",
      "[264/300] train: 0.4268 - val: 0.7803\n",
      "[265/300] train: 0.4264 - val: 0.7740\n",
      "[266/300] train: 0.4269 - val: 0.7789\n",
      "[267/300] train: 0.4263 - val: 0.7778\n",
      "[268/300] train: 0.4263 - val: 0.7706\n",
      "[269/300] train: 0.4262 - val: 0.7787\n",
      "[270/300] train: 0.4262 - val: 0.7726\n",
      "[271/300] train: 0.4260 - val: 0.7818\n",
      "[272/300] train: 0.4262 - val: 0.7764\n",
      "[273/300] train: 0.4262 - val: 0.7769\n",
      "[274/300] train: 0.4261 - val: 0.7733\n",
      "[275/300] train: 0.4258 - val: 0.7810\n",
      "[276/300] train: 0.4260 - val: 0.7877\n",
      "[277/300] train: 0.4258 - val: 0.7738\n",
      "[278/300] train: 0.4260 - val: 0.7835\n",
      "[279/300] train: 0.4260 - val: 0.7707\n",
      "[280/300] train: 0.4256 - val: 0.7743\n",
      "[281/300] train: 0.4257 - val: 0.7803\n",
      "[282/300] train: 0.4255 - val: 0.7775\n",
      "[283/300] train: 0.4256 - val: 0.7792\n",
      "[284/300] train: 0.4254 - val: 0.7766\n",
      "[285/300] train: 0.4254 - val: 0.7730\n",
      "[286/300] train: 0.4256 - val: 0.7754\n",
      "[287/300] train: 0.4258 - val: 0.7820\n",
      "[288/300] train: 0.4252 - val: 0.7782\n",
      "[289/300] train: 0.4252 - val: 0.7710\n",
      "[290/300] train: 0.4254 - val: 0.7812\n",
      "[291/300] train: 0.4253 - val: 0.7881\n",
      "[292/300] train: 0.4253 - val: 0.7827\n",
      "[293/300] train: 0.4250 - val: 0.7735\n",
      "[294/300] train: 0.4255 - val: 0.7734\n",
      "[295/300] train: 0.4254 - val: 0.7829\n",
      "[296/300] train: 0.4251 - val: 0.7756\n",
      "[297/300] train: 0.4251 - val: 0.7779\n",
      "[298/300] train: 0.4251 - val: 0.7835\n",
      "[299/300] train: 0.4249 - val: 0.7762\n",
      "[300/300] train: 0.4245 - val: 0.7784\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    with open(f'logs/large.txt', 'a') as f:\n",
    "        print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "        f.write('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8351\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8346\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Test RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration: 1727.9047\n"
     ]
    }
   ],
   "source": [
    "print(f'duration: {round(time.time() - start, 4)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "with open('best.weights.big', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 26\n",
    "plt.rcParams['axes.labelsize'] = 26\n",
    "plt.rcParams['xtick.labelsize'] = 26\n",
    "plt.rcParams['ytick.labelsize'] = 26\n",
    "plt.rcParams['legend.fontsize'] = 26\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim([0.2, 1.3])\n",
    "\n",
    "plt.savefig(figure_path + '/' + dataset +'-large-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f57757a1",
   "language": "python",
   "display_name": "PyCharm (rs-via-gnn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}