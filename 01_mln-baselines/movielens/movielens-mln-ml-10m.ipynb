{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MovieLens MLN Recommendation via PyTorch\n",
    "\n",
    "adapted from https://github.com/fastai/fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import time\n",
    "\n",
    "figure_path = '/home/weiss/git/thesis/doc/figures/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def set_random_seed(state=1):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)\n",
    "\n",
    "RANDOM_STATE = 2021\n",
    "set_random_seed(RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    files = {}\n",
    "    path = Path(path)\n",
    "    for filename in path.glob('*'):\n",
    "        if filename.suffix == '.csv':\n",
    "            files[filename.stem] = pd.read_csv(filename)\n",
    "        elif filename.suffix == '.dat':\n",
    "            if filename.stem == 'ratings':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "            else:\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "            data = pd.read_csv(filename, sep='::', names=columns, engine='python')\n",
    "            files[filename.stem] = data\n",
    "        elif filename.suffix == '.data':  # ml-100k\n",
    "            if filename.stem == 'u':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "                data = pd.read_csv(filename, sep='\\t', names=columns, engine='python')\n",
    "                files['ratings'] = data\n",
    "        elif filename.suffix == '.item':  # ml-100k\n",
    "            if filename.stem == 'u':\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "                data = pd.read_csv(filename, sep='|', names=columns, engine='python')\n",
    "                files['movies'] = data\n",
    "    return files['ratings'], files['movies']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = 'ml-10m'\n",
    "\n",
    "# pick one of the available folders\n",
    "ratings, movies = read_data('/home/weiss/rs_data/'+dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   userId  movieId  rating  timestamp\n0       1      122     5.0  838985046\n1       1      185     5.0  838983525\n2       1      231     5.0  838983392\n3       1      292     5.0  838983421\n4       1      316     5.0  838983392",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>122</td>\n      <td>5.0</td>\n      <td>838985046</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>185</td>\n      <td>5.0</td>\n      <td>838983525</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>231</td>\n      <td>5.0</td>\n      <td>838983392</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>292</td>\n      <td>5.0</td>\n      <td>838983421</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>316</td>\n      <td>5.0</td>\n      <td>838983392</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   movieId                               title  \\\n0        1                    Toy Story (1995)   \n1        2                      Jumanji (1995)   \n2        3             Grumpier Old Men (1995)   \n3        4            Waiting to Exhale (1995)   \n4        5  Father of the Bride Part II (1995)   \n\n                                        genres  \n0  Adventure|Animation|Children|Comedy|Fantasy  \n1                   Adventure|Children|Fantasy  \n2                               Comedy|Romance  \n3                         Comedy|Drama|Romance  \n4                                       Comedy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>Adventure|Children|Fantasy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>Comedy|Romance</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>Comedy|Drama|Romance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>Comedy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 69878 users, 10677 movies\n",
      "Dataset shape: (10000054, 2)\n",
      "Target shape: (10000054,)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    if top is not None:\n",
    "        ratings.groupby('userId')['rating'].count()\n",
    "\n",
    "    unique_users = ratings.userId.unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = ratings.userId.map(user_to_index)\n",
    "\n",
    "    unique_movies = ratings.movieId.unique()\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)}\n",
    "    new_movies = ratings.movieId.map(movie_to_index)\n",
    "\n",
    "    n_users = unique_users.shape[0]\n",
    "    n_movies = unique_movies.shape[0]\n",
    "\n",
    "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_movies})\n",
    "    y = ratings['rating'].astype(np.float32)\n",
    "    return (n_users, n_movies), (X, y), (user_to_index, movie_to_index)\n",
    "\n",
    "(n, m), (X, y), _ = create_dataset(ratings)\n",
    "print(f'Embeddings: {n} users, {m} movies')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, random_state=RANDOM_STATE)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=RANDOM_STATE)\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid), 'test': (X_test, y_test)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_valid), 'test': len(X_test)}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class RatingsIterator:\n",
    "\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in RatingsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class RecommenderNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates dense MLN with embedding layers.\n",
    "\n",
    "    Args:\n",
    "        n_users:\n",
    "            Number of unique users in the dataset.\n",
    "\n",
    "        n_movies:\n",
    "            Number of unique movies in the dataset.\n",
    "\n",
    "        n_factors:\n",
    "            Number of columns in the embeddings matrix.\n",
    "\n",
    "        embedding_dropout:\n",
    "            Dropout rate to apply right after embeddings layer.\n",
    "\n",
    "        hidden:\n",
    "            A single integer or a list of integers defining the number of\n",
    "            units in hidden layer(s).\n",
    "\n",
    "        dropouts:\n",
    "            A single integer or a list of integers defining the dropout\n",
    "            layers rates applied right after each of hidden layers.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_movies,\n",
    "                 n_factors=50, embedding_dropout=0.02,\n",
    "                 hidden=10, dropouts=0.2):\n",
    "\n",
    "        super().__init__()\n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "\n",
    "        def gen_layers(n_in):\n",
    "            \"\"\"\n",
    "            A generator that yields a sequence of hidden layers and\n",
    "            their activations/dropouts.\n",
    "\n",
    "            Note that the function captures `hidden` and `dropouts`\n",
    "            values from the outer scope.\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "\n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self._init()\n",
    "\n",
    "    def forward(self, users, movies, minmax=None):\n",
    "        features = torch.cat([self.u(users), self.m(movies)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        #out = self.relu(self.fc(x))  # relu delivers worse rsme\n",
    "        if minmax is not None:\n",
    "            min_rating, max_rating = minmax\n",
    "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "        return out\n",
    "\n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Setup embeddings and hidden layers with reasonable initial values.\n",
    "        \"\"\"\n",
    "\n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "\n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)\n",
    "\n",
    "\n",
    "def get_list(n):\n",
    "    if isinstance(n, (int, float)):\n",
    "        return [n]\n",
    "    elif hasattr(n, '__iter__'):\n",
    "        return list(n)\n",
    "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def plot_lr(schedule):\n",
    "    ts = list(range(1000))\n",
    "    y = [schedule(t, 0.001) for t in ts]\n",
    "    plt.plot(ts, y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5, 5.0)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = float(ratings.rating.min()), float(ratings.rating.max())\n",
    "minmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# small net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=10, hidden=[10],\n",
    "    embedding_dropout=0.05, dropouts=[0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.8454 - val: 0.7826\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7685 - val: 0.7729\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.7585 - val: 0.7700\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.7538 - val: 0.7681\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.7501 - val: 0.7671\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.7468 - val: 0.7660\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 0.7443 - val: 0.7652\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 0.7419 - val: 0.7643\n",
      "[009/300] train: 0.7402 - val: 0.7643\n",
      "loss improvement on epoch: 10\n",
      "[010/300] train: 0.7385 - val: 0.7639\n",
      "loss improvement on epoch: 11\n",
      "[011/300] train: 0.7372 - val: 0.7631\n",
      "loss improvement on epoch: 12\n",
      "[012/300] train: 0.7359 - val: 0.7624\n",
      "loss improvement on epoch: 13\n",
      "[013/300] train: 0.7342 - val: 0.7619\n",
      "loss improvement on epoch: 14\n",
      "[014/300] train: 0.7330 - val: 0.7615\n",
      "[015/300] train: 0.7314 - val: 0.7615\n",
      "loss improvement on epoch: 16\n",
      "[016/300] train: 0.7306 - val: 0.7610\n",
      "loss improvement on epoch: 17\n",
      "[017/300] train: 0.7295 - val: 0.7609\n",
      "loss improvement on epoch: 18\n",
      "[018/300] train: 0.7285 - val: 0.7606\n",
      "[019/300] train: 0.7280 - val: 0.7611\n",
      "loss improvement on epoch: 20\n",
      "[020/300] train: 0.7265 - val: 0.7599\n",
      "[021/300] train: 0.7258 - val: 0.7603\n",
      "loss improvement on epoch: 22\n",
      "[022/300] train: 0.7248 - val: 0.7599\n",
      "[023/300] train: 0.7239 - val: 0.7609\n",
      "[024/300] train: 0.7234 - val: 0.7606\n",
      "[025/300] train: 0.7227 - val: 0.7603\n",
      "[026/300] train: 0.7222 - val: 0.7605\n",
      "[027/300] train: 0.7217 - val: 0.7607\n",
      "[028/300] train: 0.7216 - val: 0.7607\n",
      "[029/300] train: 0.7209 - val: 0.7606\n",
      "[030/300] train: 0.7207 - val: 0.7607\n",
      "[031/300] train: 0.7203 - val: 0.7612\n",
      "[032/300] train: 0.7202 - val: 0.7606\n",
      "[033/300] train: 0.7196 - val: 0.7606\n",
      "[034/300] train: 0.7197 - val: 0.7609\n",
      "[035/300] train: 0.7191 - val: 0.7609\n",
      "[036/300] train: 0.7188 - val: 0.7606\n",
      "[037/300] train: 0.7184 - val: 0.7612\n",
      "[038/300] train: 0.7187 - val: 0.7612\n",
      "[039/300] train: 0.7181 - val: 0.7609\n",
      "[040/300] train: 0.7177 - val: 0.7604\n",
      "[041/300] train: 0.7175 - val: 0.7609\n",
      "[042/300] train: 0.7177 - val: 0.7610\n",
      "[043/300] train: 0.7170 - val: 0.7611\n",
      "[044/300] train: 0.7170 - val: 0.7610\n",
      "[045/300] train: 0.7169 - val: 0.7607\n",
      "[046/300] train: 0.7166 - val: 0.7609\n",
      "[047/300] train: 0.7165 - val: 0.7607\n",
      "[048/300] train: 0.7163 - val: 0.7607\n",
      "[049/300] train: 0.7164 - val: 0.7611\n",
      "[050/300] train: 0.7160 - val: 0.7607\n",
      "[051/300] train: 0.7159 - val: 0.7610\n",
      "[052/300] train: 0.7158 - val: 0.7613\n",
      "[053/300] train: 0.7157 - val: 0.7611\n",
      "[054/300] train: 0.7154 - val: 0.7614\n",
      "[055/300] train: 0.7153 - val: 0.7614\n",
      "[056/300] train: 0.7151 - val: 0.7611\n",
      "[057/300] train: 0.7154 - val: 0.7615\n",
      "[058/300] train: 0.7151 - val: 0.7613\n",
      "[059/300] train: 0.7147 - val: 0.7609\n",
      "[060/300] train: 0.7148 - val: 0.7611\n",
      "[061/300] train: 0.7145 - val: 0.7611\n",
      "[062/300] train: 0.7147 - val: 0.7612\n",
      "[063/300] train: 0.7144 - val: 0.7619\n",
      "[064/300] train: 0.7142 - val: 0.7606\n",
      "[065/300] train: 0.7140 - val: 0.7623\n",
      "[066/300] train: 0.7142 - val: 0.7609\n",
      "[067/300] train: 0.7142 - val: 0.7615\n",
      "[068/300] train: 0.7137 - val: 0.7617\n",
      "[069/300] train: 0.7138 - val: 0.7616\n",
      "[070/300] train: 0.7139 - val: 0.7610\n",
      "[071/300] train: 0.7138 - val: 0.7615\n",
      "[072/300] train: 0.7136 - val: 0.7614\n",
      "[073/300] train: 0.7137 - val: 0.7611\n",
      "[074/300] train: 0.7137 - val: 0.7616\n",
      "[075/300] train: 0.7135 - val: 0.7618\n",
      "[076/300] train: 0.7135 - val: 0.7615\n",
      "[077/300] train: 0.7132 - val: 0.7614\n",
      "[078/300] train: 0.7130 - val: 0.7618\n",
      "[079/300] train: 0.7129 - val: 0.7614\n",
      "[080/300] train: 0.7131 - val: 0.7618\n",
      "[081/300] train: 0.7129 - val: 0.7612\n",
      "[082/300] train: 0.7128 - val: 0.7612\n",
      "[083/300] train: 0.7128 - val: 0.7615\n",
      "[084/300] train: 0.7126 - val: 0.7616\n",
      "[085/300] train: 0.7130 - val: 0.7619\n",
      "[086/300] train: 0.7126 - val: 0.7621\n",
      "[087/300] train: 0.7126 - val: 0.7615\n",
      "[088/300] train: 0.7128 - val: 0.7614\n",
      "[089/300] train: 0.7126 - val: 0.7625\n",
      "[090/300] train: 0.7124 - val: 0.7613\n",
      "[091/300] train: 0.7125 - val: 0.7614\n",
      "[092/300] train: 0.7125 - val: 0.7613\n",
      "[093/300] train: 0.7119 - val: 0.7614\n",
      "[094/300] train: 0.7121 - val: 0.7616\n",
      "[095/300] train: 0.7120 - val: 0.7613\n",
      "[096/300] train: 0.7121 - val: 0.7611\n",
      "[097/300] train: 0.7121 - val: 0.7619\n",
      "[098/300] train: 0.7119 - val: 0.7616\n",
      "[099/300] train: 0.7121 - val: 0.7614\n",
      "[100/300] train: 0.7120 - val: 0.7615\n",
      "[101/300] train: 0.7117 - val: 0.7615\n",
      "[102/300] train: 0.7118 - val: 0.7614\n",
      "[103/300] train: 0.7118 - val: 0.7620\n",
      "[104/300] train: 0.7115 - val: 0.7612\n",
      "[105/300] train: 0.7118 - val: 0.7611\n",
      "[106/300] train: 0.7117 - val: 0.7606\n",
      "[107/300] train: 0.7116 - val: 0.7624\n",
      "[108/300] train: 0.7115 - val: 0.7614\n",
      "[109/300] train: 0.7113 - val: 0.7622\n",
      "[110/300] train: 0.7113 - val: 0.7617\n",
      "[111/300] train: 0.7113 - val: 0.7626\n",
      "[112/300] train: 0.7117 - val: 0.7617\n",
      "[113/300] train: 0.7114 - val: 0.7621\n",
      "[114/300] train: 0.7114 - val: 0.7622\n",
      "[115/300] train: 0.7114 - val: 0.7619\n",
      "[116/300] train: 0.7110 - val: 0.7622\n",
      "[117/300] train: 0.7109 - val: 0.7615\n",
      "[118/300] train: 0.7112 - val: 0.7617\n",
      "[119/300] train: 0.7106 - val: 0.7618\n",
      "[120/300] train: 0.7108 - val: 0.7627\n",
      "[121/300] train: 0.7110 - val: 0.7620\n",
      "[122/300] train: 0.7108 - val: 0.7617\n",
      "[123/300] train: 0.7111 - val: 0.7621\n",
      "[124/300] train: 0.7108 - val: 0.7625\n",
      "[125/300] train: 0.7108 - val: 0.7621\n",
      "[126/300] train: 0.7105 - val: 0.7626\n",
      "[127/300] train: 0.7106 - val: 0.7621\n",
      "[128/300] train: 0.7105 - val: 0.7620\n",
      "[129/300] train: 0.7106 - val: 0.7620\n",
      "[130/300] train: 0.7104 - val: 0.7611\n",
      "[131/300] train: 0.7103 - val: 0.7627\n",
      "[132/300] train: 0.7107 - val: 0.7617\n",
      "[133/300] train: 0.7105 - val: 0.7617\n",
      "[134/300] train: 0.7104 - val: 0.7620\n",
      "[135/300] train: 0.7108 - val: 0.7619\n",
      "[136/300] train: 0.7104 - val: 0.7621\n",
      "[137/300] train: 0.7102 - val: 0.7622\n",
      "[138/300] train: 0.7101 - val: 0.7616\n",
      "[139/300] train: 0.7103 - val: 0.7619\n",
      "[140/300] train: 0.7104 - val: 0.7618\n",
      "[141/300] train: 0.7101 - val: 0.7623\n",
      "[142/300] train: 0.7102 - val: 0.7617\n",
      "[143/300] train: 0.7104 - val: 0.7620\n",
      "[144/300] train: 0.7099 - val: 0.7609\n",
      "[145/300] train: 0.7101 - val: 0.7625\n",
      "[146/300] train: 0.7102 - val: 0.7615\n",
      "[147/300] train: 0.7100 - val: 0.7623\n",
      "[148/300] train: 0.7099 - val: 0.7624\n",
      "[149/300] train: 0.7102 - val: 0.7623\n",
      "[150/300] train: 0.7103 - val: 0.7619\n",
      "[151/300] train: 0.7101 - val: 0.7627\n",
      "[152/300] train: 0.7100 - val: 0.7624\n",
      "[153/300] train: 0.7101 - val: 0.7624\n",
      "[154/300] train: 0.7101 - val: 0.7617\n",
      "[155/300] train: 0.7101 - val: 0.7622\n",
      "[156/300] train: 0.7101 - val: 0.7629\n",
      "[157/300] train: 0.7102 - val: 0.7620\n",
      "[158/300] train: 0.7097 - val: 0.7623\n",
      "[159/300] train: 0.7097 - val: 0.7622\n",
      "[160/300] train: 0.7097 - val: 0.7623\n",
      "[161/300] train: 0.7095 - val: 0.7624\n",
      "[162/300] train: 0.7094 - val: 0.7616\n",
      "[163/300] train: 0.7095 - val: 0.7618\n",
      "[164/300] train: 0.7098 - val: 0.7615\n",
      "[165/300] train: 0.7096 - val: 0.7622\n",
      "[166/300] train: 0.7099 - val: 0.7625\n",
      "[167/300] train: 0.7095 - val: 0.7623\n",
      "[168/300] train: 0.7093 - val: 0.7621\n",
      "[169/300] train: 0.7098 - val: 0.7622\n",
      "[170/300] train: 0.7096 - val: 0.7615\n",
      "[171/300] train: 0.7096 - val: 0.7618\n",
      "[172/300] train: 0.7096 - val: 0.7627\n",
      "[173/300] train: 0.7096 - val: 0.7631\n",
      "[174/300] train: 0.7093 - val: 0.7623\n",
      "[175/300] train: 0.7096 - val: 0.7623\n",
      "[176/300] train: 0.7094 - val: 0.7622\n",
      "[177/300] train: 0.7095 - val: 0.7612\n",
      "[178/300] train: 0.7094 - val: 0.7622\n",
      "[179/300] train: 0.7094 - val: 0.7625\n",
      "[180/300] train: 0.7091 - val: 0.7621\n",
      "[181/300] train: 0.7095 - val: 0.7622\n",
      "[182/300] train: 0.7094 - val: 0.7624\n",
      "[183/300] train: 0.7092 - val: 0.7615\n",
      "[184/300] train: 0.7093 - val: 0.7627\n",
      "[185/300] train: 0.7091 - val: 0.7620\n",
      "[186/300] train: 0.7093 - val: 0.7617\n",
      "[187/300] train: 0.7089 - val: 0.7623\n",
      "[188/300] train: 0.7092 - val: 0.7623\n",
      "[189/300] train: 0.7090 - val: 0.7615\n",
      "[190/300] train: 0.7093 - val: 0.7626\n",
      "[191/300] train: 0.7092 - val: 0.7619\n",
      "[192/300] train: 0.7092 - val: 0.7628\n",
      "[193/300] train: 0.7087 - val: 0.7624\n",
      "[194/300] train: 0.7090 - val: 0.7628\n",
      "[195/300] train: 0.7088 - val: 0.7627\n",
      "[196/300] train: 0.7090 - val: 0.7630\n",
      "[197/300] train: 0.7088 - val: 0.7627\n",
      "[198/300] train: 0.7088 - val: 0.7622\n",
      "[199/300] train: 0.7092 - val: 0.7626\n",
      "[200/300] train: 0.7088 - val: 0.7623\n",
      "[201/300] train: 0.7089 - val: 0.7633\n",
      "[202/300] train: 0.7088 - val: 0.7624\n",
      "[203/300] train: 0.7085 - val: 0.7614\n",
      "[204/300] train: 0.7087 - val: 0.7625\n",
      "[205/300] train: 0.7089 - val: 0.7628\n",
      "[206/300] train: 0.7087 - val: 0.7629\n",
      "[207/300] train: 0.7087 - val: 0.7622\n",
      "[208/300] train: 0.7088 - val: 0.7630\n",
      "[209/300] train: 0.7088 - val: 0.7620\n",
      "[210/300] train: 0.7087 - val: 0.7615\n",
      "[211/300] train: 0.7086 - val: 0.7628\n",
      "[212/300] train: 0.7086 - val: 0.7623\n",
      "[213/300] train: 0.7084 - val: 0.7623\n",
      "[214/300] train: 0.7084 - val: 0.7626\n",
      "[215/300] train: 0.7087 - val: 0.7622\n",
      "[216/300] train: 0.7086 - val: 0.7620\n",
      "[217/300] train: 0.7087 - val: 0.7623\n",
      "[218/300] train: 0.7084 - val: 0.7627\n",
      "[219/300] train: 0.7084 - val: 0.7631\n",
      "[220/300] train: 0.7084 - val: 0.7627\n",
      "[221/300] train: 0.7086 - val: 0.7627\n",
      "[222/300] train: 0.7085 - val: 0.7620\n",
      "[223/300] train: 0.7085 - val: 0.7634\n",
      "[224/300] train: 0.7083 - val: 0.7627\n",
      "[225/300] train: 0.7084 - val: 0.7621\n",
      "[226/300] train: 0.7083 - val: 0.7619\n",
      "[227/300] train: 0.7084 - val: 0.7628\n",
      "[228/300] train: 0.7085 - val: 0.7624\n",
      "[229/300] train: 0.7083 - val: 0.7623\n",
      "[230/300] train: 0.7084 - val: 0.7627\n",
      "[231/300] train: 0.7085 - val: 0.7625\n",
      "[232/300] train: 0.7082 - val: 0.7624\n",
      "[233/300] train: 0.7081 - val: 0.7633\n",
      "[234/300] train: 0.7081 - val: 0.7627\n",
      "[235/300] train: 0.7085 - val: 0.7626\n",
      "[236/300] train: 0.7083 - val: 0.7625\n",
      "[237/300] train: 0.7086 - val: 0.7625\n",
      "[238/300] train: 0.7079 - val: 0.7626\n",
      "[239/300] train: 0.7082 - val: 0.7629\n",
      "[240/300] train: 0.7082 - val: 0.7622\n",
      "[241/300] train: 0.7083 - val: 0.7626\n",
      "[242/300] train: 0.7080 - val: 0.7631\n",
      "[243/300] train: 0.7084 - val: 0.7624\n",
      "[244/300] train: 0.7082 - val: 0.7623\n",
      "[245/300] train: 0.7084 - val: 0.7636\n",
      "[246/300] train: 0.7083 - val: 0.7634\n",
      "[247/300] train: 0.7082 - val: 0.7620\n",
      "[248/300] train: 0.7080 - val: 0.7625\n",
      "[249/300] train: 0.7079 - val: 0.7629\n",
      "[250/300] train: 0.7083 - val: 0.7623\n",
      "[251/300] train: 0.7079 - val: 0.7634\n",
      "[252/300] train: 0.7078 - val: 0.7622\n",
      "[253/300] train: 0.7082 - val: 0.7634\n",
      "[254/300] train: 0.7079 - val: 0.7625\n",
      "[255/300] train: 0.7079 - val: 0.7623\n",
      "[256/300] train: 0.7079 - val: 0.7625\n",
      "[257/300] train: 0.7077 - val: 0.7627\n",
      "[258/300] train: 0.7078 - val: 0.7624\n",
      "[259/300] train: 0.7082 - val: 0.7627\n",
      "[260/300] train: 0.7077 - val: 0.7634\n",
      "[261/300] train: 0.7080 - val: 0.7629\n",
      "[262/300] train: 0.7078 - val: 0.7630\n",
      "[263/300] train: 0.7078 - val: 0.7631\n",
      "[264/300] train: 0.7080 - val: 0.7635\n",
      "[265/300] train: 0.7079 - val: 0.7625\n",
      "[266/300] train: 0.7077 - val: 0.7627\n",
      "[267/300] train: 0.7078 - val: 0.7629\n",
      "[268/300] train: 0.7078 - val: 0.7626\n",
      "[269/300] train: 0.7080 - val: 0.7625\n",
      "[270/300] train: 0.7080 - val: 0.7617\n",
      "[271/300] train: 0.7078 - val: 0.7622\n",
      "[272/300] train: 0.7079 - val: 0.7627\n",
      "[273/300] train: 0.7076 - val: 0.7629\n",
      "[274/300] train: 0.7077 - val: 0.7629\n",
      "[275/300] train: 0.7078 - val: 0.7632\n",
      "[276/300] train: 0.7079 - val: 0.7623\n",
      "[277/300] train: 0.7079 - val: 0.7627\n",
      "[278/300] train: 0.7077 - val: 0.7623\n",
      "[279/300] train: 0.7075 - val: 0.7627\n",
      "[280/300] train: 0.7077 - val: 0.7626\n",
      "[281/300] train: 0.7076 - val: 0.7625\n",
      "[282/300] train: 0.7075 - val: 0.7627\n",
      "[283/300] train: 0.7076 - val: 0.7624\n",
      "[284/300] train: 0.7078 - val: 0.7632\n",
      "[285/300] train: 0.7079 - val: 0.7635\n",
      "[286/300] train: 0.7076 - val: 0.7624\n",
      "[287/300] train: 0.7076 - val: 0.7627\n",
      "[288/300] train: 0.7079 - val: 0.7629\n",
      "[289/300] train: 0.7078 - val: 0.7632\n",
      "[290/300] train: 0.7079 - val: 0.7628\n",
      "[291/300] train: 0.7077 - val: 0.7625\n",
      "[292/300] train: 0.7075 - val: 0.7621\n",
      "[293/300] train: 0.7078 - val: 0.7635\n",
      "[294/300] train: 0.7074 - val: 0.7625\n",
      "[295/300] train: 0.7074 - val: 0.7625\n",
      "[296/300] train: 0.7075 - val: 0.7619\n",
      "[297/300] train: 0.7073 - val: 0.7623\n",
      "[298/300] train: 0.7074 - val: 0.7626\n",
      "[299/300] train: 0.7077 - val: 0.7632\n",
      "[300/300] train: 0.7075 - val: 0.7628\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    with open(f'logs/small.txt', 'a') as f:\n",
    "        print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "        f.write('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8723\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small Test RMSE: 0.8722\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Small Test RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small duration: 877.6335\n"
     ]
    }
   ],
   "source": [
    "print(f'Small duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 26\n",
    "plt.rcParams['axes.labelsize'] = 26\n",
    "plt.rcParams['xtick.labelsize'] = 26\n",
    "plt.rcParams['ytick.labelsize'] = 26\n",
    "plt.rcParams['legend.fontsize'] = 26\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim([0.2, 1.8])\n",
    "\n",
    "plt.savefig(figure_path + '/' + dataset +'-small-loss.png', dpi=300, bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "with open('best.weights.small', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# medium net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=20, hidden=[10 ,10],\n",
    "    embedding_dropout=0.05, dropouts=[0.3, 0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.8778 - val: 0.7960\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7761 - val: 0.7788\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.7622 - val: 0.7744\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.7550 - val: 0.7715\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.7495 - val: 0.7700\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.7452 - val: 0.7690\n",
      "loss improvement on epoch: 7\n",
      "[007/300] train: 0.7415 - val: 0.7679\n",
      "loss improvement on epoch: 8\n",
      "[008/300] train: 0.7387 - val: 0.7669\n",
      "[009/300] train: 0.7367 - val: 0.7669\n",
      "[010/300] train: 0.7345 - val: 0.7671\n",
      "loss improvement on epoch: 11\n",
      "[011/300] train: 0.7330 - val: 0.7664\n",
      "loss improvement on epoch: 12\n",
      "[012/300] train: 0.7312 - val: 0.7653\n",
      "[013/300] train: 0.7302 - val: 0.7655\n",
      "[014/300] train: 0.7290 - val: 0.7659\n",
      "[015/300] train: 0.7278 - val: 0.7659\n",
      "[016/300] train: 0.7267 - val: 0.7658\n",
      "[017/300] train: 0.7258 - val: 0.7656\n",
      "[018/300] train: 0.7248 - val: 0.7663\n",
      "[019/300] train: 0.7240 - val: 0.7655\n",
      "[020/300] train: 0.7237 - val: 0.7654\n",
      "[021/300] train: 0.7229 - val: 0.7656\n",
      "[022/300] train: 0.7222 - val: 0.7657\n",
      "[023/300] train: 0.7218 - val: 0.7661\n",
      "[024/300] train: 0.7212 - val: 0.7664\n",
      "[025/300] train: 0.7205 - val: 0.7660\n",
      "[026/300] train: 0.7201 - val: 0.7659\n",
      "[027/300] train: 0.7196 - val: 0.7657\n",
      "[028/300] train: 0.7190 - val: 0.7655\n",
      "[029/300] train: 0.7186 - val: 0.7663\n",
      "[030/300] train: 0.7183 - val: 0.7667\n",
      "[031/300] train: 0.7179 - val: 0.7666\n",
      "[032/300] train: 0.7172 - val: 0.7662\n",
      "[033/300] train: 0.7168 - val: 0.7674\n",
      "[034/300] train: 0.7167 - val: 0.7662\n",
      "[035/300] train: 0.7167 - val: 0.7668\n",
      "[036/300] train: 0.7161 - val: 0.7666\n",
      "[037/300] train: 0.7162 - val: 0.7663\n",
      "[038/300] train: 0.7158 - val: 0.7672\n",
      "[039/300] train: 0.7155 - val: 0.7673\n",
      "[040/300] train: 0.7149 - val: 0.7676\n",
      "[041/300] train: 0.7144 - val: 0.7671\n",
      "[042/300] train: 0.7141 - val: 0.7667\n",
      "[043/300] train: 0.7144 - val: 0.7663\n",
      "[044/300] train: 0.7138 - val: 0.7664\n",
      "[045/300] train: 0.7141 - val: 0.7678\n",
      "[046/300] train: 0.7134 - val: 0.7672\n",
      "[047/300] train: 0.7131 - val: 0.7685\n",
      "[048/300] train: 0.7126 - val: 0.7672\n",
      "[049/300] train: 0.7129 - val: 0.7676\n",
      "[050/300] train: 0.7127 - val: 0.7674\n",
      "[051/300] train: 0.7123 - val: 0.7680\n",
      "[052/300] train: 0.7122 - val: 0.7677\n",
      "[053/300] train: 0.7117 - val: 0.7687\n",
      "[054/300] train: 0.7115 - val: 0.7668\n",
      "[055/300] train: 0.7116 - val: 0.7677\n",
      "[056/300] train: 0.7115 - val: 0.7688\n",
      "[057/300] train: 0.7111 - val: 0.7674\n",
      "[058/300] train: 0.7110 - val: 0.7685\n",
      "[059/300] train: 0.7105 - val: 0.7671\n",
      "[060/300] train: 0.7108 - val: 0.7678\n",
      "[061/300] train: 0.7105 - val: 0.7682\n",
      "[062/300] train: 0.7105 - val: 0.7687\n",
      "[063/300] train: 0.7104 - val: 0.7683\n",
      "[064/300] train: 0.7101 - val: 0.7686\n",
      "[065/300] train: 0.7102 - val: 0.7682\n",
      "[066/300] train: 0.7099 - val: 0.7691\n",
      "[067/300] train: 0.7092 - val: 0.7686\n",
      "[068/300] train: 0.7094 - val: 0.7694\n",
      "[069/300] train: 0.7093 - val: 0.7694\n",
      "[070/300] train: 0.7091 - val: 0.7683\n",
      "[071/300] train: 0.7091 - val: 0.7689\n",
      "[072/300] train: 0.7092 - val: 0.7691\n",
      "[073/300] train: 0.7091 - val: 0.7696\n",
      "[074/300] train: 0.7086 - val: 0.7688\n",
      "[075/300] train: 0.7089 - val: 0.7691\n",
      "[076/300] train: 0.7087 - val: 0.7697\n",
      "[077/300] train: 0.7082 - val: 0.7697\n",
      "[078/300] train: 0.7086 - val: 0.7688\n",
      "[079/300] train: 0.7082 - val: 0.7690\n",
      "[080/300] train: 0.7083 - val: 0.7693\n",
      "[081/300] train: 0.7081 - val: 0.7693\n",
      "[082/300] train: 0.7080 - val: 0.7696\n",
      "[083/300] train: 0.7078 - val: 0.7694\n",
      "[084/300] train: 0.7077 - val: 0.7694\n",
      "[085/300] train: 0.7076 - val: 0.7694\n",
      "[086/300] train: 0.7076 - val: 0.7690\n",
      "[087/300] train: 0.7075 - val: 0.7692\n",
      "[088/300] train: 0.7074 - val: 0.7692\n",
      "[089/300] train: 0.7073 - val: 0.7693\n",
      "[090/300] train: 0.7073 - val: 0.7695\n",
      "[091/300] train: 0.7072 - val: 0.7697\n",
      "[092/300] train: 0.7070 - val: 0.7691\n",
      "[093/300] train: 0.7071 - val: 0.7694\n",
      "[094/300] train: 0.7070 - val: 0.7694\n",
      "[095/300] train: 0.7067 - val: 0.7694\n",
      "[096/300] train: 0.7067 - val: 0.7685\n",
      "[097/300] train: 0.7067 - val: 0.7697\n",
      "[098/300] train: 0.7068 - val: 0.7696\n",
      "[099/300] train: 0.7066 - val: 0.7702\n",
      "[100/300] train: 0.7066 - val: 0.7689\n",
      "[101/300] train: 0.7066 - val: 0.7697\n",
      "[102/300] train: 0.7066 - val: 0.7709\n",
      "[103/300] train: 0.7061 - val: 0.7699\n",
      "[104/300] train: 0.7061 - val: 0.7700\n",
      "[105/300] train: 0.7061 - val: 0.7703\n",
      "[106/300] train: 0.7061 - val: 0.7705\n",
      "[107/300] train: 0.7062 - val: 0.7699\n",
      "[108/300] train: 0.7058 - val: 0.7702\n",
      "[109/300] train: 0.7054 - val: 0.7700\n",
      "[110/300] train: 0.7057 - val: 0.7697\n",
      "[111/300] train: 0.7055 - val: 0.7709\n",
      "[112/300] train: 0.7052 - val: 0.7696\n",
      "[113/300] train: 0.7055 - val: 0.7688\n",
      "[114/300] train: 0.7052 - val: 0.7705\n",
      "[115/300] train: 0.7052 - val: 0.7704\n",
      "[116/300] train: 0.7052 - val: 0.7699\n",
      "[117/300] train: 0.7054 - val: 0.7705\n",
      "[118/300] train: 0.7052 - val: 0.7704\n",
      "[119/300] train: 0.7052 - val: 0.7702\n",
      "[120/300] train: 0.7050 - val: 0.7712\n",
      "[121/300] train: 0.7050 - val: 0.7699\n",
      "[122/300] train: 0.7050 - val: 0.7698\n",
      "[123/300] train: 0.7049 - val: 0.7704\n",
      "[124/300] train: 0.7050 - val: 0.7692\n",
      "[125/300] train: 0.7047 - val: 0.7710\n",
      "[126/300] train: 0.7046 - val: 0.7700\n",
      "[127/300] train: 0.7047 - val: 0.7705\n",
      "[128/300] train: 0.7046 - val: 0.7698\n",
      "[129/300] train: 0.7047 - val: 0.7705\n",
      "[130/300] train: 0.7046 - val: 0.7715\n",
      "[131/300] train: 0.7049 - val: 0.7713\n",
      "[132/300] train: 0.7043 - val: 0.7706\n",
      "[133/300] train: 0.7043 - val: 0.7703\n",
      "[134/300] train: 0.7045 - val: 0.7720\n",
      "[135/300] train: 0.7041 - val: 0.7709\n",
      "[136/300] train: 0.7040 - val: 0.7708\n",
      "[137/300] train: 0.7045 - val: 0.7712\n",
      "[138/300] train: 0.7043 - val: 0.7692\n",
      "[139/300] train: 0.7043 - val: 0.7708\n",
      "[140/300] train: 0.7042 - val: 0.7714\n",
      "[141/300] train: 0.7038 - val: 0.7708\n",
      "[142/300] train: 0.7040 - val: 0.7720\n",
      "[143/300] train: 0.7037 - val: 0.7703\n",
      "[144/300] train: 0.7044 - val: 0.7711\n",
      "[145/300] train: 0.7037 - val: 0.7704\n",
      "[146/300] train: 0.7039 - val: 0.7708\n",
      "[147/300] train: 0.7036 - val: 0.7713\n",
      "[148/300] train: 0.7039 - val: 0.7721\n",
      "[149/300] train: 0.7036 - val: 0.7708\n",
      "[150/300] train: 0.7039 - val: 0.7714\n",
      "[151/300] train: 0.7037 - val: 0.7709\n",
      "[152/300] train: 0.7034 - val: 0.7706\n",
      "[153/300] train: 0.7032 - val: 0.7708\n",
      "[154/300] train: 0.7033 - val: 0.7707\n",
      "[155/300] train: 0.7038 - val: 0.7712\n",
      "[156/300] train: 0.7033 - val: 0.7713\n",
      "[157/300] train: 0.7033 - val: 0.7721\n",
      "[158/300] train: 0.7037 - val: 0.7718\n",
      "[159/300] train: 0.7031 - val: 0.7711\n",
      "[160/300] train: 0.7034 - val: 0.7712\n",
      "[161/300] train: 0.7030 - val: 0.7722\n",
      "[162/300] train: 0.7033 - val: 0.7722\n",
      "[163/300] train: 0.7031 - val: 0.7718\n",
      "[164/300] train: 0.7034 - val: 0.7718\n",
      "[165/300] train: 0.7032 - val: 0.7713\n",
      "[166/300] train: 0.7032 - val: 0.7714\n",
      "[167/300] train: 0.7032 - val: 0.7713\n",
      "[168/300] train: 0.7030 - val: 0.7705\n",
      "[169/300] train: 0.7028 - val: 0.7719\n",
      "[170/300] train: 0.7028 - val: 0.7723\n",
      "[171/300] train: 0.7026 - val: 0.7712\n",
      "[172/300] train: 0.7026 - val: 0.7714\n",
      "[173/300] train: 0.7029 - val: 0.7711\n",
      "[174/300] train: 0.7029 - val: 0.7712\n",
      "[175/300] train: 0.7031 - val: 0.7705\n",
      "[176/300] train: 0.7030 - val: 0.7724\n",
      "[177/300] train: 0.7027 - val: 0.7718\n",
      "[178/300] train: 0.7029 - val: 0.7717\n",
      "[179/300] train: 0.7026 - val: 0.7717\n",
      "[180/300] train: 0.7027 - val: 0.7720\n",
      "[181/300] train: 0.7025 - val: 0.7714\n",
      "[182/300] train: 0.7028 - val: 0.7718\n",
      "[183/300] train: 0.7026 - val: 0.7714\n",
      "[184/300] train: 0.7025 - val: 0.7722\n",
      "[185/300] train: 0.7026 - val: 0.7716\n",
      "[186/300] train: 0.7024 - val: 0.7712\n",
      "[187/300] train: 0.7026 - val: 0.7713\n",
      "[188/300] train: 0.7023 - val: 0.7703\n",
      "[189/300] train: 0.7023 - val: 0.7719\n",
      "[190/300] train: 0.7024 - val: 0.7717\n",
      "[191/300] train: 0.7025 - val: 0.7710\n",
      "[192/300] train: 0.7022 - val: 0.7717\n",
      "[193/300] train: 0.7022 - val: 0.7716\n",
      "[194/300] train: 0.7022 - val: 0.7708\n",
      "[195/300] train: 0.7024 - val: 0.7703\n",
      "[196/300] train: 0.7024 - val: 0.7723\n",
      "[197/300] train: 0.7022 - val: 0.7715\n",
      "[198/300] train: 0.7025 - val: 0.7710\n",
      "[199/300] train: 0.7026 - val: 0.7722\n",
      "[200/300] train: 0.7021 - val: 0.7713\n",
      "[201/300] train: 0.7020 - val: 0.7715\n",
      "[202/300] train: 0.7023 - val: 0.7719\n",
      "[203/300] train: 0.7016 - val: 0.7715\n",
      "[204/300] train: 0.7022 - val: 0.7715\n",
      "[205/300] train: 0.7020 - val: 0.7724\n",
      "[206/300] train: 0.7022 - val: 0.7716\n",
      "[207/300] train: 0.7022 - val: 0.7717\n",
      "[208/300] train: 0.7020 - val: 0.7726\n",
      "[209/300] train: 0.7015 - val: 0.7724\n",
      "[210/300] train: 0.7023 - val: 0.7717\n",
      "[211/300] train: 0.7017 - val: 0.7728\n",
      "[212/300] train: 0.7023 - val: 0.7725\n",
      "[213/300] train: 0.7018 - val: 0.7717\n",
      "[214/300] train: 0.7020 - val: 0.7722\n",
      "[215/300] train: 0.7019 - val: 0.7713\n",
      "[216/300] train: 0.7020 - val: 0.7722\n",
      "[217/300] train: 0.7017 - val: 0.7742\n",
      "[218/300] train: 0.7017 - val: 0.7718\n",
      "[219/300] train: 0.7015 - val: 0.7718\n",
      "[220/300] train: 0.7017 - val: 0.7714\n",
      "[221/300] train: 0.7016 - val: 0.7734\n",
      "[222/300] train: 0.7014 - val: 0.7725\n",
      "[223/300] train: 0.7016 - val: 0.7713\n",
      "[224/300] train: 0.7018 - val: 0.7710\n",
      "[225/300] train: 0.7015 - val: 0.7716\n",
      "[226/300] train: 0.7018 - val: 0.7712\n",
      "[227/300] train: 0.7011 - val: 0.7726\n",
      "[228/300] train: 0.7016 - val: 0.7727\n",
      "[229/300] train: 0.7017 - val: 0.7700\n",
      "[230/300] train: 0.7015 - val: 0.7728\n",
      "[231/300] train: 0.7013 - val: 0.7705\n",
      "[232/300] train: 0.7015 - val: 0.7712\n",
      "[233/300] train: 0.7017 - val: 0.7728\n",
      "[234/300] train: 0.7012 - val: 0.7720\n",
      "[235/300] train: 0.7015 - val: 0.7721\n",
      "[236/300] train: 0.7014 - val: 0.7724\n",
      "[237/300] train: 0.7015 - val: 0.7721\n",
      "[238/300] train: 0.7012 - val: 0.7728\n",
      "[239/300] train: 0.7017 - val: 0.7735\n",
      "[240/300] train: 0.7014 - val: 0.7719\n",
      "[241/300] train: 0.7013 - val: 0.7733\n",
      "[242/300] train: 0.7011 - val: 0.7722\n",
      "[243/300] train: 0.7011 - val: 0.7721\n",
      "[244/300] train: 0.7014 - val: 0.7727\n",
      "[245/300] train: 0.7013 - val: 0.7728\n",
      "[246/300] train: 0.7010 - val: 0.7735\n",
      "[247/300] train: 0.7014 - val: 0.7737\n",
      "[248/300] train: 0.7014 - val: 0.7741\n",
      "[249/300] train: 0.7011 - val: 0.7724\n",
      "[250/300] train: 0.7009 - val: 0.7721\n",
      "[251/300] train: 0.7010 - val: 0.7719\n",
      "[252/300] train: 0.7011 - val: 0.7733\n",
      "[253/300] train: 0.7007 - val: 0.7713\n",
      "[254/300] train: 0.7010 - val: 0.7731\n",
      "[255/300] train: 0.7007 - val: 0.7724\n",
      "[256/300] train: 0.7009 - val: 0.7713\n",
      "[257/300] train: 0.7007 - val: 0.7743\n",
      "[258/300] train: 0.7009 - val: 0.7728\n",
      "[259/300] train: 0.7012 - val: 0.7727\n",
      "[260/300] train: 0.7008 - val: 0.7726\n",
      "[261/300] train: 0.7009 - val: 0.7730\n",
      "[262/300] train: 0.7010 - val: 0.7734\n",
      "[263/300] train: 0.7011 - val: 0.7734\n",
      "[264/300] train: 0.7010 - val: 0.7714\n",
      "[265/300] train: 0.7008 - val: 0.7724\n",
      "[266/300] train: 0.7006 - val: 0.7731\n",
      "[267/300] train: 0.7009 - val: 0.7721\n",
      "[268/300] train: 0.7006 - val: 0.7725\n",
      "[269/300] train: 0.7008 - val: 0.7729\n",
      "[270/300] train: 0.7006 - val: 0.7725\n",
      "[271/300] train: 0.7008 - val: 0.7717\n",
      "[272/300] train: 0.7005 - val: 0.7724\n",
      "[273/300] train: 0.7008 - val: 0.7738\n",
      "[274/300] train: 0.7009 - val: 0.7739\n",
      "[275/300] train: 0.7007 - val: 0.7717\n",
      "[276/300] train: 0.7010 - val: 0.7719\n",
      "[277/300] train: 0.7008 - val: 0.7729\n",
      "[278/300] train: 0.7011 - val: 0.7716\n",
      "[279/300] train: 0.7006 - val: 0.7722\n",
      "[280/300] train: 0.7005 - val: 0.7722\n",
      "[281/300] train: 0.7010 - val: 0.7724\n",
      "[282/300] train: 0.7009 - val: 0.7727\n",
      "[283/300] train: 0.7008 - val: 0.7742\n",
      "[284/300] train: 0.7006 - val: 0.7731\n",
      "[285/300] train: 0.7004 - val: 0.7723\n",
      "[286/300] train: 0.7007 - val: 0.7727\n",
      "[287/300] train: 0.7005 - val: 0.7736\n",
      "[288/300] train: 0.7004 - val: 0.7746\n",
      "[289/300] train: 0.7006 - val: 0.7722\n",
      "[290/300] train: 0.7006 - val: 0.7725\n",
      "[291/300] train: 0.7006 - val: 0.7721\n",
      "[292/300] train: 0.7004 - val: 0.7745\n",
      "[293/300] train: 0.7009 - val: 0.7730\n",
      "[294/300] train: 0.7004 - val: 0.7729\n",
      "[295/300] train: 0.6999 - val: 0.7718\n",
      "[296/300] train: 0.7007 - val: 0.7717\n",
      "[297/300] train: 0.7003 - val: 0.7731\n",
      "[298/300] train: 0.7004 - val: 0.7729\n",
      "[299/300] train: 0.7002 - val: 0.7732\n",
      "[300/300] train: 0.7004 - val: 0.7728\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    with open(f'logs/medium.txt', 'a') as f:\n",
    "        print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "        f.write('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8755\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium test RMSE: 0.8752\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Medium test RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium duration: 1127.0676\n"
     ]
    }
   ],
   "source": [
    "print(f'Medium duration: {round(time.time() - start, 4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "with open('best.weights.medium', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 26\n",
    "plt.rcParams['axes.labelsize'] = 26\n",
    "plt.rcParams['xtick.labelsize'] = 26\n",
    "plt.rcParams['ytick.labelsize'] = 26\n",
    "plt.rcParams['legend.fontsize'] = 26\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim([0.2, 1.8])\n",
    "\n",
    "plt.savefig(figure_path + '/' + dataset +'-medium-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# large net\n",
    "\n",
    "start = time.time()\n",
    "net = RecommenderNet(\n",
    "    n_users=n, n_movies=m,\n",
    "    n_factors=50, hidden=[100, 100, 100],\n",
    "    embedding_dropout=0.05, dropouts=[0.3, 0.3, 0.3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 4096\n",
    "n_epochs = 300\n",
    "patience = 300\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/300] train: 0.7883 - val: 0.7387\n",
      "loss improvement on epoch: 2\n",
      "[002/300] train: 0.7133 - val: 0.7173\n",
      "loss improvement on epoch: 3\n",
      "[003/300] train: 0.6867 - val: 0.7073\n",
      "loss improvement on epoch: 4\n",
      "[004/300] train: 0.6664 - val: 0.7017\n",
      "loss improvement on epoch: 5\n",
      "[005/300] train: 0.6484 - val: 0.6974\n",
      "loss improvement on epoch: 6\n",
      "[006/300] train: 0.6326 - val: 0.6968\n",
      "[007/300] train: 0.6177 - val: 0.6975\n",
      "[008/300] train: 0.6046 - val: 0.6977\n",
      "[009/300] train: 0.5933 - val: 0.6984\n",
      "[010/300] train: 0.5833 - val: 0.7004\n",
      "[011/300] train: 0.5743 - val: 0.7023\n",
      "[012/300] train: 0.5665 - val: 0.7090\n",
      "[013/300] train: 0.5594 - val: 0.7048\n",
      "[014/300] train: 0.5532 - val: 0.7081\n",
      "[015/300] train: 0.5473 - val: 0.7108\n",
      "[016/300] train: 0.5419 - val: 0.7143\n",
      "[017/300] train: 0.5369 - val: 0.7157\n",
      "[018/300] train: 0.5328 - val: 0.7152\n",
      "[019/300] train: 0.5287 - val: 0.7198\n",
      "[020/300] train: 0.5247 - val: 0.7172\n",
      "[021/300] train: 0.5211 - val: 0.7216\n",
      "[022/300] train: 0.5180 - val: 0.7194\n",
      "[023/300] train: 0.5148 - val: 0.7218\n",
      "[024/300] train: 0.5119 - val: 0.7239\n",
      "[025/300] train: 0.5094 - val: 0.7257\n",
      "[026/300] train: 0.5067 - val: 0.7263\n",
      "[027/300] train: 0.5039 - val: 0.7272\n",
      "[028/300] train: 0.5020 - val: 0.7288\n",
      "[029/300] train: 0.4998 - val: 0.7335\n",
      "[030/300] train: 0.4974 - val: 0.7339\n",
      "[031/300] train: 0.4955 - val: 0.7357\n",
      "[032/300] train: 0.4935 - val: 0.7379\n",
      "[033/300] train: 0.4917 - val: 0.7385\n",
      "[034/300] train: 0.4902 - val: 0.7333\n",
      "[035/300] train: 0.4886 - val: 0.7372\n",
      "[036/300] train: 0.4871 - val: 0.7384\n",
      "[037/300] train: 0.4854 - val: 0.7390\n",
      "[038/300] train: 0.4838 - val: 0.7386\n",
      "[039/300] train: 0.4828 - val: 0.7372\n",
      "[040/300] train: 0.4815 - val: 0.7422\n",
      "[041/300] train: 0.4800 - val: 0.7465\n",
      "[042/300] train: 0.4788 - val: 0.7399\n",
      "[043/300] train: 0.4777 - val: 0.7422\n",
      "[044/300] train: 0.4768 - val: 0.7465\n",
      "[045/300] train: 0.4755 - val: 0.7465\n",
      "[046/300] train: 0.4745 - val: 0.7472\n",
      "[047/300] train: 0.4735 - val: 0.7486\n",
      "[048/300] train: 0.4725 - val: 0.7479\n",
      "[049/300] train: 0.4717 - val: 0.7464\n",
      "[050/300] train: 0.4708 - val: 0.7499\n",
      "[051/300] train: 0.4697 - val: 0.7463\n",
      "[052/300] train: 0.4690 - val: 0.7477\n",
      "[053/300] train: 0.4680 - val: 0.7488\n",
      "[054/300] train: 0.4676 - val: 0.7543\n",
      "[055/300] train: 0.4666 - val: 0.7483\n",
      "[056/300] train: 0.4660 - val: 0.7510\n",
      "[057/300] train: 0.4650 - val: 0.7519\n",
      "[058/300] train: 0.4642 - val: 0.7492\n",
      "[059/300] train: 0.4638 - val: 0.7501\n",
      "[060/300] train: 0.4633 - val: 0.7567\n",
      "[061/300] train: 0.4625 - val: 0.7496\n",
      "[062/300] train: 0.4617 - val: 0.7505\n",
      "[063/300] train: 0.4615 - val: 0.7520\n",
      "[064/300] train: 0.4606 - val: 0.7576\n",
      "[065/300] train: 0.4600 - val: 0.7551\n",
      "[066/300] train: 0.4592 - val: 0.7456\n",
      "[067/300] train: 0.4591 - val: 0.7540\n",
      "[068/300] train: 0.4586 - val: 0.7538\n",
      "[069/300] train: 0.4579 - val: 0.7524\n",
      "[070/300] train: 0.4574 - val: 0.7511\n",
      "[071/300] train: 0.4571 - val: 0.7624\n",
      "[072/300] train: 0.4563 - val: 0.7569\n",
      "[073/300] train: 0.4559 - val: 0.7585\n",
      "[074/300] train: 0.4559 - val: 0.7577\n",
      "[075/300] train: 0.4552 - val: 0.7611\n",
      "[076/300] train: 0.4545 - val: 0.7599\n",
      "[077/300] train: 0.4544 - val: 0.7605\n",
      "[078/300] train: 0.4535 - val: 0.7569\n",
      "[079/300] train: 0.4538 - val: 0.7548\n",
      "[080/300] train: 0.4533 - val: 0.7553\n",
      "[081/300] train: 0.4522 - val: 0.7645\n",
      "[082/300] train: 0.4522 - val: 0.7598\n",
      "[083/300] train: 0.4520 - val: 0.7610\n",
      "[084/300] train: 0.4513 - val: 0.7673\n",
      "[085/300] train: 0.4509 - val: 0.7595\n",
      "[086/300] train: 0.4507 - val: 0.7534\n",
      "[087/300] train: 0.4508 - val: 0.7655\n",
      "[088/300] train: 0.4500 - val: 0.7640\n",
      "[089/300] train: 0.4497 - val: 0.7630\n",
      "[090/300] train: 0.4495 - val: 0.7593\n",
      "[091/300] train: 0.4488 - val: 0.7648\n",
      "[092/300] train: 0.4487 - val: 0.7604\n",
      "[093/300] train: 0.4483 - val: 0.7657\n",
      "[094/300] train: 0.4479 - val: 0.7626\n",
      "[095/300] train: 0.4475 - val: 0.7683\n",
      "[096/300] train: 0.4477 - val: 0.7586\n",
      "[097/300] train: 0.4477 - val: 0.7640\n",
      "[098/300] train: 0.4469 - val: 0.7689\n",
      "[099/300] train: 0.4469 - val: 0.7647\n",
      "[100/300] train: 0.4467 - val: 0.7634\n",
      "[101/300] train: 0.4462 - val: 0.7650\n",
      "[102/300] train: 0.4460 - val: 0.7606\n",
      "[103/300] train: 0.4456 - val: 0.7610\n",
      "[104/300] train: 0.4454 - val: 0.7627\n",
      "[105/300] train: 0.4453 - val: 0.7667\n",
      "[106/300] train: 0.4448 - val: 0.7596\n",
      "[107/300] train: 0.4446 - val: 0.7602\n",
      "[108/300] train: 0.4443 - val: 0.7661\n",
      "[109/300] train: 0.4441 - val: 0.7671\n",
      "[110/300] train: 0.4442 - val: 0.7697\n",
      "[111/300] train: 0.4436 - val: 0.7639\n",
      "[112/300] train: 0.4437 - val: 0.7674\n",
      "[113/300] train: 0.4434 - val: 0.7684\n",
      "[114/300] train: 0.4430 - val: 0.7613\n",
      "[115/300] train: 0.4429 - val: 0.7635\n",
      "[116/300] train: 0.4424 - val: 0.7684\n",
      "[117/300] train: 0.4423 - val: 0.7688\n",
      "[118/300] train: 0.4423 - val: 0.7711\n",
      "[119/300] train: 0.4418 - val: 0.7619\n",
      "[120/300] train: 0.4418 - val: 0.7624\n",
      "[121/300] train: 0.4417 - val: 0.7689\n",
      "[122/300] train: 0.4413 - val: 0.7638\n",
      "[123/300] train: 0.4413 - val: 0.7661\n",
      "[124/300] train: 0.4409 - val: 0.7641\n",
      "[125/300] train: 0.4408 - val: 0.7676\n",
      "[126/300] train: 0.4407 - val: 0.7732\n",
      "[127/300] train: 0.4403 - val: 0.7725\n",
      "[128/300] train: 0.4402 - val: 0.7693\n",
      "[129/300] train: 0.4401 - val: 0.7740\n",
      "[130/300] train: 0.4396 - val: 0.7726\n",
      "[131/300] train: 0.4397 - val: 0.7724\n",
      "[132/300] train: 0.4396 - val: 0.7652\n",
      "[133/300] train: 0.4391 - val: 0.7674\n",
      "[134/300] train: 0.4391 - val: 0.7717\n",
      "[135/300] train: 0.4388 - val: 0.7730\n",
      "[136/300] train: 0.4391 - val: 0.7704\n",
      "[137/300] train: 0.4387 - val: 0.7638\n",
      "[138/300] train: 0.4387 - val: 0.7655\n",
      "[139/300] train: 0.4383 - val: 0.7732\n",
      "[140/300] train: 0.4381 - val: 0.7639\n",
      "[141/300] train: 0.4381 - val: 0.7672\n",
      "[142/300] train: 0.4379 - val: 0.7712\n",
      "[143/300] train: 0.4376 - val: 0.7685\n",
      "[144/300] train: 0.4377 - val: 0.7594\n",
      "[145/300] train: 0.4376 - val: 0.7716\n",
      "[146/300] train: 0.4374 - val: 0.7697\n",
      "[147/300] train: 0.4371 - val: 0.7680\n",
      "[148/300] train: 0.4368 - val: 0.7702\n",
      "[149/300] train: 0.4368 - val: 0.7738\n",
      "[150/300] train: 0.4365 - val: 0.7625\n",
      "[151/300] train: 0.4364 - val: 0.7690\n",
      "[152/300] train: 0.4365 - val: 0.7769\n",
      "[153/300] train: 0.4361 - val: 0.7751\n",
      "[154/300] train: 0.4359 - val: 0.7748\n",
      "[155/300] train: 0.4358 - val: 0.7754\n",
      "[156/300] train: 0.4361 - val: 0.7685\n",
      "[157/300] train: 0.4358 - val: 0.7719\n",
      "[158/300] train: 0.4357 - val: 0.7696\n",
      "[159/300] train: 0.4353 - val: 0.7798\n",
      "[160/300] train: 0.4353 - val: 0.7707\n",
      "[161/300] train: 0.4352 - val: 0.7678\n",
      "[162/300] train: 0.4353 - val: 0.7650\n",
      "[163/300] train: 0.4353 - val: 0.7751\n",
      "[164/300] train: 0.4350 - val: 0.7725\n",
      "[165/300] train: 0.4348 - val: 0.7644\n",
      "[166/300] train: 0.4345 - val: 0.7702\n",
      "[167/300] train: 0.4343 - val: 0.7717\n",
      "[168/300] train: 0.4345 - val: 0.7778\n",
      "[169/300] train: 0.4344 - val: 0.7669\n",
      "[170/300] train: 0.4341 - val: 0.7709\n",
      "[171/300] train: 0.4341 - val: 0.7722\n",
      "[172/300] train: 0.4340 - val: 0.7812\n",
      "[173/300] train: 0.4340 - val: 0.7733\n",
      "[174/300] train: 0.4339 - val: 0.7781\n",
      "[175/300] train: 0.4337 - val: 0.7660\n",
      "[176/300] train: 0.4333 - val: 0.7737\n",
      "[177/300] train: 0.4333 - val: 0.7728\n",
      "[178/300] train: 0.4334 - val: 0.7728\n",
      "[179/300] train: 0.4331 - val: 0.7911\n",
      "[180/300] train: 0.4331 - val: 0.7682\n",
      "[181/300] train: 0.4331 - val: 0.7707\n",
      "[182/300] train: 0.4330 - val: 0.7659\n",
      "[183/300] train: 0.4329 - val: 0.7798\n",
      "[184/300] train: 0.4322 - val: 0.7673\n",
      "[185/300] train: 0.4325 - val: 0.7776\n",
      "[186/300] train: 0.4324 - val: 0.7726\n",
      "[187/300] train: 0.4324 - val: 0.7747\n",
      "[188/300] train: 0.4319 - val: 0.7701\n",
      "[189/300] train: 0.4322 - val: 0.7777\n",
      "[190/300] train: 0.4322 - val: 0.7751\n",
      "[191/300] train: 0.4317 - val: 0.7793\n",
      "[192/300] train: 0.4319 - val: 0.7692\n",
      "[193/300] train: 0.4315 - val: 0.7694\n",
      "[194/300] train: 0.4316 - val: 0.7740\n",
      "[195/300] train: 0.4313 - val: 0.7685\n",
      "[196/300] train: 0.4318 - val: 0.7803\n",
      "[197/300] train: 0.4311 - val: 0.7803\n",
      "[198/300] train: 0.4313 - val: 0.7722\n",
      "[199/300] train: 0.4311 - val: 0.7791\n",
      "[200/300] train: 0.4312 - val: 0.7763\n",
      "[201/300] train: 0.4309 - val: 0.7736\n",
      "[202/300] train: 0.4309 - val: 0.7661\n",
      "[203/300] train: 0.4308 - val: 0.7765\n",
      "[204/300] train: 0.4310 - val: 0.7736\n",
      "[205/300] train: 0.4308 - val: 0.7751\n",
      "[206/300] train: 0.4308 - val: 0.7733\n",
      "[207/300] train: 0.4306 - val: 0.7774\n",
      "[208/300] train: 0.4306 - val: 0.7739\n",
      "[209/300] train: 0.4304 - val: 0.7700\n",
      "[210/300] train: 0.4302 - val: 0.7782\n",
      "[211/300] train: 0.4299 - val: 0.7823\n",
      "[212/300] train: 0.4303 - val: 0.7721\n",
      "[213/300] train: 0.4299 - val: 0.7770\n",
      "[214/300] train: 0.4300 - val: 0.7741\n",
      "[215/300] train: 0.4298 - val: 0.7808\n",
      "[216/300] train: 0.4297 - val: 0.7761\n",
      "[217/300] train: 0.4298 - val: 0.7761\n",
      "[218/300] train: 0.4293 - val: 0.7764\n",
      "[219/300] train: 0.4296 - val: 0.7781\n",
      "[220/300] train: 0.4295 - val: 0.7767\n",
      "[221/300] train: 0.4295 - val: 0.7706\n",
      "[222/300] train: 0.4295 - val: 0.7828\n",
      "[223/300] train: 0.4292 - val: 0.7752\n",
      "[224/300] train: 0.4292 - val: 0.7680\n",
      "[225/300] train: 0.4293 - val: 0.7765\n",
      "[226/300] train: 0.4292 - val: 0.7746\n",
      "[227/300] train: 0.4290 - val: 0.7737\n",
      "[228/300] train: 0.4289 - val: 0.7733\n",
      "[229/300] train: 0.4289 - val: 0.7800\n",
      "[230/300] train: 0.4287 - val: 0.7751\n",
      "[231/300] train: 0.4285 - val: 0.7752\n",
      "[232/300] train: 0.4286 - val: 0.7763\n",
      "[233/300] train: 0.4284 - val: 0.7775\n",
      "[234/300] train: 0.4286 - val: 0.7745\n",
      "[235/300] train: 0.4284 - val: 0.7714\n",
      "[236/300] train: 0.4283 - val: 0.7737\n",
      "[237/300] train: 0.4280 - val: 0.7746\n",
      "[238/300] train: 0.4278 - val: 0.7697\n",
      "[239/300] train: 0.4280 - val: 0.7705\n",
      "[240/300] train: 0.4278 - val: 0.7709\n",
      "[241/300] train: 0.4283 - val: 0.7735\n",
      "[242/300] train: 0.4281 - val: 0.7728\n",
      "[243/300] train: 0.4276 - val: 0.7746\n",
      "[244/300] train: 0.4278 - val: 0.7796\n",
      "[245/300] train: 0.4280 - val: 0.7819\n",
      "[246/300] train: 0.4277 - val: 0.7788\n",
      "[247/300] train: 0.4275 - val: 0.7801\n",
      "[248/300] train: 0.4276 - val: 0.7788\n",
      "[249/300] train: 0.4275 - val: 0.7804\n",
      "[250/300] train: 0.4274 - val: 0.7710\n",
      "[251/300] train: 0.4271 - val: 0.7782\n",
      "[252/300] train: 0.4272 - val: 0.7723\n",
      "[253/300] train: 0.4271 - val: 0.7725\n",
      "[254/300] train: 0.4273 - val: 0.7724\n",
      "[255/300] train: 0.4271 - val: 0.7793\n",
      "[256/300] train: 0.4272 - val: 0.7761\n",
      "[257/300] train: 0.4269 - val: 0.7853\n",
      "[258/300] train: 0.4268 - val: 0.7847\n",
      "[259/300] train: 0.4268 - val: 0.7828\n",
      "[260/300] train: 0.4270 - val: 0.7843\n",
      "[261/300] train: 0.4269 - val: 0.7747\n",
      "[262/300] train: 0.4267 - val: 0.7693\n",
      "[263/300] train: 0.4264 - val: 0.7800\n",
      "[264/300] train: 0.4268 - val: 0.7803\n",
      "[265/300] train: 0.4264 - val: 0.7740\n",
      "[266/300] train: 0.4269 - val: 0.7789\n",
      "[267/300] train: 0.4263 - val: 0.7778\n",
      "[268/300] train: 0.4263 - val: 0.7706\n",
      "[269/300] train: 0.4262 - val: 0.7787\n",
      "[270/300] train: 0.4262 - val: 0.7726\n",
      "[271/300] train: 0.4260 - val: 0.7818\n",
      "[272/300] train: 0.4262 - val: 0.7764\n",
      "[273/300] train: 0.4262 - val: 0.7769\n",
      "[274/300] train: 0.4261 - val: 0.7733\n",
      "[275/300] train: 0.4258 - val: 0.7810\n",
      "[276/300] train: 0.4260 - val: 0.7877\n",
      "[277/300] train: 0.4258 - val: 0.7738\n",
      "[278/300] train: 0.4260 - val: 0.7835\n",
      "[279/300] train: 0.4260 - val: 0.7707\n",
      "[280/300] train: 0.4256 - val: 0.7743\n",
      "[281/300] train: 0.4257 - val: 0.7803\n",
      "[282/300] train: 0.4255 - val: 0.7775\n",
      "[283/300] train: 0.4256 - val: 0.7792\n",
      "[284/300] train: 0.4254 - val: 0.7766\n",
      "[285/300] train: 0.4254 - val: 0.7730\n",
      "[286/300] train: 0.4256 - val: 0.7754\n",
      "[287/300] train: 0.4258 - val: 0.7820\n",
      "[288/300] train: 0.4252 - val: 0.7782\n",
      "[289/300] train: 0.4252 - val: 0.7710\n",
      "[290/300] train: 0.4254 - val: 0.7812\n",
      "[291/300] train: 0.4253 - val: 0.7881\n",
      "[292/300] train: 0.4253 - val: 0.7827\n",
      "[293/300] train: 0.4250 - val: 0.7735\n",
      "[294/300] train: 0.4255 - val: 0.7734\n",
      "[295/300] train: 0.4254 - val: 0.7829\n",
      "[296/300] train: 0.4251 - val: 0.7756\n",
      "[297/300] train: 0.4251 - val: 0.7779\n",
      "[298/300] train: 0.4251 - val: 0.7835\n",
      "[299/300] train: 0.4249 - val: 0.7762\n",
      "[300/300] train: 0.4245 - val: 0.7784\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "\n",
    "    for phase in ('train', 'val'):\n",
    "        if phase == 'train':\n",
    "          training = True\n",
    "        else:\n",
    "          training = False\n",
    "        running_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:,0], x_batch[:,1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    #scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    #lr_history.extend(scheduler.get_lr())\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "    history.append(stats)\n",
    "    with open(f'logs/large.txt', 'a') as f:\n",
    "        print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "        f.write('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(best_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8351\n"
     ]
    }
   ],
   "source": [
    "valid_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Validation RMSE: {valid_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['test'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large test RMSE: 0.8346\n"
     ]
    }
   ],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Large test RMSE: {final_loss:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large duration: 1729.4503\n"
     ]
    }
   ],
   "source": [
    "print(f'Large duration: {round(time.time() - start, 4)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "with open('best.weights.big', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 26\n",
    "plt.rcParams['axes.labelsize'] = 26\n",
    "plt.rcParams['xtick.labelsize'] = 26\n",
    "plt.rcParams['ytick.labelsize'] = 26\n",
    "plt.rcParams['legend.fontsize'] = 26\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim([0.2, 1.8])\n",
    "\n",
    "plt.savefig(figure_path + '/' + dataset +'-large-loss.png', dpi=300, bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f57757a1",
   "language": "python",
   "display_name": "PyCharm (rs-via-gnn)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}